{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from astropy.io import fits\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from autoconf import conf\n",
        "import autofit as af\n",
        "from autofit_workspace.examples.simple import model as m\n",
        "from autofit_workspace.examples.simple import analysis as a\n",
        "\n",
        "\"\"\"\n",
        "__Example: Result__\n",
        "\n",
        "In this example, we'll repeat the fit of 1D data of a Gaussian profile with a 1D Gaussian model using the non-linear \n",
        "search emcee and inspect the *Result* object that is returned in detail.\n",
        "\n",
        "If you haven't already, you should checkout the files 'example/model.py','example/analysis.py' and 'example/fit.py' to \n",
        "see how the fit is performed by the code below. The first section of code below is simmply repeating the commands in\n",
        "'example/fit.py', so feel free to skip over it until you his the __Result__ section.\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Paths__\n",
        "\n",
        "Setup the path to the autofit_workspace, using a relative directory name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "workspace_path = \"{}/../..\".format(os.path.dirname(os.path.realpath(__file__)))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use this path to explicitly set the config path and output path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "conf.instance = conf.Config(\n",
        "    config_path=f\"{workspace_path}/config\", output_path=f\"{workspace_path}/output\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Data__\n",
        "\n",
        "First, lets load our data of a 1D Gaussian."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = f\"{workspace_path}/dataset/gaussian_x1\"\n",
        "\n",
        "data_hdu_list = fits.open(f\"{dataset_path}/data.fits\")\n",
        "data = np.array(data_hdu_list[0].data)\n",
        "\n",
        "noise_map_hdu_list = fits.open(f\"{dataset_path}/noise_map.fits\")\n",
        "noise_map = np.array(noise_map_hdu_list[0].data)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "Next, we create our model, which in this case corresponds to a single Gaussian. In model.py, you will have noted\n",
        "this Gaussian has 3 parameters (centre, intensity and sigma). These are the free parameters of our model that the\n",
        "non-linear search fits for, meaning the non-linear parameter space has dimensionality = 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = af.PriorModel(m.Gaussian)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checkout 'autofit_workspace/config/json_priors' - this config file defines the default priors of all our model\n",
        "components. However, we can overwrite priors before running the non-linear search as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model.centre = af.UniformPrior(lower_limit=0.0, upper_limit=100.0)\n",
        "model.intensity = af.LogUniformPrior(lower_limit=1e-2, upper_limit=1e2)\n",
        "model.sigma = af.GaussianPrior(mean=10.0, sigma=5.0, lower_limit=0.0, upper_limit=np.inf)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "We now set up our Analysis, using the class described in 'analysis.py'. The analysis describes how given an instance\n",
        "of our model (a Gaussian) we fit the data and return a log likelihood value. For this simple example, we only have to\n",
        "pass it the data and its noise-map."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = a.Analysis(data=data, noise_map=noise_map)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the non-linear object for emcee and perform the fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "emcee = af.Emcee(\n",
        "    nwalkers=30,\n",
        "    nsteps=1000,\n",
        "    initialize_method=\"ball\",\n",
        "    initialize_ball_lower_limit=0.49,\n",
        "    initialize_ball_upper_limit=0.51,\n",
        "    auto_correlation_check_for_convergence=True,\n",
        "    auto_correlation_check_size=100,\n",
        "    auto_correlation_required_length=50,\n",
        "    auto_correlation_change_threshold=0.01,\n",
        "    number_of_cores=1,\n",
        ")\n",
        "\n",
        "result = emcee.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__RESULT__\n",
        "\n",
        "Here, we'll look in detail at what information is contained in the result.\n",
        "\n",
        "It contains a *Samples* object, which contains information on the non-linear sampling, for example the parameters. \n",
        "The parameters are stored as a a list of lists, where the first entry corresponds to the sample index and second entry\n",
        "the parameter index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples = result.samples\n",
        "print(\"All Parameters:\")\n",
        "print(samples.parameters)\n",
        "print(\"Sample 10's third parameter value (Gaussian -> sigma)\")\n",
        "print(samples.parameters[9][1], \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The parameters are a list of lists of all accepted parameter values sampled by the non-linear search. Also available\n",
        "are lists of the likelihood, prior, posterior and weight values associated with every sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"All Log Likelihoods:\")\n",
        "print(samples.log_likelihoods)\n",
        "print(\"All Log Priors:\")\n",
        "print(samples.log_priors)\n",
        "print(\"All Log Posteriors:\")\n",
        "print(samples.log_posteriors)\n",
        "print(\"All Sample Weights:\")\n",
        "print(samples.weights, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For MCMC analysis, these can be used perform parameter estimation by binning the samples in a histogram (assuming we\n",
        "have removed the burn-in phase):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples_after_burn_in = result.samples.samples_after_burn_in\n",
        "\n",
        "median_pdf_vector = [float(np.percentile(samples_after_burn_in[:, i], [50])) for i in range(model.prior_count)]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The most probable vector is readily available from the *Samples* object for you convenience (and if a nested sampling\n",
        "*non-linear search* is used instead, it will use an appropriate method to estimate the parameters):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "median_pdf_vector = samples.median_pdf_vector\n",
        "print(\"Most Probable Vector:\")\n",
        "print(median_pdf_vector, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The samples contain many useful vectors, including the samples with the highest likelihood and posterior values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "max_log_likelihood_vector = samples.max_log_likelihood_vector\n",
        "max_log_posterior_vector = samples.max_log_posterior_vector\n",
        "\n",
        "print(\"Maximum Log Likelihood Vector:\")\n",
        "print(max_log_likelihood_vector)\n",
        "print(\"Maximum Log Posterior Vector:\")\n",
        "print(max_log_posterior_vector, \"\\n\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It also provides methods for computing the error estimates of all parameters at an input sigma confidence limit, which\n",
        "can be returned at the values of the parameters including their errors or the size of the errors on each parameter:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "vector_at_upper_sigma = samples.vector_at_upper_sigma(sigma=3.0)\n",
        "vector_at_lower_sigma = samples.vector_at_lower_sigma(sigma=3.0)\n",
        "\n",
        "print(\"Upper Parameter values w/ error (at 3.0 sigma confidence):\")\n",
        "print(vector_at_upper_sigma)\n",
        "print(\"lower Parameter values w/ errors (at 3.0 sigma confidence):\")\n",
        "print(vector_at_lower_sigma, \"\\n\")\n",
        "\n",
        "error_vector_at_upper_sigma = samples.error_vector_at_upper_sigma(sigma=3.0)\n",
        "error_vector_at_lower_sigma = samples.error_vector_at_lower_sigma(sigma=3.0)\n",
        "\n",
        "print(\"Upper Error values (at 3.0 sigma confidence):\")\n",
        "print(error_vector_at_upper_sigma)\n",
        "print(\"lower Error values (at 3.0 sigma confidence):\")\n",
        "print(error_vector_at_lower_sigma, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results vectors return the results as a list, which means you need to know the parameter ordering. The list of\n",
        "parameter names are available as a property of the *Samples*, as are parameter labels which can be used for labeling\n",
        "figures:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(samples.parameter_names)\n",
        "print(samples.parameter_labels)\n",
        "print(\"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results can instead be returned as an instance, which is an instance of the model using the Python classes used to\n",
        "compose it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "max_log_likelihood_instance = samples.max_log_likelihood_instance\n",
        "\n",
        "print(\"Max Log Likelihood Gaussian Instance:\")\n",
        "print(\"Centre = \", max_log_likelihood_instance.centre)\n",
        "print(\"Intensity = \", max_log_likelihood_instance.intensity)\n",
        "print(\"Sigma = \", max_log_likelihood_instance.sigma, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For our example problem of fitting a 1D Gaussian profile, this makes it straight forward to plot the maximum\n",
        "likelihood model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_data = samples.max_log_likelihood_instance.line_from_xvalues(\n",
        "    xvalues=np.arange(data.shape[0])\n",
        ")\n",
        "\n",
        "plt.plot(range(data.shape[0]), data)\n",
        "plt.plot(range(data.shape[0]), model_data)\n",
        "plt.title(\"Illustrative model fit to 1D Gaussian profile data.\")\n",
        "plt.xlabel(\"x values of profile\")\n",
        "plt.ylabel(\"Profile intensity\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All methods above are available as an instance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "median_pdf_instance = samples.median_pdf_instance\n",
        "instance_at_upper_sigma = samples.instance_at_upper_sigma\n",
        "instance_at_lower_sigma = samples.instance_at_lower_sigma\n",
        "error_instance_at_upper_sigma = samples.error_instance_at_upper_sigma\n",
        "error_instance_at_lower_sigma = samples.error_instance_at_lower_sigma"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "An instance of any accepted sample can be created:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "instance = samples.instance_from_sample_index(sample_index=500)\n",
        "print(\"Gaussian Instance of sample 5000:\")\n",
        "print(\"Centre = \", instance.centre)\n",
        "print(\"Intensity = \", instance.intensity)\n",
        "print(\"Sigma = \", instance.sigma, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If a nested sampling *non-linear search* is used, the evidence of the model is also available which enables Bayesian\n",
        "model comparison to be performed (given we are using Emcee, which is not a nested sampling algorithm, the log evidence \n",
        "is None).:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "log_evidence = samples.log_evidence"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At this point, you might be wondering what else the results contains - pretty much everything we discussed above was a\n",
        "part of its *samples* property! For projects which use **PyAutoFit**'s phase API (see the howtofit tutrials), the \n",
        "*Results* object can be extended to include model-specific results.\n",
        "\n",
        "For example, we may extend the results of our 1D Gaussian example to include properties containing the maximum\n",
        "log likelihood of the summed model data and for every individual profile in the model.\n",
        "\n",
        "(The commented out functions below are llustrative of the API we can create, but do not work in this example given we \n",
        "are not using the phase API.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# max_log_likelihood_line = results.max_log_likelihood_line\n",
        "# max_log_likelihood_line_list = results.max_log_likelihood_line_list"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}