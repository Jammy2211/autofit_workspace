{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from astropy.io import fits\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from autoconf import conf\n",
        "import autofit as af\n",
        "from autofit_workspace.examples.complex import model as m\n",
        "from autofit_workspace.examples.complex import analysis as a\n",
        "\n",
        "\"\"\"\n",
        "__Example: Result__\n",
        "\n",
        "In this example, we'll repeat the fit performed in 'fit.py' of 1D data of a Gaussian + Exponential profile with 1D line \n",
        "data using the  non-linear  search emcee and inspect the *Result* object that is returned in detail.\n",
        "\n",
        "If you haven't already, you should checkout the files 'example/model.py','example/analysis.py' and 'example/fit.py' to \n",
        "see how the fit is performed by the code below. The first section of code below is simply repeating the commands in\n",
        "'example/fit.py', so feel free to skip over it until you his the __Result__ section.\n",
        "\n",
        "The attributes of the Result object are described in 'examples/simple/result.py'. This example will not cover the \n",
        "attributes in full, and instead only focus on how the use of a more complex model changes the Result object.\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Paths__\n",
        "\n",
        "Setup the path to the autofit_workspace, using a relative directory name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "workspace_path = \"{}/../..\".format(os.path.dirname(os.path.realpath(__file__)))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use this path to explicitly set the config path and output path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "conf.instance = conf.Config(\n",
        "    config_path=f\"{workspace_path}/config\", output_path=f\"{workspace_path}/output\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Data__\n",
        "\n",
        "First, lets load our data of a 1D Gaussian + Exponential, which we'll plot before we perform the model-fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = f\"{workspace_path}/dataset/gaussian_x1__exponential_x1\"\n",
        "\n",
        "data_hdu_list = fits.open(f\"{dataset_path}/data.fits\")\n",
        "data = np.array(data_hdu_list[0].data)\n",
        "\n",
        "noise_map_hdu_list = fits.open(f\"{dataset_path}/noise_map.fits\")\n",
        "noise_map = np.array(noise_map_hdu_list[0].data)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "Next, we create our model, which in this case corresponds to a Gaussian + Exponential. In model.py, you will have\n",
        "noted the Gaussian has 3 parameters (centre, intensity and sigma) and Exponential 3 parameters (centre, intensity and\n",
        "rate). These are the free parameters of our model that the non-linear search fits for, meaning the non-linear\n",
        "parameter space has dimensionality = 6.\n",
        "\n",
        "In the simple example tutorial, we used a PriorModel to create the model of the Gaussian. PriorModels cannot be used to\n",
        "compose models from multiple model components and for this example we must instead use the CollectionPriorModel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = af.CollectionPriorModel(gaussian=m.Gaussian, exponential=m.Exponential)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checkout 'autofit_workspace/config/json_priors' - this config file defines the default priors of all our model\n",
        "components. However, we can overwrite priors before running the non-linear search as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model.gaussian.centre = af.UniformPrior(lower_limit=0.0, upper_limit=100.0)\n",
        "model.gaussian.intensity = af.UniformPrior(lower_limit=0.0, upper_limit=1e2)\n",
        "model.gaussian.sigma = af.UniformPrior(lower_limit=0.0, upper_limit=30.0)\n",
        "model.exponential.centre = af.UniformPrior(lower_limit=0.0, upper_limit=100.0)\n",
        "model.exponential.intensity = af.UniformPrior(lower_limit=0.0, upper_limit=1e2)\n",
        "model.exponential.rate = af.UniformPrior(lower_limit=0.0, upper_limit=10.0)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "We now set up our Analysis, using the class described in 'analysis.py'. The analysis describes how given an instance\n",
        "of our model (a Gaussian + Exponential) we fit the data and return a log likelihood value. For this simple example,\n",
        "we only have to pass it the data and its noise-map."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = a.Analysis(data=data, noise_map=noise_map)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the non-linear object for emcee and perform the fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "emcee = af.Emcee(\n",
        "    nwalkers=50,\n",
        "    nsteps=2000,\n",
        "    initialize_method=\"ball\",\n",
        "    initialize_ball_lower_limit=0.49,\n",
        "    initialize_ball_upper_limit=0.51,\n",
        "    auto_correlation_check_for_convergence=True,\n",
        "    auto_correlation_check_size=100,\n",
        "    auto_correlation_required_length=50,\n",
        "    auto_correlation_change_threshold=0.01,\n",
        "    number_of_cores=1,\n",
        ")\n",
        "\n",
        "result = emcee.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__RESULT__\n",
        "\n",
        "Here, we'll look in detail at how the information contained in the result changes when we fit a more complex model. If\n",
        "you are unfamiliar with the result object, first read through 'examples/simple/result.py'.\n",
        "\n",
        "First, we can note that the parameters list of lists now has 6 entries in the parameters column, given the \n",
        "dimensionality of the model has increased from N=3 to N=6."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples = result.samples\n",
        "print(\"All Parameters:\")\n",
        "print(samples.parameters)\n",
        "print(\"Sample 10's sixth parameter value (Exponential -> rate)\")\n",
        "print(samples.parameters[9][5], \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The vectors containing models have the same meaning as before, but they are also now of size 6 given the increase in\n",
        "model complexity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Result and Error Vectors:\")\n",
        "print(samples.median_pdf_vector)\n",
        "print(samples.max_log_likelihood_vector)\n",
        "print(samples.max_log_posterior_vector)\n",
        "print(samples.vector_at_upper_sigma(sigma=3.0))\n",
        "print(samples.vector_at_lower_sigma(sigma=3.0))\n",
        "print(samples.error_vector_at_upper_sigma(sigma=3.0))\n",
        "print(samples.error_vector_at_lower_sigma(sigma=3.0), \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The parameter names and labels now contain 6 entries, including the Exponential class that was not included in the\n",
        "simple model example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(samples.parameter_names)\n",
        "print(samples.parameter_labels)\n",
        "print(\"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When we return a result as an instance, it provides us with instances of the model using the Python classes used to\n",
        "compose it. Because our fit uses a CollectionPriorModel (as opposed to a PriorModel in the simple example) the instance\n",
        "returned a dictionary named acoording to the names given to the CollectionPriorModel, which above were 'gaussian' and\n",
        "'exponential'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "max_log_likelihood_instance = samples.max_log_likelihood_instance\n",
        "\n",
        "print(\"Max Log Likelihood Gaussian Instance:\")\n",
        "print(\"Centre = \", max_log_likelihood_instance.gaussian.centre)\n",
        "print(\"Intensity = \", max_log_likelihood_instance.gaussian.intensity)\n",
        "print(\"Sigma = \", max_log_likelihood_instance.gaussian.sigma, \"\\n\")\n",
        "print(\"Max Log Likelihood Exponential Instance:\")\n",
        "print(\"Centre = \", max_log_likelihood_instance.exponential.centre)\n",
        "print(\"Intensity = \", max_log_likelihood_instance.exponential.intensity)\n",
        "print(\"Sigma = \", max_log_likelihood_instance.exponential.rate, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For our example problem of fitting a 1D Gaussian + Exponential profile, this makes it straight forward to plot \n",
        "the maximum likelihood model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_gaussian = max_log_likelihood_instance.gaussian.line_from_xvalues(xvalues=np.arange(data.shape[0]))\n",
        "model_exponential = max_log_likelihood_instance.exponential.line_from_xvalues(xvalues=np.arange(data.shape[0]))\n",
        "model_data = model_gaussian + model_exponential\n",
        "\n",
        "plt.plot(range(data.shape[0]), data)\n",
        "plt.plot(range(data.shape[0]), model_data)\n",
        "plt.plot(range(data.shape[0]), model_gaussian, '--')\n",
        "plt.plot(range(data.shape[0]), model_exponential, '--')\n",
        "plt.title(\"Illustrative model fit to 1D Gaussian + Exponential profile data.\")\n",
        "plt.xlabel(\"x values of profile\")\n",
        "plt.ylabel(\"Profile intensity\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All methods which give instances give us the same instance of a CollectionPriorModel:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(samples.median_pdf_instance)\n",
        "print(samples.instance_at_upper_sigma)\n",
        "print(samples.instance_at_lower_sigma)\n",
        "print(samples.error_instance_at_upper_sigma)\n",
        "print(samples.error_instance_at_lower_sigma)\n",
        "print(samples.instance_from_sample_index(sample_index=500))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So that is that - adding model complexity doesn't change a whole lot about the Result object, other than the switch\n",
        "to CollectionPriorModels meaning that our instances now have named entries.\n",
        "\n",
        "The take home point should be that when you name your model components, you should make sure to give them descriptive\n",
        "and information names that make the use of a result object clear and intuitive!"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}