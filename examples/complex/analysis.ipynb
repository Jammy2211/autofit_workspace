{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import autofit as af\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# The 'analysis.py' module contains the dataset and log likelihood function which given a model instance (set up by\n",
        "# the non-linear search) fits the dataset and returns the log likelihood of that model.\n",
        "\n",
        "class Analysis(af.Analysis):\n",
        "\n",
        "    # In this example the Analysis only contains the data and noise-map. It can be easily extended however, for more\n",
        "    # complex data-sets and model fitting problems.\n",
        "\n",
        "    def __init__(self, data, noise_map):\n",
        "\n",
        "        self.data = data\n",
        "        self.noise_map = noise_map\n",
        "\n",
        "    # In the log_likelihood_function function below, 'instance' is an instance of our model, which in this example is\n",
        "    # an instance of the Gaussian class and Exponential class in 'model.py'. Their parameters are set via the\n",
        "    # non-linear search. This gives us the instance of the model we need to fit our data!\n",
        "\n",
        "    def log_likelihood_function(self, instance):\n",
        "        \"\"\"\n",
        "        Determine the log likelihood of a fit of multiple profiles to the dataset.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        instance : af.CollectionPriorModel\n",
        "            The model instances of the profiles.\n",
        "\n",
        "        Returnsn\n",
        "        -------\n",
        "        fit : Fit.log_likelihood\n",
        "            The log likelihood value indicating how well this model fit the dataset.\n",
        "        \"\"\"\n",
        "\n",
        "        # The 'instance' that comes into this method is a CollectionPriorModel. It contains instances of every class\n",
        "        # we instantiated it with, where each instance is named following the names given to the CollectionPriorModel,\n",
        "        # which in this example is a Gaussian (with name 'gaussian) and Exponential (with name 'exponential'):\n",
        "\n",
        "        # print(\"Gaussian Instance:\")\n",
        "        # print(\"Centre = \", instance.gaussian.centre)\n",
        "        # print(\"Intensity = \", instance.gaussian.intensity)\n",
        "        # print(\"Sigma = \", instance.gaussian.sigma)\n",
        "\n",
        "        # print(\"Exponential Instance:\")\n",
        "        # print(\"Centre = \", instance.exponential.centre)\n",
        "        # print(\"Intensity = \", instance.exponential.intensity)\n",
        "        # print(\"Rate = \", instance.exponential.rate)\n",
        "\n",
        "        # Get the range of x-values the data is defined on, to evaluate the model of the profiles.\n",
        "        xvalues = np.arange(self.data.shape[0])\n",
        "\n",
        "        # The simplest way to create the summed profile is to add the profile of each model component. If we\n",
        "        # know we are going to fit a Gaussian + Exponential we can do the following:\n",
        "\n",
        "        # model_data_gaussian = instance.gaussian.line_from_xvalues(xvalues=xvalues)\n",
        "        # model_data_exponential = instance.exponential.line_from_xvalues(xvalues=xvalues)\n",
        "        # model_data = model_data_gaussian + model_data_exponential\n",
        "\n",
        "        # However, this does not work if we change our model components. However, the *instance* variable is a list of\n",
        "        # our model components. We can iterate over this list, calling their line_from_xvalues and summing the result\n",
        "        # to compute the summed profile of any model.\n",
        "\n",
        "        # Use these xvalues to create model data of our profiles.\n",
        "        model_data = sum([line.line_from_xvalues(xvalues=xvalues) for line in instance])\n",
        "\n",
        "        # Fit the model profile data to the observed data, computing the residuals and chi-squareds.\n",
        "        residual_map = self.data - model_data\n",
        "        chi_squared_map = (residual_map / self.noise_map) ** 2.0\n",
        "        log_likelihood = -0.5 * sum(chi_squared_map)\n",
        "\n",
        "        return log_likelihood\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}