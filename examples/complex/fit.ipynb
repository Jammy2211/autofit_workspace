{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from astropy.io import fits\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from autoconf import conf\n",
        "import autofit as af\n",
        "from autofit_workspace.examples.complex import model as m\n",
        "from autofit_workspace.examples.complex import analysis as a"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example, we'll fit 1D data of a Gaussian and Exponential profile with a 1D Gaussian + Exponential model using \n",
        "the non-linear searches emcee and Dynesty.\n",
        "\n",
        "If you haven't already, you should checkout the files 'example/model.py' and 'example/analysis.py' to see how we have\n",
        "provided PyAutoFit with the necessary information on our model, data and log likelihood function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Paths__\n",
        "\n",
        "Setup the path to the autofit_workspace, using a relative directory name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "workspace_path = \"{}/../..\".format(os.path.dirname(os.path.realpath(__file__)))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use this path to explicitly set the config path and output path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "conf.instance = conf.Config(\n",
        "    config_path=f\"{workspace_path}/config\", output_path=f\"{workspace_path}/output\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Data__\n",
        "\n",
        "First, lets load our data of a 1D Gaussian + Exponential, which we'll plot before we perform the model-fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = f\"{workspace_path}/dataset/gaussian_x1__exponential_x1\"\n",
        "\n",
        "data_hdu_list = fits.open(f\"{dataset_path}/data.fits\")\n",
        "data = np.array(data_hdu_list[0].data)\n",
        "\n",
        "noise_map_hdu_list = fits.open(f\"{dataset_path}/noise_map.fits\")\n",
        "noise_map = np.array(noise_map_hdu_list[0].data)\n",
        "\n",
        "plt.plot(range(data.shape[0]), data)\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "Next, we create our model, which in this case corresponds to a Gaussian + Exponential. In model.py, you will have\n",
        "noted the Gaussian has 3 parameters (centre, intensity and sigma) and Exponential 3 parameters (centre, intensity and\n",
        "rate). These are the free parameters of our model that the non-linear search fits for, meaning the non-linear\n",
        "parameter space has dimensionality = 6.\n",
        "\n",
        "In the simple example tutorial, we used a PriorModel to create the model of the Gaussian. PriorModels cannot be used to\n",
        "compose models from multiple model components and for this example we must instead use the CollectionPriorModel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = af.CollectionPriorModel(gaussian=m.Gaussian, exponential=m.Exponential)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can again customize the priors of our model used by the non-linear search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model.gaussian.centre = af.UniformPrior(lower_limit=0.0, upper_limit=100.0)\n",
        "model.gaussian.intensity = af.UniformPrior(lower_limit=0.0, upper_limit=1e2)\n",
        "model.gaussian.sigma = af.UniformPrior(lower_limit=0.0, upper_limit=30.0)\n",
        "model.exponential.centre = af.UniformPrior(lower_limit=0.0, upper_limit=100.0)\n",
        "model.exponential.intensity = af.UniformPrior(lower_limit=0.0, upper_limit=1e2)\n",
        "model.exponential.rate = af.UniformPrior(lower_limit=0.0, upper_limit=10.0)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Above, we named our model-components: we called the Gaussian component 'gaussian' and Exponential component\n",
        "'exponential'. We could have chosen anything for these names, as shown by the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_custom_names = af.CollectionPriorModel(rich=m.Gaussian, james=m.Exponential)\n",
        "\n",
        "model_custom_names.rich.centre = af.UniformPrior(lower_limit=0.0, upper_limit=100.0)\n",
        "model_custom_names.rich.intensity = af.UniformPrior(lower_limit=0.0, upper_limit=1e2)\n",
        "model_custom_names.rich.sigma = af.UniformPrior(lower_limit=0.0, upper_limit=30.0)\n",
        "model_custom_names.james.centre = af.UniformPrior(lower_limit=0.0, upper_limit=100.0)\n",
        "model_custom_names.james.intensity = af.UniformPrior(lower_limit=0.0, upper_limit=1e2)\n",
        "model_custom_names.james.rate = af.UniformPrior(lower_limit=0.0, upper_limit=10.0)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The naming of model components is important - as these names will are adotped by the instance pass to the Analysis\n",
        "class and the results returned by the non-linear search.\n",
        "\n",
        "We'll use the 'model' variable from here on, with the more sensible names of 'gaussian' and 'exponential'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "We now set up our Analysis, using the class described in 'analysis.py'. The analysis describes how given an instance\n",
        "of our model (a Gaussian + Exponential) we fit the data and return a log likelihood value. For this simple example,\n",
        "we only have to pass it the data and its noise-map."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = a.Analysis(data=data, noise_map=noise_map)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#####################\n",
        "###### DYNESTY ######\n",
        "#####################\n",
        "\n",
        "We finally choose and set up our non-linear search. We'll first fit the data with the nested sampling algorithm\n",
        "Dynesty. Below, we manually specify all of the Dynesty settings, however if we omitted them the default values\n",
        "found in the config file 'config/non_linear/Dynesty.ini' would be used.\n",
        "\n",
        "For a full description of Dynesty checkout its Github and documentation webpages:\n",
        "\n",
        "https://github.com/joshspeagle/dynesty\n",
        "https://dynesty.readthedocs.io/en/latest/index.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dynesty = af.DynestyStatic(\n",
        "    n_live_points=150,\n",
        "    bound=\"multi\",\n",
        "    sample=\"auto\",\n",
        "    bootstrap=0,\n",
        "    enlarge=-1,\n",
        "    update_interval=-1.0,\n",
        "    vol_dec=0.5,\n",
        "    vol_check=2.0,\n",
        "    walks=25,\n",
        "    facc=0.5,\n",
        "    slices=5,\n",
        "    fmove=0.9,\n",
        "    max_move=100,\n",
        "    iterations_per_update=500,\n",
        "    number_of_cores=1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To perform the fit with Dynesty, we pass it our model and analysis and we're good to go!\n",
        "\n",
        "Checkout the folder 'autofit_workspace/output/dynestystatic', where the non-linear search results, visualizaion and\n",
        "information can be found."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result = dynesty.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "The result object returned by the fit provides information on the results of the non-linear search. Lets use it to\n",
        "compare the maximum log likelihood Gaussian + Exponential model to the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "instance = result.max_log_likelihood_instance\n",
        "\n",
        "model_gaussian = instance.gaussian.line_from_xvalues(xvalues=np.arange(data.shape[0]))\n",
        "model_exponential = instance.exponential.line_from_xvalues(xvalues=np.arange(data.shape[0]))\n",
        "model_data = model_gaussian + model_exponential\n",
        "\n",
        "plt.plot(range(data.shape[0]), data)\n",
        "plt.plot(range(data.shape[0]), model_data)\n",
        "plt.plot(range(data.shape[0]), model_gaussian, '--')\n",
        "plt.plot(range(data.shape[0]), model_exponential, '--')\n",
        "plt.title(\"Illustrative model fit to 1D Gaussian + Exponential profile data.\")\n",
        "plt.xlabel(\"x values of profile\")\n",
        "plt.ylabel(\"Profile intensity\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We discuss in more detail how to use a results object in the files 'autofit_workspace/example/results'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#################\n",
        "##### Emcee #####\n",
        "#################\n",
        "\n",
        "To use a different non-linear we simply use call a different search from PyAutoFit, passing it the same the model\n",
        "and analysis as we did before to perform the fit. Below, we fit the same dataset using the MCMC sampler Emcee.\n",
        "Again, we manually specify all of the Emcee settings, however if they were omitted the values found in the config\n",
        "file 'config/non_linear/Emcee.ini' would be used instead.\n",
        "\n",
        "For a full description of Emcee, checkout its Github and readthedocs webpages:\n",
        "\n",
        "https://github.com/dfm/emcee\n",
        "https://emcee.readthedocs.io/en/stable/\n",
        "\n",
        "**PyAutoFit** extends **emcee** by providing an option to check the auto-correlation length of the samples\n",
        "during the run and terminating sampling early if these meet a specified threshold. See this page\n",
        "(https://emcee.readthedocs.io/en/stable/tutorials/autocorr/#autocorr) for a description of how this is implemented."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "emcee = af.Emcee(\n",
        "    nwalkers=50,\n",
        "    nsteps=2000,\n",
        "    initialize_method=\"ball\",\n",
        "    initialize_ball_lower_limit=0.49,\n",
        "    initialize_ball_upper_limit=0.51,\n",
        "    auto_correlation_check_for_convergence=True,\n",
        "    auto_correlation_check_size=100,\n",
        "    auto_correlation_required_length=50,\n",
        "    auto_correlation_change_threshold=0.01,\n",
        "    number_of_cores=1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result = emcee.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "The result object returned by Emcee's fit is similar in structure to the Dynesty result above - it again provides\n",
        "us with the maximum log likelihood instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "instance = result.max_log_likelihood_instance\n",
        "\n",
        "model_gaussian = instance.gaussian.line_from_xvalues(xvalues=np.arange(data.shape[0]))\n",
        "model_exponential = instance.exponential.line_from_xvalues(xvalues=np.arange(data.shape[0]))\n",
        "model_data = model_gaussian + model_exponential\n",
        "\n",
        "plt.plot(range(data.shape[0]), data)\n",
        "plt.plot(range(data.shape[0]), model_data)\n",
        "plt.plot(range(data.shape[0]), model_gaussian, '--')\n",
        "plt.plot(range(data.shape[0]), model_exponential, '--')\n",
        "plt.title(\"Illustrative model fit to 1D Gaussian + Exponential profile data.\")\n",
        "plt.xlabel(\"x values of profile\")\n",
        "plt.ylabel(\"Profile intensity\")\n",
        "plt.savefig(f\"{workspace_path}/toy_model_fit_x2.png\", bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##########################\n",
        "##### Other Samplers #####\n",
        "##########################\n",
        "\n",
        "Checkout ? for all of the non-linear searches available in PyAutoFit."
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}