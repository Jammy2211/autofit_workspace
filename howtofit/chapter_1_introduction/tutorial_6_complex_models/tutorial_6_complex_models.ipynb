{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Complex Models__\n",
        "\n",
        "Up to now, we've fitted a very simple model - a single 1D Gaussian with just 3 free parameters. In this tutorial,\n",
        "we'll look at how PyAutoFit allows us to compose and fit models of arbitrary complexity.\n",
        "\n",
        "To begin, you should check out the module 'tutorial_6_complex_models/model/profiles.py'. In previous tutorials this\n",
        "module was called 'gaussian.py' and it contained only the Gaussian class we fitted to data. The module now includes\n",
        "a second profile, 'Exponential', which like the Gaussian class is a model-component that can be fitted to data.\n",
        "\n",
        "Up to now, our data has always been generated using a single Gaussian profile. Thus, we have only needed to fit\n",
        "it with a single Gaussian. In this tutorial, our dataset is now a superpositions of multiple profiles (e.g a\n",
        "Gaussians + Exponential). The models we compose and fit are therefore composed of multiple profiles, such that when we\n",
        "generate the model-data we generate it as the sum of all individual profiles in our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from autoconf import conf\n",
        "import autofit as af\n",
        "import numpy as np\n",
        "\n",
        "from howtofit.chapter_1_introduction.tutorial_6_complex_models.src.model import profiles\n",
        "from howtofit.chapter_1_introduction.tutorial_6_complex_models.src.dataset import (\n",
        "    dataset as ds,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You need to change the path below to the workspace directory so we can load the dataset/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "workspace_path = \"/home/jammy/PycharmProjects/PyAuto/autofit_workspace\"\n",
        "chapter_path = f\"{workspace_path}/howtofit/chapter_1_introduction\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setup the configs as we did in the previous tutorial, as well as the output folder for our non-linear search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "conf.instance = conf.Config(\n",
        "    config_path=f\"{workspace_path}/config\",\n",
        "    output_path=f\"{workspace_path}/output/howtofit\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets quickly recap tutorial 1, where using PriorModels we created a Gaussian as a model component and used it to map a\n",
        "list of parameters to a model instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = af.PriorModel(profiles.Gaussian)\n",
        "\n",
        "print(\"PriorModel Gaussian object: \\n\")\n",
        "print(model)\n",
        "\n",
        "instance = model.instance_from_vector(vector=[0.1, 0.2, 0.3])\n",
        "\n",
        "print(\"Model Instance: \\n\")\n",
        "print(instance)\n",
        "\n",
        "print(\"Instance Parameters \\n\")\n",
        "print(\"x = \", instance.centre)\n",
        "print(\"intensity = \", instance.intensity)\n",
        "print(\"sigma = \", instance.sigma)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defining a model using multiple model components is straight forward in PyAutoFit, using a CollectionPriorModel\n",
        "object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = af.CollectionPriorModel(\n",
        "    gaussian=profiles.Gaussian, exponential=profiles.Exponential\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A CollectionPriorModel behaves like a PriorModel but contains a collection of model components. For example, it can\n",
        "create a model instance by mapping a list of parameters, which in this case is 6 (3 for the Gaussian [centre,\n",
        "intensity, sigma] and 3 for the Exponential [centre, intensity, rate])."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "instance = model.instance_from_vector(vector=[0.1, 0.2, 0.3, 0.4, 0.5, 0.01])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This instance contains each of the model components we defined above, using the input argument name of the\n",
        "CollectionoPriorModel to define the attributes in the instance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Instance Parameters \\n\")\n",
        "print(\"x (Gaussian) = \", instance.gaussian.centre)\n",
        "print(\"intensity (Gaussian) = \", instance.gaussian.intensity)\n",
        "print(\"sigma (Gaussian) = \", instance.gaussian.sigma)\n",
        "print(\"x (Exponential) = \", instance.exponential.centre)\n",
        "print(\"intensity (Exponential) = \", instance.exponential.intensity)\n",
        "print(\"sigma (Exponential) = \", instance.exponential.rate)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can call the components of a CollectionPriorModel whatever we want, and the mapped instance will use those names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_custom_names = af.CollectionPriorModel(\n",
        "    james=profiles.Gaussian, rich=profiles.Exponential\n",
        ")\n",
        "\n",
        "instance = model_custom_names.instance_from_vector(\n",
        "    vector=[0.1, 0.2, 0.3, 0.4, 0.5, 0.01]\n",
        ")\n",
        "\n",
        "print(\"Instance Parameters \\n\")\n",
        "print(\"x (Gaussian) = \", instance.james.centre)\n",
        "print(\"intensity (Gaussian) = \", instance.james.intensity)\n",
        "print(\"sigma (Gaussian) = \", instance.james.sigma)\n",
        "print(\"x (Exponential) = \", instance.rich.centre)\n",
        "print(\"intensity (Exponential) = \", instance.rich.intensity)\n",
        "print(\"sigma (Exponential) = \", instance.rich.rate)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can create a model composed of multiple components, lets fit it to a dataset. To do this, we updated this \n",
        "tutorial's phase package, spefically its 'Analysis' class such that it creates model data as a super position of all of \n",
        "the model's individual profiles. For example, in the model above, the model data is the sum of the Gaussian's \n",
        "individual profile and Exponential's individual profile.\n",
        "\n",
        "Checkout 'phase.py' and 'analysis.py' now, for a description of how this has been implemented.\n",
        "\n",
        "Lets create the phase and run it to fit a dataset which was specifically generated as a sum of a Gaussian and\n",
        "Exponential profile."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = f\"{chapter_path}/dataset/gaussian_x1_exponential_x1\"\n",
        "\n",
        "dataset = ds.Dataset.from_fits(\n",
        "    data_path=f\"{dataset_path}/data.fits\",\n",
        "    noise_map_path=f\"{dataset_path}/noise_map.fits\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We again need to create a mask for our data. In this exmample, we'll omit actual masking of the dataset, but still\n",
        "need to define a mask to pass the 'phase.run' method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = np.full(fill_value=False, shape=dataset.data.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets now perform the fit using our model which is composed of two profiles. You'll note that the Emcee\n",
        "dimensionality has increased from N=3 to N=6, given that we are now fitting two profiles each with 3 free parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from howtofit.chapter_1_introduction.tutorial_6_complex_models.src.phase import (\n",
        "    phase as ph,\n",
        ")\n",
        "\n",
        "phase = ph.Phase(\n",
        "    phase_name=\"phase_t6_gaussian_x1_exponential_x1\",\n",
        "    profiles=af.CollectionPriorModel(\n",
        "        gaussian=profiles.Gaussian, exponential=profiles.Exponential\n",
        "    ),\n",
        "    search=af.Emcee(),\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"Emcee has begun running - checkout the autofit_workspace/howtofit/chapter_1_introduction/output/phase_t5_gaussian_x1_exponential_x1\"\n",
        "    \"folder for live output of the results.\"\n",
        "    \"This Jupyter notebook cell with progress once Emcee has completed - this could take a few minutes!\"\n",
        ")\n",
        "\n",
        "phase.run(dataset=dataset, mask=mask)\n",
        "\n",
        "print(\"Emcee has finished run - you may now continue the notebook.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Quickly inspect the results of this fit, which you may have noticed takes a bit longer to run than the fits performed\n",
        "in previous tutorials. This is because the dimensionality of the model we are fitted increased from 3 to 6.\n",
        "\n",
        "With the CollectionPriorModel, PyAutoFit gives us all the tools we need to compose and fit any model imaginable!\n",
        "Lets fit a model composed of two Gaussians and and an Exponential, which will have a dimensionality of N=9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = f\"{chapter_path}/dataset/gaussian_x2_exponential_x1\"\n",
        "\n",
        "dataset = ds.Dataset.from_fits(\n",
        "    data_path=f\"{dataset_path}/data.fits\",\n",
        "    noise_map_path=f\"{dataset_path}/noise_map.fits\",\n",
        ")\n",
        "\n",
        "phase = ph.Phase(\n",
        "    phase_name=\"phase_t6_gaussian_x2_exponential_x1\",\n",
        "    profiles=af.CollectionPriorModel(\n",
        "        gaussian_0=profiles.Gaussian,\n",
        "        gaussian_1=profiles.Gaussian,\n",
        "        exponential=profiles.Exponential,\n",
        "    ),\n",
        "    search=af.Emcee(),\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"Emcee has begun running - checkout the autofit_workspace/howtofit/chapter_1_introduction/output/phase_t5_gaussian_x2_exponential_x1\"\n",
        "    \"folder for live output of the results.\"\n",
        "    \"This Jupyter notebook cell with progress once Emcee has completed - this could take a few minutes!\"\n",
        ")\n",
        "\n",
        "phase.run(dataset=dataset, mask=mask)\n",
        "\n",
        "print(\"Emcee has finished run - you may now continue the notebook.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can fully custommize the model that we fit. Lets suppose we have a dataset that consists of three Gaussian line\n",
        "profiles, but we also know the following information about the dataset:\n",
        "\n",
        "- All 3 Gaussians are centrally aligned.\n",
        "- The sigma of one Gaussian is equal to 1.0.\n",
        "\n",
        "We can edit our CollectionPriorModel to meet these constraints accordingly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = af.CollectionPriorModel(\n",
        "    gaussian_0=profiles.Gaussian,\n",
        "    gaussian_1=profiles.Gaussian,\n",
        "    gaussian_2=profiles.Gaussian,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This aligns the centres of the 3 Gaussians, reducing the dimensionality of the model from N=9 to N=7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model.gaussian_0.centre = model.gaussian_1.centre\n",
        "model.gaussian_1.centre = model.gaussian_2.centre"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This fixes the sigma value of one Gaussian to 1.0, further reducing the dimensionality from N=7 to N=6."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model.gaussian_0.sigma = 1.0"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now fit this model using a phase as per usual."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = f\"{chapter_path}/dataset/gaussian_x3/\"\n",
        "\n",
        "dataset = ds.Dataset.from_fits(\n",
        "    data_path=f\"{dataset_path}/data.fits\",\n",
        "    noise_map_path=f\"{dataset_path}/noise_map.fits\",\n",
        ")\n",
        "\n",
        "phase = ph.Phase(phase_name=\"phase_t6_gaussian_x3\", profiles=model, search=af.Emcee())\n",
        "\n",
        "print(\n",
        "    \"Emcee has begun running - checkout the autofit_workspace/howtofit/chapter_1_introduction/output/phase_t5_gaussian_x3\"\n",
        "    \"folder for live output of the results.\"\n",
        "    \"This Jupyter notebook cell with progress once Emcee has completed - this could take a few minutes!\"\n",
        ")\n",
        "\n",
        "phase.run(dataset=dataset, mask=mask)\n",
        "\n",
        "print(\"Emcee has finished run - you may now continue the notebook.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And with that, we are complete. In this tutorial, we learned how to compose complex models in PyAutoFit and adjust our\n",
        "'phase.py' and 'analyis.py' modules to fit them. To end, you should think again in more detail about your model\n",
        "fitting problem:\n",
        "\n",
        "Are there many different model components you may wish to define and fit?\n",
        "Is your model-data the super position of many different model components, like the profiles in this tutorial?\n",
        "\n",
        "In this tutorial, all components of our model did the same thing - represent a 'line' of data. In your model, you may\n",
        "have model components that represent different parts of your model, which need to be combined in more complicated ways\n",
        "in order to create your model-fit. In such circumstances, the 'fit' method in your 'Analysis' class may be significantly\n",
        "more complex than the example shown in this tutorial. Nevertheless, you now have all the tools you need to define,\n",
        "compose and fit very complex models - there isn't much left for you to learn on your journey through PyAutoFit!"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}