{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#%%\n",
        "\"\"\"\n",
        "__Source Code__\n",
        "\n",
        "Up to now, all tutorials have been self contained. That is, the code used to define the model, analysis, run the\n",
        "non-linear search, load data and plot images were contained in the Jupyter notebooks or Python scritps you were run.\n",
        "\n",
        "For a real software developmet project, this code woulnd't be contained in one script, but instead make up the\n",
        "project's source code. In this tutorial, and every tutorial hereafter, we will set up our code as if it were\n",
        "an actual software project with a clearly defined source code library. This source code can be found in the folder\n",
        "'/autofit_workspace/howtofit/chapter_1_introduction/tutorial_4_source_code/src'.\n",
        "\n",
        "Check it out, and first note the directory structure of the source code, which is separated into 5 packages: 'dataset',\n",
        "'fit', 'model', 'plot' and 'phase'. This cleanly separates the different parts of the code which perform do different\n",
        "tasks and I recommend your model-fitting project close adopts this structure!\n",
        "\n",
        "For example, the code which handles the model is completely separate from the code which handles the analysis class.\n",
        "The model thus never interfaces directly with PyAutoFit, ensuring good code design by removing dependencies between\n",
        "parts of the code that do not need them! Its the same for the part of the code that stores data ('dataset')\n",
        "and fits a model to a dataset ('fit') - by keeping them separate its clear which part of the code do what task.\n",
        "\n",
        "This is a principle aspect of object oriented design and software engineering called 'separation of concerns' and all\n",
        "templates we provide in the HowToFit series will adhere to it.\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from autoconf import conf\n",
        "import autofit as af"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You need to change the path below to the workspace directory so we can load the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "workspace_path = \"/home/jammy/PycharmProjects/PyAuto/autofit_workspace\"\n",
        "chapter_path = f\"{workspace_path}/howtofit/chapter_1_introduction\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "conf.instance = conf.Config(\n",
        "    config_path=f\"{workspace_path}/config\",\n",
        "    output_path=f\"{workspace_path}/output/howtofit\",  # <- This sets up where the non-linear search's outputs go.\n",
        ")\n",
        "\n",
        "dataset_path = f\"{chapter_path}/dataset/gaussian_x1/\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To begin, checkout the 'data' package, which contains one module, 'dataset.py'. Whereas before we has arrays which\n",
        "separately contained the data and noise_map, from here on we'll combine them into a 'Dataset' class, which can be \n",
        "easily extended if our model-fitting problem has additional data components.\n",
        "\n",
        "We can use the Dataset's 'from_fits' method to load the dataset for the model-fit we will perform.\n",
        "\"\"\"\n",
        "\n",
        "from howtofit.chapter_1_introduction.tutorial_4_source_code.src.dataset import (\n",
        "    dataset as ds,\n",
        ")\n",
        "\n",
        "dataset = ds.Dataset.from_fits(\n",
        "    data_path=f\"{dataset_path}/data.fits\",\n",
        "    noise_map_path=f\"{dataset_path}/noise_map.fits\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Previously, we manually specified how to plot the dataset. These plotting functions are now in our source code, in the\n",
        "'plot' package - check them out now! You'll note we have separate modules for plotting lines (e.g. anything which is \n",
        "line, the data, a residual map, etc.), parts of the dataset or the results of a fit.\n",
        "\n",
        "You'll notice that the dataset plot functions take instances of the Dataset class. This means we don't have to manually\n",
        "specify which part of our data we want to pass to the function - just use the function that plots the data!\n",
        "\n",
        "Lets use a plot function to plot our data.\n",
        "\"\"\"\n",
        "\n",
        "from howtofit.chapter_1_introduction.tutorial_4_source_code.src.plot import (\n",
        "    dataset_plots,\n",
        ")\n",
        "\n",
        "dataset_plots.data(dataset=dataset)\n",
        "dataset_plots.noise_map(dataset=dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, look at the 'model' package, which contains the module 'gaussian.py'. This contains the Gaussian class we have\n",
        "used previous to compose the 1D Gaussian model that we fit.\n",
        "\n",
        "By packaging all the model components into a single package, this will make it straight forward to add new model\n",
        "components to the source code.\n",
        "\"\"\"\n",
        "\n",
        "from howtofit.chapter_1_introduction.tutorial_4_source_code.src.model import (\n",
        "    gaussian as g,\n",
        ")\n",
        "\n",
        "gaussian = g.Gaussian(centre=50.0, intensity=2.0, sigma=20.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, lets checkout the 'fit' package which contains the 'fit.py' module. This packages all the fitting methods we \n",
        "introduced in tutorial 2 into a single Fit class, making it straight forward to compute the residual map, chi-squared \n",
        "map, log likelihood and so forth. \n",
        "\n",
        "The fit plot functions take an instance of this Fit class, making it straight forward to plot the different components\n",
        "of the fit. Below, I used the Gaussian model above to illustrate how we can easily plot different aspects of a fit. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from howtofit.chapter_1_introduction.tutorial_4_source_code.src.plot import fit_plots\n",
        "from howtofit.chapter_1_introduction.tutorial_4_source_code.src.fit import fit as f\n",
        "\n",
        "model_data = gaussian.line_from_xvalues(xvalues=dataset.xvalues)\n",
        "\n",
        "fit = f.FitDataset(dataset=dataset, model_data=model_data)\n",
        "\n",
        "fit_plots.residual_map(fit=fit)\n",
        "fit_plots.normalized_residual_map(fit=fit)\n",
        "fit_plots.chi_squared_map(fit=fit)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we discussed in tutorial 2, the different steps of performing a fit (e.g. computing the residuals, the chi-squared,\n",
        "log likelihood, and so forth) are pretty much generic tasks performed by any model-fitting problem. \n",
        "\n",
        "Thus, you should literally be able to copy and paste the Fit class found in this tutorial (and future tutorials) and \n",
        "use them in your modeling software! I have made sure the class works for datasets of higher dimensionality (e.g. \n",
        "2D images or 3D datacubes)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We're finally ready to look at how our source code sets up the non-linear search and model-fit. Whereas before, we \n",
        "manually set up the model, analysis and non-linear search, from now on we're going to use PyAutoFits 'phase API' which\n",
        "uses the 'phase' package, which contains 3 modules: 'phase.py', 'analysis.py' and 'result.py'.\n",
        "\n",
        "At this point, you should open and inspect (in detail) these 3 source code files. These are the heart of any PyAutoFit \n",
        "model fit! \n",
        "\n",
        "An over view of each is as follows:\n",
        "\n",
        "phase.py -> contains the Phase class:\n",
        "\n",
        "    - Receives the model to be fitted (in this case a single Gaussian).\n",
        "    - Handles the directory structure of the output (in this example results are output to the folder\n",
        "      '/output/phase_example/'.\n",
        "    - Is passed the data when run, which is set up for the analysis.\n",
        "\n",
        "analysis.py -> contains the Analysis class (is a restructred version of the the previous tutorial's Analysis class):\n",
        "\n",
        "    - Prepares the dataset for fitting.\n",
        "    - Fits this dataset with a model instance to compute a log likelihood for every iteration of the non-linear search.\n",
        "\n",
        "result.py -> contains the Result class:\n",
        "\n",
        "    - Stores the Samples object containing information on the non-linear search's samples.\n",
        "    - Has functions to create the model image, residual map, chi-squared map and so forth of the maximum log likelihood \n",
        "      model etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Perform a non-linear search in PyAutoFit now only requires that we instantiate and run a Phase object. The Phase \n",
        "performs the following tasks (which we performed manually in the previous tutorial):\n",
        "\n",
        "    - Builds the model to be fitted and interfaces it with the non-linear search algorithm.\n",
        "    - Receives the data to be fitted and prepares it so the model can fit it.\n",
        "    - Contains the Analysis class that defines the log likelihood function.\n",
        "    - Returns the results. including the non-linear search's samples and the maximum likelihood fit.\n",
        "\n",
        "Lets instantiate and run a phase to, which reduces the take of perforing a model-fit in PyAutoFit to just two lines. \n",
        "The results are output to the path 'autofit_workspace/howtofit/chapter_1_introduction/output/phase_t4/emcee', which in \n",
        "contrast to the previous tutorial includes the phase name in the path structure.\n",
        "\"\"\"\n",
        "\n",
        "from howtofit.chapter_1_introduction.tutorial_4_source_code.src.phase import phase as ph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "phase = ph.Phase(\n",
        "    phase_name=\"phase_t4\", gaussian=af.PriorModel(g.Gaussian), search=af.Emcee()\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"Emcee has begun running - checkout the autofit_workspace/howtofit/chapter_1_introduction/output/phase_t4/emcee\"\n",
        "    \"folder for live output of the results.\"\n",
        "    \"This Jupyter notebook cell with progress once Emcee has completed - this could take a few minutes!\"\n",
        ")\n",
        "\n",
        "result = phase.run(dataset=dataset)\n",
        "\n",
        "print(\"Emcee has finished run - you may now continue the notebook.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The phase returns a Result object, just like the model-fit performed in the previous tutorial did. However, in\n",
        "'result.py' you'll have noted we extended the Results object to include a property containing an instance of the \n",
        "maximum likelihood fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.max_log_likelihood_fit)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The benefit of writing plot functions that take as input instances of class, specifically in this case the Fit class,\n",
        "is now clear. We can visualize our results by simply passing this instance to our plots!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_plots.model_data(fit=result.max_log_likelihood_fit)\n",
        "fit_plots.residual_map(fit=result.max_log_likelihood_fit)\n",
        "fit_plots.chi_squared_map(fit=result.max_log_likelihood_fit)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And with that, we have introduced the PyAutoFit phase API alongside an example project, which provides a template on\n",
        "how to structure model-fitting software. \n",
        "\n",
        "All of the remaining tutorials will be provided with a 'src' source code folder, and the functionality these tutorials\n",
        "describe will be reflected in the comments of the source code. At this point, you should be thinking about how you\n",
        "might wish to structure your model-fitting software!"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}