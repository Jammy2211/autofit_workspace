{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Example: Result__\n",
        "\n",
        "In this example, we'll repeat the fit performed in `fit.py` of 1D data of a `Gaussian` + Exponential profile with 1D line\n",
        "data using the  non-linear  search emcee and inspect the *Result* object that is returned in detail.\n",
        "\n",
        "If you haven't already, you should checkout the files `example/model.py`,`example/analysis.py` and `example/fit.py` to\n",
        "see how the fit is performed by the code below. The first section of code below is simply repeating the commands in\n",
        "`example/fit.py`, so feel free to skip over it until you his the `Result`'s section.\n",
        "\n",
        "The attributes of the Result object are described in `overview/simple/result.py`. This example will not cover the\n",
        "attributes in full, and instead only focus on how the use of a more complex model changes the Result object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import autofit as af\n",
        "import autofit.plot as aplt\n",
        "\n",
        "from os import path\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Data__\n",
        "\n",
        "Load data of a 1D `Gaussian` + 1D Exponential, by loading it from a .json file in the directory \n",
        "`autofit_workspace/dataset/`, which simulates the noisy data we fit (check it out to see how we simulate the \n",
        "data)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = path.join(\"dataset\", \"example_1d\", \"gaussian_x1__exponential_x1\")\n",
        "data = af.util.numpy_array_from_json(file_path=path.join(dataset_path, \"data.json\"))\n",
        "noise_map = af.util.numpy_array_from_json(\n",
        "    file_path=path.join(dataset_path, \"noise_map.json\")\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "Next, we create our model, which in this case corresponds to a `Gaussian` + Exponential.\n",
        " \n",
        "We use the `af.ex` package to create the `Gaussian` and `Exponential`, where `af.ex` stands for **PyAutoFit** \n",
        "example objects used in example scripts such as this one. \n",
        "\n",
        "The `Gaussian` and `Exponential` models below are identical to the 1D profiles used in the `fit.py` example script."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = af.Collection(gaussian=af.ex.Gaussian, exponential=af.ex.Exponential)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checkout `autofit_workspace/config/priors` - this config file defines the default priors of all our model\n",
        "components. However, we can overwrite priors before running the `NonLinearSearch` as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model.gaussian.centre = af.UniformPrior(lower_limit=0.0, upper_limit=100.0)\n",
        "model.gaussian.normalization = af.UniformPrior(lower_limit=0.0, upper_limit=1e2)\n",
        "model.gaussian.sigma = af.UniformPrior(lower_limit=0.0, upper_limit=30.0)\n",
        "model.exponential.centre = af.UniformPrior(lower_limit=0.0, upper_limit=100.0)\n",
        "model.exponential.normalization = af.UniformPrior(lower_limit=0.0, upper_limit=1e2)\n",
        "model.exponential.rate = af.UniformPrior(lower_limit=0.0, upper_limit=10.0)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "We now set up our `Analysis`, which describes how given an instance of our model (a Gaussian) we fit the data and \n",
        "return a log likelihood value. \n",
        "\n",
        "We use the `af.ex` package to create the `Analysis`, where `af.ex` stands for **PyAutoFit** example objects used\n",
        "in example scripts such as this one. \n",
        "\n",
        "The `Analysis` below is an identical to the one used in the `fit.py` example script."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = af.ex.Analysis(data=data, noise_map=noise_map)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now create the `Emcee` non-linear search and perform a model-fit to get the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Emcee(\n",
        "    nwalkers=50,\n",
        "    nsteps=1000,\n",
        "    initializer=af.InitializerBall(lower_limit=0.49, upper_limit=0.51),\n",
        "    auto_correlations_settings=af.AutoCorrelationsSettings(\n",
        "        check_for_convergence=True,\n",
        "        check_size=100,\n",
        "        required_length=50,\n",
        "        change_threshold=0.01,\n",
        "    ),\n",
        "    number_of_cores=1,\n",
        ")\n",
        "\n",
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "Here, we'll look in detail at what information is contained in the `Result`.\n",
        "\n",
        "It contains an `info` attribute which prints the result in readable format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Parameters__\n",
        "\n",
        "First, we can note that the parameters list of lists now has 6 entries in the parameters column, given the \n",
        "dimensionality of the model has increased from N=3 to N=6."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples = result.samples\n",
        "print(\"All Parameters:\")\n",
        "print(samples.parameter_lists)\n",
        "print(\"Sample 10`s sixth parameter value (Exponential -> rate)\")\n",
        "print(samples.parameter_lists[9][5], \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Instances__\n",
        "\n",
        "When we return a result as an instance, it provides us with instances of the model using the Python classes used to\n",
        "compose it. \n",
        "\n",
        "Because our fit uses a Collection (as opposed to a `Model` in the simple example) the instance\n",
        "returned a dictionary named acoording to the names given to the Collection, which above were `gaussian` and\n",
        "`exponential`.\n",
        "\n",
        "For complex models, with a large number of model components and parameters, this offers a readable API to interpret\n",
        "the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "max_lh_instance = samples.max_log_likelihood()\n",
        "\n",
        "print(\"Max Log Likelihood `Gaussian` Instance:\")\n",
        "print(\"Centre = \", max_lh_instance.gaussian.centre)\n",
        "print(\"Normalization = \", max_lh_instance.gaussian.normalization)\n",
        "print(\"Sigma = \", max_lh_instance.gaussian.sigma, \"\\n\")\n",
        "\n",
        "print(\"Max Log Likelihood Exponential Instance:\")\n",
        "print(\"Centre = \", max_lh_instance.exponential.centre)\n",
        "print(\"Normalization = \", max_lh_instance.exponential.normalization)\n",
        "print(\"Sigma = \", max_lh_instance.exponential.rate, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Vectors__\n",
        "\n",
        "1D vectors containing models have the same meaning as before, but they are also now of size 6 given the increase in\n",
        "model complexity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Result and Error Vectors:\")\n",
        "print(samples.median_pdf(as_instance=False))\n",
        "print(samples.max_log_likelihood(as_instance=False))\n",
        "print(samples.max_log_posterior(as_instance=False))\n",
        "print(samples.values_at_upper_sigma(sigma=3.0, as_instance=False))\n",
        "print(samples.values_at_lower_sigma(sigma=3.0, as_instance=False))\n",
        "print(samples.errors_at_upper_sigma(sigma=3.0, as_instance=False))\n",
        "print(samples.errors_at_lower_sigma(sigma=3.0, as_instance=False), \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Labels__\n",
        "\n",
        "Vectors return a lists of all model parameters, but do not tell us which values correspond to which parameters.\n",
        "\n",
        "The following quantities are available in the `Model`, where the order of their entries correspond to the parameters \n",
        "in the `ml_vector` above:\n",
        " \n",
        " - `paths`: a list of tuples which give the path of every parameter in the `Model`.\n",
        " - `parameter_names`: a list of shorthand parameter names derived from the `paths`.\n",
        " - `parameter_labels`: a list of parameter labels used when visualizing non-linear search results (see below)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = samples.model\n",
        "\n",
        "print(model.paths)\n",
        "print(model.parameter_names)\n",
        "print(model.parameter_labels)\n",
        "print(model.model_component_and_parameter_names)\n",
        "print(\"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Plot__\n",
        "\n",
        "Because results are returned as instances, it is straight forward to use them and their associated functionality\n",
        "to make plots of the results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_gaussian = max_lh_instance.gaussian.model_data_1d_via_xvalues_from(\n",
        "    xvalues=np.arange(data.shape[0])\n",
        ")\n",
        "model_exponential = max_lh_instance.exponential.model_data_1d_via_xvalues_from(\n",
        "    xvalues=np.arange(data.shape[0])\n",
        ")\n",
        "model_data = model_gaussian + model_exponential\n",
        "\n",
        "plt.plot(range(data.shape[0]), data)\n",
        "plt.plot(range(data.shape[0]), model_data)\n",
        "plt.plot(range(data.shape[0]), model_gaussian, \"--\")\n",
        "plt.plot(range(data.shape[0]), model_exponential, \"--\")\n",
        "plt.title(\"Illustrative model fit to 1D `Gaussian` + Exponential profile data.\")\n",
        "plt.xlabel(\"x values of profile\")\n",
        "plt.ylabel(\"Profile normalization\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Samples Filtering (Advanced)__\n",
        "\n",
        "Our samples object has the results for all three parameters in our model. However, we might only be interested in the\n",
        "results of a specific parameter.\n",
        "\n",
        "The basic form of filtering specifies parameters via their path, which was printed above via the model and is printed \n",
        "again below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples = result.samples\n",
        "\n",
        "print(\"Parameter paths in the model which are used for filtering:\")\n",
        "print(samples.model.paths)\n",
        "\n",
        "print(\"All parameters of the very first sample\")\n",
        "print(samples.parameter_lists[0])\n",
        "\n",
        "samples = samples.with_paths([(\"gaussian\", \"centre\")])\n",
        "\n",
        "print(\"All parameters of the very first sample (containing only the Gaussian centre.\")\n",
        "print(samples.parameter_lists[0])\n",
        "\n",
        "print(\"Maximum Log Likelihood Model Instances (containing only the Gaussian centre):\\n\")\n",
        "print(samples.max_log_likelihood(as_instance=False))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Above, we specified each path as a list of tuples of strings. \n",
        "\n",
        "This is how the PyAutoFit source code stores the path to different components of the model, but it is not \n",
        "in-profile_1d with the PyAutoFIT API used to compose a model.\n",
        "\n",
        "We can alternatively use the following API:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples = result.samples\n",
        "\n",
        "samples = samples.with_paths([\"gaussian.centre\"])\n",
        "\n",
        "print(\"All parameters of the very first sample (containing only the Gaussian centre).\")\n",
        "print(samples.parameter_lists[0])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Above, we filtered the `Samples` but asking for all parameters which included the path (\"gaussian\", \"centre\").\n",
        "\n",
        "We can alternatively filter the `Samples` object by removing all parameters with a certain path. Below, we remove\n",
        "the Gaussian's `centre` to be left with 2 parameters; the `normalization` and `sigma`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples = result.samples\n",
        "\n",
        "print(\"Parameter paths in the model which are used for filtering:\")\n",
        "print(samples.model.paths)\n",
        "\n",
        "print(\"All parameters of the very first sample\")\n",
        "print(samples.parameter_lists[0])\n",
        "\n",
        "samples = samples.without_paths([\"gaussian.centre\"])\n",
        "\n",
        "print(\n",
        "    \"All parameters of the very first sample (containing only the Gaussian normalization and sigma).\"\n",
        ")\n",
        "print(samples.parameter_lists[0])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Wrap Up__\n",
        "\n",
        "Adding model complexity does not change the behaviour of the Result object, other than the switch\n",
        "to Collections meaning that our instances now have named entries.\n",
        "\n",
        "When you name your model components, you should make sure to give them descriptive and information names that make \n",
        "the use of a result object clear and intuitive!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}