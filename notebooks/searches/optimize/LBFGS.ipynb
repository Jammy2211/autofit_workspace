{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Searches: LBFGS\n",
        "===============\n",
        "\n",
        "This example illustrates how to use the scipy optimize.minimize algorithm L-BFGS.\n",
        "\n",
        "Information about the L-BFGS method can be found at the following links:\n",
        "\n",
        " - https://docs.scipy.org/doc/scipy/reference/optimize.minimize-lbfgsb.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from os import path\n",
        "\n",
        "import autofit as af"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Data__\n",
        "\n",
        "This example fits a single 1D Gaussian, we therefore load and plot data containing one Gaussian."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = path.join(\"dataset\", \"example_1d\", \"gaussian_x1\")\n",
        "data = af.util.numpy_array_from_json(file_path=path.join(dataset_path, \"data.json\"))\n",
        "noise_map = af.util.numpy_array_from_json(\n",
        "    file_path=path.join(dataset_path, \"noise_map.json\")\n",
        ")\n",
        "\n",
        "plt.errorbar(\n",
        "    x=range(data.shape[0]),\n",
        "    y=data,\n",
        "    yerr=noise_map,\n",
        "    color=\"k\",\n",
        "    ecolor=\"k\",\n",
        "    elinewidth=1,\n",
        "    capsize=2,\n",
        ")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model + Analysis__\n",
        "\n",
        "We create the model and analysis, which in this example is a single `Gaussian` and therefore has dimensionality N=3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = af.Model(af.ex.Gaussian)\n",
        "\n",
        "model.centre = af.UniformPrior(lower_limit=0.0, upper_limit=100.0)\n",
        "model.normalization = af.UniformPrior(lower_limit=1e-2, upper_limit=1e2)\n",
        "model.sigma = af.UniformPrior(lower_limit=0.0, upper_limit=30.0)\n",
        "\n",
        "analysis = af.ex.Analysis(data=data, noise_map=noise_map)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "We now create and run the `LBFGS` object which acts as our non-linear search. \n",
        "\n",
        "We manually specify all of the LBFGS settings, descriptions of which are provided at the following webpage:\n",
        "\n",
        " https://docs.scipy.org/doc/scipy/reference/optimize.minimize-lbfgsb.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.LBFGS(\n",
        "    path_prefix=\"searches\",\n",
        "    name=\"LBFGS\",\n",
        "    tol=None,\n",
        "    disp=None,\n",
        "    maxcor=10,\n",
        "    ftol=2.220446049250313e-09,\n",
        "    gtol=1e-05,\n",
        "    eps=1e-08,\n",
        "    maxfun=15000,\n",
        "    maxiter=15000,\n",
        "    iprint=-1,\n",
        "    maxls=20,\n",
        "    iterations_per_update=1000,\n",
        ")\n",
        "\n",
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "The result object returned by the fit provides information on the results of the non-linear search. Lets use it to\n",
        "compare the maximum log likelihood `Gaussian` to the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_data = result.max_log_likelihood_instance.model_data_1d_via_xvalues_from(\n",
        "    xvalues=np.arange(data.shape[0])\n",
        ")\n",
        "\n",
        "plt.errorbar(\n",
        "    x=range(data.shape[0]),\n",
        "    y=data,\n",
        "    yerr=noise_map,\n",
        "    color=\"k\",\n",
        "    ecolor=\"k\",\n",
        "    elinewidth=1,\n",
        "    capsize=2,\n",
        ")\n",
        "plt.plot(range(data.shape[0]), model_data, color=\"r\")\n",
        "plt.title(\"PySwarmsLocal model fit to 1D Gaussian dataset.\")\n",
        "plt.xlabel(\"x values of profile\")\n",
        "plt.ylabel(\"Profile normalization\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search Internal__\n",
        "\n",
        "The result also contains the internal representation of the non-linear search.\n",
        "\n",
        "The internal representation of the non-linear search ensures that all sampling info is available in its native form.\n",
        "This can be passed to functions which take it as input, for example if the sampling package has bespoke visualization \n",
        "functions.\n",
        "\n",
        "For `PySwarms`, this is an instance of the `Sampler` object (`from pyswarms import GlobalBestPSO`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search_internal = result.search_internal\n",
        "\n",
        "print(search_internal)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The internal search is by default not saved to hard-disk, because it can often take up quite a lot of hard-disk space\n",
        "(significantly more than standard output files).\n",
        "\n",
        "This means that the search internal will only be available the first time you run the search. If you rerun the code \n",
        "and the search is bypassed because the results already exist on hard-disk, the search internal will not be available.\n",
        "\n",
        "If you are frequently using the search internal you can have it saved to hard-disk by changing the `search_internal`\n",
        "setting in `output.yaml` to `True`. The result will then have the search internal available as an attribute, \n",
        "irrespective of whether the search is re-run or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}