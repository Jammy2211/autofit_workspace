{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Feature: Start Point\n",
        "====================\n",
        "\n",
        "For maximum likelihood estimator (MLE) and Markov Chain Monte Carlo (MCMC) non-linear searches, parameter space\n",
        "sampling is built around having a \"location\" in parameter space.\n",
        "\n",
        "This could simply be the parameters of the current maximum likelihood model in an MLE fit, or the locations of many\n",
        "walkers in parameter space (e.g. MCMC).\n",
        "\n",
        "For many model-fitting problems, we may have an expectation of where correct solutions lie in parameter space and\n",
        "therefore want our non-linear search to start near that location of parameter space. Alternatively, we may want to\n",
        "sample a specific region of parameter space, to determine what solutions look like there.\n",
        "\n",
        "The start-point API allows us to do this, by manually specifying the start-point of an MLE fit or the start-point of\n",
        "the walkers in an MCMC fit. Because nested sampling draws from priors, it cannot use the start-point API.\n",
        "\n",
        "__Comparison to Priors__\n",
        "\n",
        "Similar behaviour can be achieved by customizing the priors of a model-fit. We could place `GaussianPrior`'s\n",
        "centred on the regions of parameter space we want to sample, or we could place tight `UniformPrior`'s on regions\n",
        "of parameter space we believe the correct answer lies.\n",
        "\n",
        "The downside of using priors is that our priors have a direct influence on the parameters we infer and the size\n",
        "of the inferred parameter errors. By using priors to control the location of our model-fit, we therefore risk\n",
        "inferring a non-representative model.\n",
        "\n",
        "For users more familiar with statistical inference, adjusting ones priors in the way described above leads to\n",
        "changes in the posterior, which therefore impacts the model inferred.\n",
        "\n",
        "__Example Source Code (`af.ex`)__\n",
        "\n",
        "The **PyAutoFit** source code has the following example objects (accessed via `af.ex`) used in this tutorial:\n",
        "\n",
        " - `Analysis`: an analysis object which fits noisy 1D datasets, including `log_likelihood_function` and\n",
        " `visualize` functions.\n",
        "\n",
        " - `Gaussian`: a model component representing a 1D Gaussian profile.\n",
        "\n",
        "These are functionally identical to the `Analysis` and `Gaussian` objects you have seen elsewhere in the workspace.\n",
        "\n",
        "__Start Here Notebook__\n",
        "\n",
        "If any code in this script is unclear, refer to the `modeling/start_here.ipynb` notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from os import path\n",
        "import autofit as af"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Data__\n",
        "\n",
        "This example fits a single 1D Gaussian, we therefore load and plot data containing one Gaussian."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = path.join(\"dataset\", \"example_1d\", \"gaussian_x1\")\n",
        "data = af.util.numpy_array_from_json(file_path=path.join(dataset_path, \"data.json\"))\n",
        "noise_map = af.util.numpy_array_from_json(\n",
        "    file_path=path.join(dataset_path, \"noise_map.json\")\n",
        ")\n",
        "\n",
        "plt.errorbar(\n",
        "    x=range(data.shape[0]),\n",
        "    y=data,\n",
        "    yerr=noise_map,\n",
        "    linestyle=\"\",\n",
        "    color=\"k\",\n",
        "    ecolor=\"k\",\n",
        "    elinewidth=1,\n",
        "    capsize=2,\n",
        ")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Start Point Priors__\n",
        "\n",
        "The start-point API does not conflict with the use of priors, which are still associated with every parameter.\n",
        "\n",
        "We manually customize the priors of the model used by the non-linear search.\n",
        "\n",
        "We use broad `UniformPriors`'s so that our priors do not impact our inferred model and errors (which would be\n",
        "the case with tight `GaussianPrior`'s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = af.Model(af.ex.Gaussian)\n",
        "\n",
        "model.centre = af.UniformPrior(lower_limit=0.0, upper_limit=100.0)\n",
        "model.normalization = af.UniformPrior(lower_limit=1e-2, upper_limit=1e2)\n",
        "model.sigma = af.UniformPrior(lower_limit=0.0, upper_limit=30.0)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can inspect the model (with customized priors) via its `.info` attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Start Point__\n",
        "\n",
        "We now define the start point of certain parameters in the model:\n",
        "\n",
        " - The 1D Gaussian is centred near pixel 50, so we set a start point there.\n",
        "\n",
        " - The sigma value of the Gaussian looks around 10, so we set a start point there.\n",
        "\n",
        "For all parameters where the start-point is not specified (in this case the `normalization`, their \n",
        "parameter values are drawn randomly from the prior when determining the initial locations of the parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "initializer = af.SpecificRangeInitializer(\n",
        "    {model.centre: (49.0, 51.0), model.sigma: (9.0, 100.0)}\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A quick look at the model's `info` attribute shows that the starting points above do not change\n",
        "the priors or model info."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search + Analysis + Model-Fit__\n",
        "\n",
        "The code below performs the normal steps to set up a model-fit. We omit comments of this code as you should be \n",
        "familiar with it and it is not specific to this example!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Emcee(\n",
        "    path_prefix=\"searches\",\n",
        "    name=\"start_point\",\n",
        "    nwalkers=30,\n",
        "    nsteps=1000,\n",
        "    initializer=initializer,\n",
        "    number_of_cores=1,\n",
        ")\n",
        "\n",
        "analysis = af.ex.Analysis(data=data, noise_map=noise_map)\n",
        "\n",
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "We can print the initial `parameter_lists` of the result's `Samples` object to check that the initial \n",
        "walker samples were set within the start point ranges above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples = result.samples\n",
        "\n",
        "print(samples.model.parameter_names)\n",
        "\n",
        "print(samples.parameter_lists[0])\n",
        "print(samples.parameter_lists[1])\n",
        "print(samples.parameter_lists[2])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}