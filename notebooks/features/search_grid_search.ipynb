{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Feature: Search Grid Search\n",
        "===========================\n",
        "\n",
        "A classic method to perform model-fitting is a grid search, where the parameters of a model are divided on to a grid of\n",
        "values and the likelihood of each set of parameters on this grid is sampled. For low dimensionality problems this\n",
        "simple approach can be sufficient to locate high likelihood solutions, however it scales poorly to higher dimensional\n",
        "problems.\n",
        "\n",
        "**PyAutoFit** can perform a search grid search, which allows one to perform a grid-search over a subset of parameters\n",
        "within a model, but use a non-linear search to fit for the other parameters. The parameters over which the grid-search\n",
        "is performed are also included in the model fit and their values are simply confined to the boundaries of their grid\n",
        "cell by setting these as the lower and upper limits of a `UniformPrior`.\n",
        "\n",
        "The benefits of using a search grid search are:\n",
        "\n",
        " - For problems with complex and multi-model parameters spaces it can be difficult to robustly and efficiently perform\n",
        " model-fitting. If specific parameters are known to drive the multi-modality then sampling over a grid can ensure the\n",
        " parameter space of each individual model-fit is not multi-modal and therefore sampled more accurately and efficiently.\n",
        "\n",
        " - It can provide a goodness-of-fit measure (e.g. the Bayesian evidence) of many model-fits over the grid. This can\n",
        " provide additional insight into where the model does and does not fit the data well, in a way that a standard\n",
        " non-linear search does not.\n",
        "\n",
        " - The search grid search is embarrassingly parallel, and if sufficient computing facilities are available one can\n",
        " perform model-fitting faster in real-time than a single non-linear search. The **PyAutoFit** search grid search\n",
        " includes an option for parallel model-fitting via the Python `multiprocessing` module.\n",
        "\n",
        "In this example we will demonstrate the search grid search feature, again using the example of fitting 1D Gaussian's\n",
        "in noisy data.\n",
        "\n",
        "__Example Source Code (`af.ex`)__\n",
        "\n",
        "The **PyAutoFit** source code has the following example objects (accessed via `af.ex`) used in this tutorial:\n",
        "\n",
        " - `Analysis`: an analysis object which fits noisy 1D datasets, including `log_likelihood_function` and\n",
        " `visualize` functions.\n",
        "\n",
        " - `Gaussian`: a model component representing a 1D Gaussian profile.\n",
        "\n",
        "These are functionally identical to the `Analysis` and `Gaussian` objects you have seen elsewhere in the workspace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from os import path\n",
        "\n",
        "import autofit as af"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Data__\n",
        "\n",
        "First, lets load data of a 1D Gaussian, by loading it from a .json file in the directory \n",
        "`autofit_workspace/dataset/gaussian_x1_with_feature`.\n",
        "\n",
        "This 1D data includes a small feature to the right of the central `Gaussian`. This feature is a second `Gaussian` \n",
        "centred on pixel 70. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = path.join(\"dataset\", \"example_1d\", \"gaussian_x1_with_feature\")\n",
        "data = af.util.numpy_array_from_json(file_path=path.join(dataset_path, \"data.json\"))\n",
        "noise_map = af.util.numpy_array_from_json(\n",
        "    file_path=path.join(dataset_path, \"noise_map.json\")\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now lets plot the data, including its error bars. \n",
        "\n",
        "The feature on pixel 70 is clearly visible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "xvalues = range(data.shape[0])\n",
        "\n",
        "plt.errorbar(\n",
        "    x=xvalues, y=data, yerr=noise_map, color=\"k\", ecolor=\"k\", elinewidth=1, capsize=2\n",
        ")\n",
        "plt.title(\"1D Gaussian Data With Feature at pixel 70.\")\n",
        "plt.xlabel(\"x values of profile\")\n",
        "plt.ylabel(\"Profile normalization\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "Next, we create the model, which in this case corresponds to two `Gaussian`'s, one for the main signal seen in the\n",
        "data and one for the feature on pixel 70."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = af.Collection(gaussian_main=af.ex.Gaussian, gaussian_feature=af.ex.Gaussian)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model in a readable format, showing it contains two `Gaussian`'s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "Our Analysis class is described in `analysis.py` and is the same used in the `overview/complex` example. \n",
        "\n",
        "It fits the data as the sum of the two `Gaussian`'s in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = af.ex.Analysis(data=data, noise_map=noise_map)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "We will now fit the data using a single non-linear search, to demonstrate the behaviour of the fit before we invoke\n",
        "the search grid search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.DynestyStatic(\n",
        "    path_prefix=path.join(\"features\", \"search_grid_search\"),\n",
        "    name=\"single_fit\",\n",
        "    nlive=100,\n",
        "    maxcall=30000,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To perform the fit with Dynesty, we pass it our model and analysis and we`re good to go!\n",
        "\n",
        "Checkout the folder `autofit_workspace/output/features.search_grid_search/single_fit`, where the `NonLinearSearch` \n",
        "results, visualization and information can be found.\n",
        "\n",
        "For test runs on my laptop it is 'hit or miss' whether the feature is fitted correctly. This is because although models\n",
        "including the feature corresponds to the highest likelihood solutions, they occupy a small volume in parameter space\n",
        "which the non linear search may miss. Furthemore, it is common for the model-fit to get stuck in local maxima where\n",
        "both `Gaussian`'s go to a centre value of 50.0.\n",
        "\n",
        "The fit can also take a very long time to run, therefore I limited `Dynesty` to 30000 iterations above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "If you ran the fit above, you can now plot the result. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "instance = result.max_log_likelihood_instance\n",
        "\n",
        "gaussian_main = instance.gaussian_main.model_data_1d_via_xvalues_from(\n",
        "    xvalues=np.arange(data.shape[0])\n",
        ")\n",
        "gaussian_feature = instance.gaussian_feature.model_data_1d_via_xvalues_from(\n",
        "    xvalues=np.arange(data.shape[0])\n",
        ")\n",
        "model_data = gaussian_main + gaussian_feature\n",
        "\n",
        "plt.errorbar(\n",
        "    x=xvalues, y=data, yerr=noise_map, color=\"k\", ecolor=\"k\", elinewidth=1, capsize=2\n",
        ")\n",
        "plt.plot(range(data.shape[0]), model_data, color=\"r\")\n",
        "plt.plot(range(data.shape[0]), gaussian_main, \"--\")\n",
        "plt.plot(range(data.shape[0]), gaussian_feature, \"--\")\n",
        "plt.title(\"Dynesty model fit to 1D Gaussian with feature dataset.\")\n",
        "plt.xlabel(\"x values of profile\")\n",
        "plt.ylabel(\"Profile normalization\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search Grid Search__\n",
        "\n",
        "We will now perform the search grid search. \n",
        "\n",
        "We will use the same `Dynesty` settings, but change its `name`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.DynestyStatic(\n",
        "    name=\"grid_fit\",\n",
        "    path_prefix=path.join(\"features\", \"search_grid_search\"),\n",
        "    nlive=100,\n",
        "    maxcall=30000,\n",
        "    force_x1_cpu=True,  # ensures parallelizing over grid search works.\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To set up the search grid search we specify two additional settings:\n",
        "\n",
        "`number_of_steps`: The number of steps in the grid search that are performedm which is set to 5 below. \n",
        " \n",
        "Because the prior on the parameter `centre` is a `UniformPrior` from 0.0 -> 100.0, this means the first grid search\n",
        "will set the prior on the centre to be a `UniformPrior` from 0.0 -> 20.0. The second will run from 20.0 -> 40.0,\n",
        "the third 40.0 -> 60.0, and so on.\n",
        "   \n",
        "`parallel`: If `True`, each grid search is performed in parallel on your laptop. \n",
        "\n",
        "`number_of_cores`: The number of cores the grid search will parallelize the run over. If `number_of_cores=1`, the\n",
        "search is run in serial. For > 1 core, 1 core is reserved as a farmer, e.g., if `number_of_cores=4` then up to 3 \n",
        "searches will be run in parallel. In case your laptop has limited hardware resources we do not run in parallel in \n",
        "this example by default, but feel free to change the option to `True` if you have a lot of CPUs and memory!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid_search = af.SearchGridSearch(search=search, number_of_steps=5, number_of_cores=1)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now run the grid search.\n",
        "\n",
        "This is where we specify the parameter over which the grid search is performed, in this case the `centre` of the \n",
        "`gaussian_feature` in our model.\n",
        "\n",
        "On my laptop, each model fit performed by the grid search takes ~15000 iterations, whereas the fit above\n",
        "required ~ 40000 iterations. Thus, in this simple example, the grid search did not speed up the overall analysis \n",
        "(unless it is run in parallel). However, more complex and realistic model-fitting problems, the grid search has the\n",
        "potential to give huge performance improvements if used effectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid_search_result = grid_search.fit(\n",
        "    model=model, analysis=analysis, grid_priors=[model.gaussian_feature.centre]\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This returns a `GridSearchResult`, which includes information on every model-fit performed on the grid.\n",
        "\n",
        "Below, we print:\n",
        " \n",
        " - The central value of the `UniformPrior` on the `centre` of the gaussian_feature` for each fit performed on the\n",
        " grid search. \n",
        " \n",
        " - The maximum log likelihood value of each of the 5 fits. \n",
        " \n",
        " - The Bayesian evidence of each (this is accessible because we used a nested sampling algorithm).\n",
        "\n",
        "You should see that the highest likelihood and evidence values correspond to run 4, where the `UniformPrior` on the\n",
        "centre parameter ran from 60 -> 80 and therefore captured the true value of 70.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(grid_search_result.physical_centres_lists)\n",
        "print(grid_search_result.log_likelihoods_native)\n",
        "print(grid_search_result.log_evidences_native)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also access the `best_result` and `best_model`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(grid_search_result.best_result)\n",
        "print(grid_search_result.best_model)\n",
        "print(grid_search_result.best_model.gaussian_main.centre)\n",
        "print(grid_search_result.best_model.gaussian_main.normalization)\n",
        "print(grid_search_result.best_model.gaussian_main.sigma)\n",
        "print(grid_search_result.best_model.gaussian_feature.centre)\n",
        "print(grid_search_result.best_model.gaussian_feature.normalization)\n",
        "print(grid_search_result.best_model.gaussian_feature.sigma)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By plotting the `best_model` we can confirm the grid search fitted the feature at pixel 70."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "instance = grid_search_result.best_result.instance\n",
        "\n",
        "gaussian_main = instance.gaussian_main.model_data_1d_via_xvalues_from(\n",
        "    xvalues=np.arange(data.shape[0])\n",
        ")\n",
        "gaussian_feature = instance.gaussian_feature.model_data_1d_via_xvalues_from(\n",
        "    xvalues=np.arange(data.shape[0])\n",
        ")\n",
        "model_data = gaussian_main + gaussian_feature\n",
        "\n",
        "plt.errorbar(\n",
        "    x=xvalues, y=data, yerr=noise_map, color=\"k\", ecolor=\"k\", elinewidth=1, capsize=2\n",
        ")\n",
        "plt.plot(range(data.shape[0]), model_data, color=\"r\")\n",
        "plt.plot(range(data.shape[0]), gaussian_main, \"--\")\n",
        "plt.plot(range(data.shape[0]), gaussian_feature, \"--\")\n",
        "plt.title(\"Dynesty model fit to 1D Gaussian with feature dataset.\")\n",
        "plt.xlabel(\"x values of profile\")\n",
        "plt.ylabel(\"Profile normalization\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A multi-dimensional grid search can be easily performed by adding more parameters to the `grid_priors` input.\n",
        "\n",
        "The fit below belows performs a 5x5 grid search over the `centres` of both `Gaussians`. This would take quite a long\n",
        "time to run, so I've commented it out, but feel free to run it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# grid_search_result = grid_search.fit(\n",
        "#     model=model,\n",
        "#     analysis=analysis,\n",
        "#     grid_priors=[model.gaussian_feature.centre, model.gaussian_main.centre],\n",
        "# )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}