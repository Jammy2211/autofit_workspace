{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Feature: Start Point\n",
        "====================\n",
        "\n",
        "For maximum likelihood estimator (MLE) and Markov Chain Monte Carlo (MCMC) non-linear searches, parameter space\n",
        "sampling is built around having a \"location\" in parameter space.\n",
        "\n",
        "This could simply be the parameters of the current maximum likelihood model in an MLE fit, or the locations of many\n",
        "walkers in parameter space (e.g. MCMC).\n",
        "\n",
        "For many model-fitting problems, we may have an expectation of where correct solutions lie in parameter space and\n",
        "therefore want our non-linear search to start near that location of parameter space. Alternatively, we may want to\n",
        "sample a specific region of parameter space, to determine what solutions look like there.\n",
        "\n",
        "The start-point API allows us to do this, by manually specifying the start-point of an MLE fit or the start-point of\n",
        "the walkers in an MCMC fit. Because nested sampling draws from priors, it cannot use the start-point API.\n",
        "\n",
        "__Comparison to Priors__\n",
        "\n",
        "Similar behaviour can be achieved by customizing the priors of a model-fit. We could place `GaussianPrior`'s\n",
        "centred on the regions of parameter space we want to sample, or we could place tight `UniformPrior`'s on regions\n",
        "of parameter space we believe the correct answer lies.\n",
        "\n",
        "The downside of using priors is that our priors have a direct influence on the parameters we infer and the size\n",
        "of the inferred parameter errors. By using priors to control the location of our model-fit, we therefore risk\n",
        "inferring a non-representative model.\n",
        "\n",
        "For users more familiar with statistical inference, adjusting ones priors in the way described above leads to\n",
        "changes in the posterior, which therefore impacts the model inferred.\n",
        "\n",
        "__Example Source Code (`af.ex`)__\n",
        "\n",
        "The **PyAutoFit** source code has the following example objects (accessed via `af.ex`) used in this tutorial:\n",
        "\n",
        " - `Analysis`: an analysis object which fits noisy 1D datasets, including `log_likelihood_function` and\n",
        " `visualize` functions.\n",
        "\n",
        " - `Gaussian`: a model component representing a 1D Gaussian profile.\n",
        "\n",
        "These are functionally identical to the `Analysis` and `Gaussian` objects you have seen elsewhere in the workspace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from os import path\n",
        "\n",
        "import autofit as af"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Data__\n",
        "\n",
        "Load data of a 1D `Gaussian` + 1D Exponential, by loading it from a .json file in the directory \n",
        "`autofit_workspace/dataset//gaussian_x1__exponential_x1`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = path.join(\"dataset\", \"example_1d\", \"gaussian_x1__exponential_x1\")\n",
        "data = af.util.numpy_array_from_json(file_path=path.join(dataset_path, \"data.json\"))\n",
        "noise_map = af.util.numpy_array_from_json(\n",
        "    file_path=path.join(dataset_path, \"noise_map.json\")\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets plot the data. We'll use its shape to determine the xvalues of the\n",
        "data for the plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "xvalues = range(data.shape[0])\n",
        "plt.errorbar(\n",
        "    x=xvalues, y=data, yerr=noise_map, color=\"k\", ecolor=\"k\", elinewidth=1, capsize=2\n",
        ")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "Next, we create our model, which in this case corresponds to a `Gaussian` + `Exponential`. \n",
        "\n",
        "The `Gaussian` has 3 parameters (centre, normalization and sigma) and Exponential 3 parameters (centre, normalization \n",
        "and rate), meaning the non-linear parameter space has dimensionality = 6."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "gaussian = af.Model(af.ex.Gaussian)\n",
        "exponential = af.Model(af.ex.Exponential)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The start-point API does not conflict with the use of priors, which are still associated with every parameter.\n",
        "\n",
        "We manually customize the priors of the model used by the non-linear search.\n",
        "\n",
        "We use broad `UniformPriors`'s so that our priors do not impact our inferred model and errors (which would be\n",
        "the case with tight `GaussianPrior`'s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "gaussian.centre = af.UniformPrior(lower_limit=0.0, upper_limit=100.0)\n",
        "gaussian.normalization = af.UniformPrior(lower_limit=0.0, upper_limit=1e2)\n",
        "gaussian.sigma = af.UniformPrior(lower_limit=0.0, upper_limit=30.0)\n",
        "exponential.centre = af.UniformPrior(lower_limit=0.0, upper_limit=100.0)\n",
        "exponential.normalization = af.UniformPrior(lower_limit=0.0, upper_limit=1e2)\n",
        "exponential.rate = af.UniformPrior(lower_limit=0.0, upper_limit=10.0)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now compose the overall model using a `Collection`, which takes the model components we defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = af.Collection(gaussian=gaussian, exponential=exponential)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can inspect the model (with customized priors) via its `.info` attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Start Point__\n",
        "\n",
        "We now define the start point of certain parameters in the model.\n",
        "\n",
        "By looking at the data, we can see clearly that both the `Gaussian` and `Exponential` are centred near 50.0, thus\n",
        "we set both their starting points to between the range 49.0 to 51.0.\n",
        "\n",
        "We also set the `Gaussian` `sigma` value to a start point of 4.0 to 6.0.\n",
        "\n",
        "For all parameters where the start-point is not specified, their parameter values are drawn randomly from the prior\n",
        "when determining the initial locations of the parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "initializer = af.SpecificRangeInitializer(\n",
        "    {\n",
        "        model.gaussian.centre: (49.0, 51.0),\n",
        "        model.gaussian.sigma: (4.0, 6.0),\n",
        "        model.exponential.centre: (49.0, 51.0),\n",
        "    }\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A quick look at the model's `info` attribute shows that the starting points above do not change\n",
        "the priors or model info."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "Create the analysis which fits the model to the data.\n",
        "\n",
        "It fits the data as the sum of the two `Gaussian`'s in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = af.ex.Analysis(data=data, noise_map=noise_map)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "We will perform the fit using the MCMC algorithm Emcee, which samples parameter space via 50 walkers.\n",
        "\n",
        "The starting point of all walkers will correspond to `centre` values within 49.0 to 51.0 and a `sigma` values between\n",
        "4.0 to 6.0.\n",
        "\n",
        "note that once the Emcee sampling begins, walkers are able to walk outside the starting point range set in the\n",
        "initializer above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Emcee(\n",
        "    path_prefix=\"features\",\n",
        "    name=\"start_point\",\n",
        "    nwalkers=50,\n",
        "    nsteps=500,\n",
        "    initializer=initializer,\n",
        ")\n",
        "\n",
        "\n",
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "We can print the initial `parameter_lists` of the result's `Samples` object to check that the initial walker samples \n",
        "were set within the start point ranges above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples = result.samples\n",
        "\n",
        "print(samples.model.parameter_names)\n",
        "\n",
        "print(samples.parameter_lists[0])\n",
        "print(samples.parameter_lists[1])\n",
        "print(samples.parameter_lists[2])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}