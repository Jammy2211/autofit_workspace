{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Feature: Search Chaining\n",
        "========================\n",
        "\n",
        "To perform a model-fit, we typically compose one model and fit it to our data using one non-linear search.\n",
        "\n",
        "Search chaining fits many different models to a dataset using a chained sequence of non-linear searches. Initial\n",
        "fits are performed using simplified model parameterizations and faster non-linear fitting techniques. The results of\n",
        "these simplified fits can then be used to initialize fits using a higher dimensionality model with more detailed\n",
        "non-linear search.\n",
        "\n",
        "To fit highly complex models our aim is therefore to granularize the fitting procedure into a series of **bite-sized**\n",
        "searches which are faster and more reliable than fitting the more complex model straight away.\n",
        "\n",
        "Our ability to construct chained non-linear searches that perform model fitting more accurately and efficiently relies\n",
        "on our **domain specific knowledge** of the model fitting task. For example, we may know that our dataset contains\n",
        "multiple features that can be accurately fitted separately before performing a joint fit, or that certain parameter\n",
        "share minimal covariance such that certain parameters can be fixed before fitting both with a more complex model\n",
        "parameterization.\n",
        "\n",
        "We may also know tricks that can speed up the fitting of the initial model, for example reducing the size of the data\n",
        "or changing the likelihood evaluations in a way that makes them quicker (likely at the expense of the overall\n",
        "quality of the fit itself). By using chained searches these speed-ups can be relaxed towards the end of the\n",
        "model-fitting sequence when we want the most precise, most accurate model that best fits the dataset available.\n",
        "\n",
        "In this example we demonstrate search chaining using the example data where there are two `Gaussians` that are visibly\n",
        "split. Instead of fitting them simultaneously using a single non-linear search consisting of N=6 parameters, we break\n",
        "this model-fit into a chained of three searches where:\n",
        "\n",
        " 1) The first model fits just the left `Gaussian` where N=3.\n",
        " 2) The first model fits just the right `Gaussian` where again N=3.\n",
        " 3) The final model is fitted with both `Gaussians` where N=6. Crucially, the results of the first two searches\n",
        " are used to initialize the search and tell it the highest likelihood regions of parameter space.\n",
        "\n",
        "By initially fitting parameter spaces of reduced complexity we can achieve a more efficient and reliable model-fitting\n",
        "procedure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import autofit as af\n",
        "import model as m\n",
        "import analysis as a\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from os import path"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Data__\n",
        "\n",
        "First, lets load data of two 1D Gaussians, by loading it from a .json file in the directory \n",
        "`autofit_workspace/dataset/gaussian_x1_with_feature`.\n",
        "\n",
        "This 1D data includes two `Gaussians` that are split from one another."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = path.join(\"dataset\", \"example_1d\", \"gaussian_x2_split\")\n",
        "data = af.util.numpy_array_from_json(file_path=path.join(dataset_path, \"data.json\"))\n",
        "noise_map = af.util.numpy_array_from_json(\n",
        "    file_path=path.join(dataset_path, \"noise_map.json\")\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now lets plot the data, including its error bars. \n",
        "\n",
        "Two separate `Gaussians` are clearly visible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "xvalues = range(data.shape[0])\n",
        "\n",
        "plt.errorbar(\n",
        "    x=xvalues, y=data, yerr=noise_map, color=\"k\", ecolor=\"k\", elinewidth=1, capsize=2\n",
        ")\n",
        "plt.title(\"1D Gaussian Data With two Gaussians split apart.\")\n",
        "plt.xlabel(\"x values of profile\")\n",
        "plt.ylabel(\"Profile intensity\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "Our Analysis class is described in `analysis.py` and is the same used in the `overview/complex` example. \n",
        "\n",
        "It fits the data as the sum of as many `Gaussian`'s as are in the model.\n",
        "\n",
        "To better fit the left gaussian, we remove all data points in the right-half of the data. Note that for more \n",
        "computationally demanding model-fitting problems this would give a significant speed-up in log likelihood function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = a.Analysis(data=data[0:50], noise_map=noise_map[0:50])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We are now going to fit the left `Gaussian` in this split dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = af.CollectionPriorModel(gaussian_left=m.Gaussian)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search[1]__\n",
        "\n",
        "We will now fit the data with the `left_gaussian` using a single non-linear search. \n",
        "\n",
        "Given the simplicity of the model, we can use a low number of live points to achieve a fast model-fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dynesty = af.DynestyStatic(\n",
        "    name=(\"search[1]__left_gaussian\"),\n",
        "    path_prefix=path.join(\"features\", \"search_chaining\"),\n",
        "    n_live_points=30,\n",
        "    iterations_per_update=500,\n",
        ")\n",
        "\n",
        "search_1_result = dynesty.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By plotting the result we can see we have fitted the left `Gaussian` reasonably well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "instance = search_1_result.max_log_likelihood_instance\n",
        "\n",
        "model_data = instance.gaussian_left.profile_from_xvalues(\n",
        "    xvalues=np.arange(data.shape[0])\n",
        ")\n",
        "\n",
        "plt.errorbar(\n",
        "    x=xvalues, y=data, yerr=noise_map, color=\"k\", ecolor=\"k\", elinewidth=1, capsize=2\n",
        ")\n",
        "plt.plot(range(data.shape[0]), model_data, color=\"r\")\n",
        "plt.title(\"Search 1  fit to left Gaussian.\")\n",
        "plt.xlabel(\"x values of profile\")\n",
        "plt.ylabel(\"Profile intensity\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search[2]__\n",
        "\n",
        "We now repeat the above process for the right `Gaussian`.\n",
        "\n",
        "We could remove the data on the left like we did the `Gaussian` above. However, we are instead going to fit the full \n",
        "dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = a.Analysis(data=data, noise_map=noise_map)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Because the left Gaussian is now again in the data, we need to fit it. We can do this, without increasing the \n",
        "dimensionality of our parameter space to N=6, by using the maximum log likelihood model of the `gaussian_left` in\n",
        "search[1].\n",
        "\n",
        "For search chaining, **PyAutoFit** has many convenient methods for passing the results of a search to a subsequence \n",
        "search. Below, we achieve this by passing the result of the search above as an `instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = af.CollectionPriorModel(\n",
        "    gaussian_left=search_1_result.instance.gaussian_left, gaussian_right=m.Gaussian\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now run our second Dynesty search to fit the right `Gaussian`.\n",
        "\n",
        "Given the simplicity of the model, we can again use a low number of live points to achieve a fast model-fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dynesty = af.DynestyStatic(\n",
        "    name=(\"search[2]__right_gaussian\"),\n",
        "    path_prefix=path.join(\"features\", \"search_chaining\"),\n",
        "    n_live_points=30,\n",
        "    iterations_per_update=500,\n",
        ")\n",
        "\n",
        "search_2_result = dynesty.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By plotting the result we can see we have fitted the right `Gaussian` reasonably well and that the model includes the\n",
        "`left_gaussian` from the first search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "instance = search_2_result.max_log_likelihood_instance\n",
        "\n",
        "gaussian_left = instance.gaussian_left.profile_from_xvalues(\n",
        "    xvalues=np.arange(data.shape[0])\n",
        ")\n",
        "gaussian_right = instance.gaussian_right.profile_from_xvalues(\n",
        "    xvalues=np.arange(data.shape[0])\n",
        ")\n",
        "\n",
        "model_data = gaussian_left + gaussian_right\n",
        "\n",
        "plt.errorbar(\n",
        "    x=xvalues, y=data, yerr=noise_map, color=\"k\", ecolor=\"k\", elinewidth=1, capsize=2\n",
        ")\n",
        "plt.plot(range(data.shape[0]), model_data, color=\"r\")\n",
        "plt.plot(range(data.shape[0]), gaussian_left, \"--\")\n",
        "plt.plot(range(data.shape[0]), gaussian_right, \"--\")\n",
        "plt.title(\"Search 2 fit to right Gaussian.\")\n",
        "plt.xlabel(\"x values of profile\")\n",
        "plt.ylabel(\"Profile intensity\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search[3]__\n",
        "\n",
        "We now fit both `Gaussians`'s simultaneously, using the results of the previous two searches to initialize where \n",
        "the non-linear searches parameter space.\n",
        "\n",
        "To pass the result in this way we use the command `result.model`, which in contrast to `result.instance` above passes\n",
        "the parameters not as the maximum log likelihood values but as `GaussianPrior`'s that are fitted for by the\n",
        "non-linear search. We discuss below how this `GaussianPrior` is passed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = af.CollectionPriorModel(\n",
        "    gaussian_left=search_1_result.model.gaussian_left,\n",
        "    gaussian_right=search_2_result.model.gaussian_right,\n",
        ")\n",
        "\n",
        "dynesty = af.DynestyStatic(\n",
        "    name=(\"search[3]__both_gaussians\"),\n",
        "    path_prefix=path.join(\"features\", \"search_chaining\"),\n",
        "    n_live_points=100,\n",
        "    iterations_per_update=500,\n",
        ")\n",
        "\n",
        "search_3_result = dynesty.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By plotting the result we can now see we have fitted both `Gaussian`'s accurately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "instance = search_3_result.max_log_likelihood_instance\n",
        "\n",
        "gaussian_left = instance.gaussian_left.profile_from_xvalues(\n",
        "    xvalues=np.arange(data.shape[0])\n",
        ")\n",
        "gaussian_right = instance.gaussian_right.profile_from_xvalues(\n",
        "    xvalues=np.arange(data.shape[0])\n",
        ")\n",
        "\n",
        "model_data = gaussian_left + gaussian_right\n",
        "\n",
        "plt.errorbar(\n",
        "    x=xvalues, y=data, yerr=noise_map, color=\"k\", ecolor=\"k\", elinewidth=1, capsize=2\n",
        ")\n",
        "plt.plot(range(data.shape[0]), model_data, color=\"r\")\n",
        "plt.plot(range(data.shape[0]), gaussian_left, \"--\")\n",
        "plt.plot(range(data.shape[0]), gaussian_right, \"--\")\n",
        "plt.title(\"Search 3 fit to both Gaussian.\")\n",
        "plt.xlabel(\"x values of profile\")\n",
        "plt.ylabel(\"Profile intensity\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Prior Passing__\n",
        "\n",
        "Now search 3 is complete, you should checkout its `model.info` file. The parameters do not use the default priors of \n",
        "the `Gaussian` model component. Instead, they use GaussianPrior`s where:\n",
        "\n",
        " - The mean values are the median PDF results of every parameter inferred by the fits performed in searches 1 and 2.\n",
        " - They sigma values are the errors computed by these searches, or they are values higher than these errors.\n",
        "\n",
        "The sigma values uses the errors of searches 1 and 2 for an obvious reason, this is a reasonable estimate of where in\n",
        "parameter space the model-fit can be expected to provide a good fit to the data. However, we may want to specify \n",
        "even larger sigma values on certain parameters, if for example we anticipate that our earlier searches may under \n",
        "estimate the errors.\n",
        "\n",
        "The `width_modifier` term in the `Gaussian` section of the `config/priors/gaussian.ini` is used instead of the errors \n",
        "of a search, when the errors estimated are smaller  than the `width_modifier` value. This ensure that the sigma \n",
        "values used in later searches do not assume extremely small values if earlier searches risk under estimating the errors.\n",
        "\n",
        "Thus, search 3 used the results of searches 1 and 2 to inform it where to search non-linear parameter space! \n",
        "\n",
        "The `PriorPasser` customizes how priors are passed from a search as follows:\n",
        "\n",
        " - sigma: The sigma value of the errors passed to set the sigma values in the previous search are estimated at.\n",
        " - use_widths: If False, the \"width_modifier\" values in the json_prior configs are not used to override a passed\n",
        " error value.\n",
        " - use_errors: If False, errors are not passed from search 1 to set up the priors and only the `width_modifier`\n",
        "  entries in the configs are used.  \n",
        "\n",
        "There are two ways a value is specified using the priors/width file:\n",
        "\n",
        " 1) Absolute: In this case, the error assumed on the parameter is the value given in the config file. \n",
        "  For example, if for the width on `centre` the width modifier reads \"Absolute\" with a value 20.0, this means if the \n",
        "  error on the parameter `centre` was less than 20.0 in the previous search, the sigma of its `GaussianPrior` in \n",
        "  the next search will be 20.0.\n",
        "\n",
        " 2) Relative: In this case, the error assumed on the parameter is the % of the value of the estimate value given in \n",
        " the config file. For example, if the intensity estimated in the previous search was 2.0, and the relative error in \n",
        " the config file reads \"Relative\" with a value 0.5, then the sigma of the `GaussianPrior` \n",
        "  will be 50% of this value, i.e. sigma = 0.5 * 2.0 = 1.0.\n",
        "\n",
        "We use absolute and relative values for different parameters, depending on their properties. For example, using the \n",
        "relative value of a parameter like the `centre` makes no sense as the profile could be centred at 0.0, making \n",
        "the relative error tiny and poorly defined.\n",
        "\n",
        "However, there are parameters where using an absolute value does not make sense. Intensity is a good example of this. \n",
        "The intensity of an image depends on its units and S/N. There is no single absolute value that one can use to \n",
        "generically chain the intensity of any two proflies. Thus, it makes more sense to chain them using the relative value \n",
        "from a previous search.\n",
        "\n",
        "We can customize how priors are passed from the results of a search and `NonLinearSearch` by inputting to the search \n",
        "a `PriorPasser` object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.DynestyStatic(\n",
        "    prior_passer=af.PriorPasser(sigma=2.0, use_widths=False, use_errors=True)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `PriorPasser` allows us to customize at what sigma the error values the model results are computed at to compute\n",
        "the passed sigma values and customizes whether the widths in the config file, these computed errors, or both, \n",
        "are used to set the sigma values of the passed priors.\n",
        "\n",
        "The default values of the `PriorPasser` are found in the config file of every non-linear search, in the [prior_passer]\n",
        "section. All non-linear searches by default use a sigma value of 3.0, use_width=True and use_errors=True.\n",
        "\n",
        "__EXAMPLE__\n",
        "\n",
        "Lets go through an example using a real parameter. Lets say in search 1 we fit a `Gaussian` and we estimate that \n",
        "its intensity is equal to 4.0 +- 2.0 where the error value of 2.0 was computed at 3.0 sigma confidence. To pass this \n",
        "as a prior to search 2, we would write:\n",
        "\n",
        "    gaussian.intensity = search_1_result.model.gaussian.intensity\n",
        "\n",
        "The prior on the `Gaussian` `intensity` in search 2 would thus be a `GaussianPrior`, with mean=4.0 and \n",
        "sigma=2.0. If we had used a sigma value of 1.0 to compute the error, which reduced the estimate from 4.0 +- 2.0 to \n",
        "4.0 +- 1.0, the sigma of the `GaussianPrior` would instead be 1.0. \n",
        "\n",
        "If the error on the intensity in search 1 had been really small, lets say, 0.01, we would instead use the value of the \n",
        "intensity width in the priors config file to set sigma instead. In this case, the prior config file specifies \n",
        "that we use an \"Relative\" value of 0.5 to chain this prior. Thus, the GaussianPrior in search 2 would have a mean=4.0 \n",
        "and sigma=2.0.\n",
        "\n",
        "And with that, we`re done. Chaining searches is a bit of an art form, but for certain problems can be extremely \n",
        "powerful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}