{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Feature: Model Comparison\n",
        "=========================\n",
        "\n",
        "Common questions when fitting a model to data are: what model should I use? How many parameters should the model have? \n",
        "Is the model too complex or too simple?\n",
        "\n",
        "Model comparison answers to these questions. It amounts to composing and fitting many different models to the data \n",
        "and comparing how well they fit the data. \n",
        "\n",
        "This example illustrates model comparison using the noisy 1D Gaussian example. We fit a dataset consisting of two \n",
        "Gaussians and fit it with three models comprised of 1, 2 and 3 Gaussian's respectively. Using the Bayesian evidence to \n",
        "compare the models, we favour the model with 2 Gaussians, which is the \"correct\" model given that it was the model used \n",
        "to simulate the dataset in the first place.\n",
        "\n",
        "__Metrics__\n",
        "\n",
        "Different metrics can be used compare models and quantify their goodness-of-fit.\n",
        "\n",
        "In this example we show the results of using two different metrics:\n",
        "\n",
        " - `log_likelihood`: The value returned by the `log_likelihood_function` of an `Analysis` object. which is directly \n",
        "   related to the sum of the residuals squared (e.g. the `chi_squared`). The log likelihood does not change when more \n",
        "   or less parameters are included in the model, therefore it does not account for over-fitting and will often favour \n",
        "   more complex models irrespective of whether they fit the data better.\n",
        " \n",
        " - `log_evidence`: The Bayesian evidence, which is closely related to the log likelihood but utilizes additional\n",
        "   information which penalizes models based on their complexity. The Bayesian evidence will therefore favour simpler\n",
        "   models over more complex models, unless the more complex model provides a much better fit to the data.\n",
        "   \n",
        "__Example Source Code (`af.ex`)__\n",
        "\n",
        "The **PyAutoFit** source code has the following example objects (accessed via `af.ex`) used in this tutorial:\n",
        "\n",
        " - `Analysis`: an analysis object which fits noisy 1D datasets, including `log_likelihood_function` and \n",
        " `visualize` functions.\n",
        " \n",
        " - `Gaussian`: a model component representing a 1D Gaussian profile.\n",
        "\n",
        "These are functionally identical to the `Analysis` and `Gaussian` objects you have seen elsewhere in the workspace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from os import path\n",
        "\n",
        "import autofit as af"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Data__\n",
        "\n",
        "Load data of a 1D Gaussian from a .json file in the directory `autofit_workspace/dataset/gaussian_x2`.\n",
        "\n",
        "This 1D data was created using two 1D Gaussians, therefore model comparison should favor a model with two Gaussians over \n",
        "a models with 1 or 3 Gaussians."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = path.join(\"dataset\", \"example_1d\", \"gaussian_x2\")\n",
        "data = af.util.numpy_array_from_json(file_path=path.join(dataset_path, \"data.json\"))\n",
        "noise_map = af.util.numpy_array_from_json(\n",
        "    file_path=path.join(dataset_path, \"noise_map.json\")\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "xvalues = range(data.shape[0])\n",
        "\n",
        "plt.errorbar(\n",
        "    x=xvalues,\n",
        "    y=data,\n",
        "    yerr=noise_map,\n",
        "    color=\"k\",\n",
        "    ecolor=\"k\",\n",
        "    linestyle=\" \",\n",
        "    elinewidth=1,\n",
        "    capsize=2,\n",
        ")\n",
        "plt.title(\"1D Gaussian Dataset Used For Model Comparison.\")\n",
        "plt.xlabel(\"x values of profile\")\n",
        "plt.ylabel(\"Profile normalization\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model x1 Gaussian__\n",
        "\n",
        "Create a model to fit the data, starting with a model where the data is fitted with 1 Gaussian."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = af.Collection(gaussian_0=af.ex.Gaussian)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model in a readable format, showing it contains one `Gaussian`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the analysis which fits the model to the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = af.ex.Analysis(data=data, noise_map=noise_map)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit the data using a non-linear search, to determine the goodness of fit of this model.\n",
        "\n",
        "We use the nested sampling algorithm Dynesty, noting that the Bayesian evidence (`log_evidence`) of a model can only\n",
        "be estimated using a nested sampling algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.DynestyStatic(\n",
        "    path_prefix=path.join(\"features\", \"model_comparison\"),\n",
        "    name=\"gaussian_x1\",\n",
        "    nlive=50,\n",
        "    iterations_per_update=3000,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Perform the fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result_x1_gaussian = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The results are concisely summarised using the `result.info` property.\n",
        "\n",
        "These show that the parameters of the Gaussian are well constrained, with small errors on their inferred values.\n",
        "However, it does not inform us of whether the model provides a good fit to the data overall."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result_x1_gaussian.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The maximum log likelihood model is used to visualize the fit.\n",
        "\n",
        "For 1 Gaussian, residuals are visible, whereby the model Gaussian cannot fit the highest central data-point and \n",
        "there is a mismatch at the edges of the profile around pixels 40 and 60.\n",
        "\n",
        "Based on visual inspection, the model therefore provides a poor fit to the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "instance = result_x1_gaussian.max_log_likelihood_instance\n",
        "\n",
        "gaussian_0 = instance.gaussian_0.model_data_1d_via_xvalues_from(\n",
        "    xvalues=np.arange(data.shape[0])\n",
        ")\n",
        "model_data = gaussian_0\n",
        "\n",
        "plt.errorbar(\n",
        "    x=xvalues,\n",
        "    y=data,\n",
        "    yerr=noise_map,\n",
        "    color=\"k\",\n",
        "    ecolor=\"k\",\n",
        "    linestyle=\" \",\n",
        "    elinewidth=1,\n",
        "    capsize=2,\n",
        ")\n",
        "plt.plot(range(data.shape[0]), model_data, color=\"r\")\n",
        "plt.plot(range(data.shape[0]), gaussian_0, \"--\")\n",
        "plt.title(\"Model fit using 1 Gaussian.\")\n",
        "plt.xlabel(\"x values of profile\")\n",
        "plt.ylabel(\"Profile normalization\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print the `log_likelihood` and `log_evidence` of this model-fit, which we will compare to more complex models in order \n",
        "to determine which model provides the best fit to the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"1 Gaussian:\")\n",
        "print(f\"Log Likelihood: {result_x1_gaussian.samples.max_log_likelihood()}\")\n",
        "print(f\"Log Evidence: {result_x1_gaussian.samples.log_evidence}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model x2 Gaussian__\n",
        "\n",
        "We now create a model to fit the data which consists of 2 Gaussians."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = af.Collection(gaussian_0=af.ex.Gaussian, gaussian_1=af.ex.Gaussian)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model now consists of two `Gaussian`'s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We repeat the steps above to create the non-linear search and perform the model-fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.DynestyStatic(\n",
        "    path_prefix=path.join(\"features\", \"model_comparison\"),\n",
        "    name=\"gaussian_x2\",\n",
        "    nlive=50,\n",
        "    iterations_per_update=3000,\n",
        ")\n",
        "\n",
        "result_x2_gaussian = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The results show that two Gaussians have now been fitted to the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result_x2_gaussian.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualizing the fit, we see that the problems with the previous fit have been addressed. The central data-point at the \n",
        "highest normalization is fitted correctly and the residuals at the edges of the profile around pixels 40 and 60 are \n",
        "significantly reduced.\n",
        "\n",
        "There are effectively no residuals, indicating that the model provides a good fit to the data.\n",
        "\n",
        "The residuals are so small that they are consistent with noise in the data. One therefore should not expect that \n",
        "a more complex model than one with 2 Gaussians can provide a better fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "instance = result_x2_gaussian.max_log_likelihood_instance\n",
        "\n",
        "gaussian_0 = instance.gaussian_0.model_data_1d_via_xvalues_from(\n",
        "    xvalues=np.arange(data.shape[0])\n",
        ")\n",
        "gaussian_1 = instance.gaussian_0.model_data_1d_via_xvalues_from(\n",
        "    xvalues=np.arange(data.shape[0])\n",
        ")\n",
        "model_data = gaussian_0 + gaussian_1\n",
        "\n",
        "plt.errorbar(\n",
        "    x=xvalues,\n",
        "    y=data,\n",
        "    yerr=noise_map,\n",
        "    color=\"k\",\n",
        "    ecolor=\"k\",\n",
        "    linestyle=\" \",\n",
        "    elinewidth=1,\n",
        "    capsize=2,\n",
        ")\n",
        "plt.plot(range(data.shape[0]), model_data, color=\"r\")\n",
        "plt.plot(range(data.shape[0]), gaussian_0, \"--\")\n",
        "plt.plot(range(data.shape[0]), gaussian_1, \"--\")\n",
        "plt.title(\"Model fit using 2 Gaussian.\")\n",
        "plt.xlabel(\"x values of profile\")\n",
        "plt.ylabel(\"Profile normalization\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print the `log_likelihood` and `log_evidence` of this model-fit, and compare these values to the previous model-fit\n",
        "which used 1 Gaussian."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"1 Gaussian:\")\n",
        "print(f\"Log Likelihood: {max(result_x1_gaussian.samples.log_likelihood_list)}\")\n",
        "print(f\"Log Evidence: {result_x1_gaussian.samples.log_evidence}\")\n",
        "\n",
        "print(\"2 Gaussians:\")\n",
        "print(f\"Log Likelihood: {max(result_x2_gaussian.samples.log_likelihood_list)}\")\n",
        "print(f\"Log Evidence: {result_x2_gaussian.samples.log_evidence}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Both the `log_likelihood` and `log_evidence` have increased significantly, indicating that the model with 2 Gaussians\n",
        "is favored over the model with 1 Gaussian.\n",
        "\n",
        "This is expected, as we know the data was generated using 2 Gaussians!\n",
        "\n",
        "__Model x3 Gaussian__\n",
        "\n",
        "We now create a model to fit the data which consists of 3 Gaussians."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = af.Collection(\n",
        "    gaussian_0=af.ex.Gaussian, gaussian_1=af.ex.Gaussian, gaussian_2=af.ex.Gaussian\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model consists of three `Gaussian`'s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We repeat the steps above to create the non-linear search and perform the model-fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.DynestyStatic(\n",
        "    path_prefix=path.join(\"features\", \"model_comparison\"),\n",
        "    name=\"gaussian_x3\",\n",
        "    nlive=50,\n",
        "    iterations_per_update=3000,\n",
        ")\n",
        "\n",
        "result_x3_gaussian = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The results show that three Gaussians have now been fitted to the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result_x3_gaussian.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualizing the fit, we see that there are effectively no residuals, indicating that the model provides a good fit.\n",
        "\n",
        "By eye, this fit is as good as the 2 Gaussian model above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "instance = result_x3_gaussian.max_log_likelihood_instance\n",
        "\n",
        "gaussian_0 = instance.gaussian_0.model_data_1d_via_xvalues_from(\n",
        "    xvalues=np.arange(data.shape[0])\n",
        ")\n",
        "gaussian_1 = instance.gaussian_0.model_data_1d_via_xvalues_from(\n",
        "    xvalues=np.arange(data.shape[0])\n",
        ")\n",
        "gaussian_2 = instance.gaussian_0.model_data_1d_via_xvalues_from(\n",
        "    xvalues=np.arange(data.shape[0])\n",
        ")\n",
        "model_data = gaussian_0 + gaussian_1 + gaussian_2\n",
        "\n",
        "plt.errorbar(\n",
        "    x=xvalues,\n",
        "    y=data,\n",
        "    yerr=noise_map,\n",
        "    color=\"k\",\n",
        "    ecolor=\"k\",\n",
        "    linestyle=\" \",\n",
        "    elinewidth=1,\n",
        "    capsize=2,\n",
        ")\n",
        "plt.plot(range(data.shape[0]), model_data, color=\"r\")\n",
        "plt.plot(range(data.shape[0]), gaussian_0, \"--\")\n",
        "plt.plot(range(data.shape[0]), gaussian_1, \"--\")\n",
        "plt.plot(range(data.shape[0]), gaussian_2, \"--\")\n",
        "plt.title(\"Model fit using 3 Gaussian.\")\n",
        "plt.xlabel(\"x values of profile\")\n",
        "plt.ylabel(\"Profile normalization\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We print the `log_likelihood` and `log_evidence` of this model-fit, and compare these values to the previous model-fit\n",
        "which used 1 and 2 Gaussian."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"1 Gaussian:\")\n",
        "print(f\"Log Likelihood: {max(result_x1_gaussian.samples.log_likelihood_list)}\")\n",
        "print(f\"Log Evidence: {result_x1_gaussian.samples.log_evidence}\")\n",
        "\n",
        "print(\"2 Gaussians:\")\n",
        "print(f\"Log Likelihood: {max(result_x2_gaussian.samples.log_likelihood_list)}\")\n",
        "print(f\"Log Evidence: {result_x2_gaussian.samples.log_evidence}\")\n",
        "\n",
        "print(\"3 Gaussians:\")\n",
        "print(f\"Log Likelihood: {max(result_x3_gaussian.samples.log_likelihood_list)}\")\n",
        "print(f\"Log Evidence: {result_x3_gaussian.samples.log_evidence}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now see an interesting result. The `log_likelihood` of the 3 Gaussian model is higher than the 2 Gaussian model\n",
        "(albeit, only slightly higher). However, the `log_evidence` is lower than the 2 Gaussian model.\n",
        "\n",
        "This confirms the behavior discussed at the start of the tutorial. The Bayesian evidence penalizes models with more \n",
        "freedom to fit the data, unless they provide a significantly better fit to the data. Using the evidence we favor the\n",
        "2 Gaussian model over the 3 Gaussian model for this reason, whereas using the likelihood we favor the 3 Gaussian model.\n",
        "\n",
        "__Wrap Up__\n",
        "\n",
        "Discuss Priors. Discuss unique id and benefits of autofit / science workflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}