{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Feature: Sensitivity Mapping\n",
        "============================\n",
        "\n",
        "Bayesian model comparison allows us to take a dataset, fit it with multiple models and use the Bayesian evidence to\n",
        "quantify which model objectively gives the best-fit following the principles of Occam's Razor.\n",
        "\n",
        "However, a complex model may not be favoured by model comparison not because it is the 'wrong' model, but simply\n",
        "because the dataset being fitted is not of a sufficient quality for the more complex model to be favoured. Sensitivity\n",
        "mapping addresses what quality of data would be needed for the more complex model to be favoured.\n",
        "\n",
        "In order to do this, sensitivity mapping involves us writing a function that uses the model(s) to simulate a dataset.\n",
        "We then use this function to simulate many datasets, for different models, and fit each dataset to quantify\n",
        "how much the change in the model led to a measurable change in the data. This is called computing the sensitivity.\n",
        "\n",
        "How we compute the sensitivity is chosen by us, the user. In this example, we will perform multiple model-fits\n",
        "with a nested sampling search, and therefore perform Bayesian model comparison to compute the sensitivity. This allows \n",
        "us to infer how much of a Bayesian evidence increase we should expect for datasets of varying quality and / or models \n",
        "with different parameters.\n",
        "\n",
        "__Example Source Code (`af.ex`)__\n",
        "\n",
        "The **PyAutoFit** source code has the following example objects (accessed via `af.ex`) used in this tutorial:\n",
        "\n",
        " - `Analysis`: an analysis object which fits noisy 1D datasets, including `log_likelihood_function` and\n",
        " `visualize` functions.\n",
        "\n",
        " - `Gaussian`: a model component representing a 1D Gaussian profile.\n",
        "\n",
        "These are functionally identical to the `Analysis` and `Gaussian` objects you have seen elsewhere in the workspace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from os import path\n",
        "\n",
        "import autofit as af"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Data__\n",
        "\n",
        "Load data of a 1D Gaussian from a .json file in the directory \n",
        "`autofit_workspace/dataset/gaussian_x1_with_feature`.\n",
        "\n",
        "This 1D data includes a small feature to the right of the central `Gaussian`. This feature is a second `Gaussian` \n",
        "centred on pixel 70. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = path.join(\"dataset\", \"example_1d\", \"gaussian_x1_with_feature\")\n",
        "data = af.util.numpy_array_from_json(file_path=path.join(dataset_path, \"data.json\"))\n",
        "noise_map = af.util.numpy_array_from_json(\n",
        "    file_path=path.join(dataset_path, \"noise_map.json\")\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets plot the data. \n",
        "\n",
        "The feature on pixel 70 is clearly visible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "xvalues = range(data.shape[0])\n",
        "\n",
        "plt.errorbar(\n",
        "    x=xvalues,\n",
        "    y=data,\n",
        "    yerr=noise_map,\n",
        "    linestyle=\"\",\n",
        "    color=\"k\",\n",
        "    ecolor=\"k\",\n",
        "    elinewidth=1,\n",
        "    capsize=2,\n",
        ")\n",
        "plt.title(\"1D Gaussian Data With Feature at pixel 70.\")\n",
        "plt.xlabel(\"x values of profile\")\n",
        "plt.ylabel(\"Profile normalization\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "Create the analysis which fits the model to the data.\n",
        "\n",
        "It fits the data as the sum of the two `Gaussian`'s in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = af.ex.Analysis(data=data, noise_map=noise_map)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model Comparison__\n",
        "\n",
        "Before performing sensitivity mapping, we will quickly perform Bayesian model comparison on this data to get a sense \n",
        "for whether the `Gaussian` feature is detectable and how much the Bayesian evidence increases when it is included in\n",
        "the model.\n",
        "\n",
        "We therefore fit the data using two models, one where the model is a single `Gaussian` and one where it is \n",
        "two `Gaussians`. \n",
        "\n",
        "To avoid slow model-fitting and more clearly prounce the results of model comparison, we restrict the centre of \n",
        "the`gaussian_feature` to its true centre of 70 and sigma value of 0.5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = af.Collection(gaussian_main=af.ex.Gaussian)\n",
        "\n",
        "search = af.DynestyStatic(\n",
        "    path_prefix=path.join(\"features\", \"sensitivity_mapping\"),\n",
        "    name=\"single_gaussian\",\n",
        "    unique_tag=\"hello\",\n",
        "    nlive=100,\n",
        ")\n",
        "\n",
        "result_single = search.fit(model=model, analysis=analysis)\n",
        "\n",
        "model = af.Collection(gaussian_main=af.ex.Gaussian, gaussian_feature=af.ex.Gaussian)\n",
        "model.gaussian_feature.centre = 70.0\n",
        "model.gaussian_feature.sigma = 0.5\n",
        "\n",
        "search = af.DynestyStatic(\n",
        "    path_prefix=path.join(\"features\", \"sensitivity_mapping\", \"two_gaussians\"), nlive=100\n",
        ")\n",
        "\n",
        "result_multiple = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now print the `log_evidence` of each fit and confirm the model with two `Gaussians` was preferred to the model\n",
        "with just one `Gaussian`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result_single.samples.log_evidence)\n",
        "print(result_multiple.samples.log_evidence)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Sensitivity Mapping__\n",
        "\n",
        "The model comparison above shows that in this dataset, the `Gaussian` feature was detectable and that it increased the \n",
        "Bayesian evidence by ~25. Furthermore, the normalization of this `Gaussian` was ~0.3. \n",
        "\n",
        "A lower value of normalization makes the `Gaussian` fainter and harder to detect. We will demonstrate sensitivity \n",
        "mapping by answering the following question, at what value of normalization does the `Gaussian` feature become \n",
        "undetectable and not provide us with a noticeable increase in Bayesian evidence?\n",
        "\n",
        "__Base Model__\n",
        "\n",
        "To begin, we define the `base_model` that we use to perform sensitivity mapping. This model is used to simulate every \n",
        "dataset. It is also fitted to every simulated dataset without the extra model component below, to give us the Bayesian\n",
        "evidence of the every simpler model to compare to the more complex model. \n",
        "\n",
        "The `base_model` corresponds to the `gaussian_main` above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "base_model = af.Collection(gaussian_main=af.ex.Gaussian)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Perturb Model__\n",
        "\n",
        "We now define the `perturb_model`, which is the model component whose parameters we iterate over to perform \n",
        "sensitivity mapping. Many instances of the `perturb_model` are created and used to simulate the many datasets \n",
        "that we fit. However, it is only included in half of the sensitivity mapping models, corresponding to the more complex \n",
        "models whose Bayesian evidence we compare to the simpler model-fits consisting of just the `base_model`.\n",
        "\n",
        "The `perturb_model` is therefore another `Gaussian` but now corresponds to the `gaussian_feature` above.\n",
        "\n",
        "By fitting both of these models to every simulated dataset, we will therefore infer the Bayesian evidence of every\n",
        "model to every dataset. Sensitivity mapping therefore maps out for what values of `normalization` in \n",
        "the `gaussian_feature` does the more complex model-fit provide higher values of Bayesian evidence than the simpler\n",
        "model-fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "perturb_model = af.Model(af.ex.Gaussian)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mapping Grid__\n",
        "\n",
        "Sensitivity mapping is performed over a large grid of model parameters. To make this demonstration quick and clear we \n",
        "are going to fix the `centre` and `sigma` values to the true values of the `gaussian_feature`. We will also iterate \n",
        "over just two `normalization` values corresponding to 0.01 and 100.0, which will exhaggerate the difference in\n",
        "sensitivity between the models at these two values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "perturb_model.centre = 70.0\n",
        "perturb_model.sigma = 0.5\n",
        "perturb_model.normalization = af.UniformPrior(lower_limit=0.01, upper_limit=100.0)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Simulation Instance__\n",
        "\n",
        "We are performing sensitivity mapping to determine how bright the `gaussian_feature` needs to be in order to be \n",
        "detectable. However, every simulated dataset must include the `main_gaussian`, as its presence in the data will effect\n",
        "the detectability of the `gaussian_feature`.\n",
        "\n",
        "We can pass the `main_gaussian` into the sensitivity mapping as the `simulation_instance`, meaning that it will be used \n",
        "in the simulation of every dataset. For this example we use the inferred `main_gaussian` from one of the model-fits\n",
        "performed above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "simulation_instance = result_single.instance"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Simulate Function Class__\n",
        "\n",
        "We are about to write a `simulate_cls` that simulates examples of 1D `Gaussian` datasets that are fitted to\n",
        "perform sensitivity mapping.\n",
        "\n",
        "To pass each simulated data through **PyAutoFit**'s sensitivity mapping tools, the function must return a single \n",
        "Python object. We therefore define a `Dataset` class that combines the `data` and `noise_map` that are to be \n",
        "output by this `simulate_cls`.\n",
        "\n",
        "It is also convenient to define a `Analysis` class, which behaves analogously to the `Analysis` class used in\n",
        "PyAutoFit to fit a model to data. In this example it makes it easy to define how we fit each simulated dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "class Dataset:\n",
        "    def __init__(self, data, noise_map):\n",
        "        self.data = data\n",
        "        self.noise_map = noise_map\n",
        "\n",
        "\n",
        "class Analysis(af.ex.Analysis):\n",
        "    def __init__(self, dataset):\n",
        "        super().__init__(data=dataset.data, noise_map=dataset.noise_map)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now write the `simulate_cls`, which takes the `simulation_instance` of our model (defined above) and uses it to \n",
        "simulate a dataset which is subsequently fitted. \n",
        "\n",
        "Additional attributes required to simulate the data can be passed to the `__init__` method, and the simulation is \n",
        "performed in the `__call__` method.\n",
        "\n",
        "Note that when this dataset is simulated, the quantity `instance.perturb` is used in `__call__`.\n",
        "This is an instance of the `gaussian_feature`, and it is different every time the `simulate_cls` is called. \n",
        "\n",
        "In this example, this `instance.perturb` corresponds to two different `gaussian_feature` with values of\n",
        "`normalization` of 0.01 and 100.0, such that our simulated datasets correspond to a very faint and very bright gaussian \n",
        "features ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "class Simulate:\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Class used to simulate every dataset used for sensitivity mapping.\n",
        "\n",
        "        This `__init__` constructor can be extended with new inputs which can be used to control how the dataset is\n",
        "        simulated in the `__call__` simulate_function below.\n",
        "\n",
        "        In this example we leave it empty as our `simulate_function` does not require any additional information.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def __call__(self, instance, simulate_path):\n",
        "        \"\"\"\n",
        "        The `simulate_function` called by the `Sensitivity` class which simulates each dataset fitted\n",
        "        by the sensitivity mapper.\n",
        "\n",
        "        The simulation procedure is as follows:\n",
        "\n",
        "        1) Use the input sensitivity `instance` to simulate the data with the small Gaussian feature.\n",
        "\n",
        "        2) Output information about the simulation to hard-disk.\n",
        "\n",
        "        3) Return the data for the sensitivity mapper to fit.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        instance\n",
        "            The sensitivity instance, which includes the Gaussian feature parameters are varied to perform sensitivity.\n",
        "            The Gaussian feature in this instance changes for every iteration of the sensitivity mapping.\n",
        "        simulate_path\n",
        "            The path where the simulated dataset is output, contained within each sub-folder of the sensitivity\n",
        "            mapping.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        A simulated image of a Gaussian, which i input into the fits of the sensitivity mapper.\n",
        "        \"\"\"\n",
        "\n",
        "        \"\"\"\n",
        "        Specify the number of pixels used to create the xvalues on which the 1D line of the profile is generated \n",
        "        using and thus defining the number of data-points in our data.\n",
        "        \"\"\"\n",
        "        pixels = 100\n",
        "        xvalues = np.arange(pixels)\n",
        "\n",
        "        \"\"\"\n",
        "        Evaluate the `Gaussian` and Exponential model instances at every xvalues to create their model profile \n",
        "        and sum them together to create the overall model profile.\n",
        "\n",
        "        This print statement will show that, when you run `Sensitivity` below the values of the perturbation \n",
        "        use fixed  values of `centre=70` and `sigma=0.5`, whereas the normalization varies over the `number_of_steps` \n",
        "        based on its prior.\n",
        "        \"\"\"\n",
        "\n",
        "        print(instance.perturb.centre)\n",
        "        print(instance.perturb.normalization)\n",
        "        print(instance.perturb.sigma)\n",
        "\n",
        "        model_line = instance.gaussian_main.model_data_from(\n",
        "            xvalues=xvalues\n",
        "        ) + instance.perturb.model_data_from(xvalues=xvalues)\n",
        "\n",
        "        \"\"\"\n",
        "        Determine the noise (at a specified signal to noise level) in every pixel of our model profile.\n",
        "        \"\"\"\n",
        "        signal_to_noise_ratio = 25.0\n",
        "        noise = np.random.normal(0.0, 1.0 / signal_to_noise_ratio, pixels)\n",
        "\n",
        "        \"\"\"\n",
        "        Add this noise to the model line to create the line data that is fitted, using the signal-to-noise ratio \n",
        "        to compute noise-map of our data which is required when evaluating the chi-squared value of the likelihood.\n",
        "        \"\"\"\n",
        "        data = model_line + noise\n",
        "        noise_map = (1.0 / signal_to_noise_ratio) * np.ones(pixels)\n",
        "\n",
        "        return Dataset(data=data, noise_map=noise_map)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Base Fit__\n",
        "\n",
        "We have defined a `Simulate` class that will be used to simulate every dataset simulated by the sensitivity mapper.\n",
        "Each simulated dataset will have a unique set of parameters for the `gaussian_feature` (e.g. due to different values of\n",
        "`perturb_model`.\n",
        "\n",
        "We will fit each simulated dataset using the `base_model`, which quantifies whether not including the Gaussian feature\n",
        "in the model changes the goodness-of-fit and therefore indicates if we are sensitive to the Gaussian feature.\n",
        "\n",
        "We now write a `BaseFit` class, defining how the `base_model` is fitted to each simulated dataset and \n",
        "the goodness-of-fit used to quantify whether the model fits the data well. As above, the `__init__` method can be\n",
        "extended with new inputs to control how the model is fitted and the `__call__` method performs the fit.\n",
        "\n",
        "In this example, we use a full non-linear search to fit the `base_model` to the simulated data and return\n",
        "the `log_evidence` of the model fit as the goodness-of-fit. This fit could easily be something much simpler and\n",
        "more computationally efficient, for example performing a single log likelihood evaluation of the `base_model` fit\n",
        "to the simulated data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "class BaseFit:\n",
        "    def __init__(self, analysis_cls):\n",
        "        \"\"\"\n",
        "        Class used to fit every dataset used for sensitivity mapping with the base model (the model without the\n",
        "        perturbed feature sensitivity mapping maps out).\n",
        "\n",
        "        In this example, the base model therefore does not include the extra Gaussian feature, but the simulated\n",
        "        dataset includes one.\n",
        "\n",
        "        The base fit is repeated for every parameter on the sensitivity grid and compared to the perturbed fit. This\n",
        "        maps out the sensitivity of every parameter is (e.g. the sensitivity of the normalization of the Gaussian\n",
        "        feature).\n",
        "\n",
        "        The `__init__` constructor can be extended with new inputs which can be used to control how the dataset is\n",
        "        fitted, below we include an input `analysis_cls` which is the `Analysis` class used to fit the model to the\n",
        "        dataset.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        analysis_cls\n",
        "            The `Analysis` class used to fit the model to the dataset.\n",
        "        \"\"\"\n",
        "        self.analysis_cls = analysis_cls\n",
        "\n",
        "    def __call__(self, dataset, model, paths, instance):\n",
        "        \"\"\"\n",
        "        The base fitting function which fits every dataset used for sensitivity mapping with the base model.\n",
        "\n",
        "        This function receives as input each simulated dataset of the sensitivity map and fits it, in order to\n",
        "        quantify how sensitive the model is to the perturbed feature.\n",
        "\n",
        "        In this example, a full non-linear search is performed to determine how well the model fits the dataset.\n",
        "        The `log_evidence` of the fit is returned which acts as the sensitivity map figure of merit.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        dataset\n",
        "            The dataset which is simulated with the perturbed model and which is fitted.\n",
        "        model\n",
        "            The model instance which is fitted to the dataset, which does not include the perturbed feature.\n",
        "        paths\n",
        "            The `Paths` instance which contains the path to the folder where the results of the fit are written to.\n",
        "        instance\n",
        "            The simulation instance, which includes the perturbed feature that is used to simulate the dataset.\n",
        "            This is often not used, but may be useful for certain sensitivity mapping tasks, for example using\n",
        "            true values of the simulated instance to set up aspects of the model-fit (e.g. the priors).\n",
        "        \"\"\"\n",
        "\n",
        "        search = af.DynestyStatic(\n",
        "            paths=paths.for_sub_analysis(analysis_name=\"[base]\"),\n",
        "            nlive=50,\n",
        "            iterations_per_update=50000,\n",
        "        )\n",
        "\n",
        "        analysis = self.analysis_cls(dataset=dataset)\n",
        "\n",
        "        return search.fit(model=model, analysis=analysis)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Perturb Fit__\n",
        "\n",
        "We now define a `PerturbFit` class, which defines how the `perturb_model` is fitted to each simulated dataset. This\n",
        "behaves analogously to the `BaseFit` class above, but now fits the `perturb_model` to the simulated data (as\n",
        "opposed to the `base_model`).\n",
        "\n",
        "Again, in this example we use a full non-linear search to fit the `perturb_model` to the simulated data and return\n",
        "the `log_evidence` of the model fit as the goodness-of-fit. This fit could easily be something much simpler and\n",
        "more computationally efficient, for example performing a single log likelihood evaluation of the `perturb_model` fit\n",
        "to the simulated data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "class PerturbFit:\n",
        "    def __init__(self, analysis_cls):\n",
        "        \"\"\"\n",
        "        Class used to fit every dataset used for sensitivity mapping with the perturbed model (the model with the\n",
        "        perturbed feature sensitivity mapping maps out).\n",
        "\n",
        "        In this example, the perturbed model therefore includes the extra Gaussian feature, which is also in the\n",
        "        simulated dataset.\n",
        "\n",
        "        The perturbed fit is repeated for every parameter on the sensitivity grid and compared to the base fit. This\n",
        "        maps out the sensitivity of every parameter is (e.g. the sensitivity of the normalization of the Gaussian\n",
        "        feature).\n",
        "\n",
        "        The `__init__` constructor can be extended with new inputs which can be used to control how the dataset is\n",
        "        fitted, below we include an input `analysis_cls` which is the `Analysis` class used to fit the model to the\n",
        "        dataset.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        analysis_cls\n",
        "            The `Analysis` class used to fit the model to the dataset.\n",
        "        \"\"\"\n",
        "        self.analysis_cls = analysis_cls\n",
        "\n",
        "    def __call__(self, dataset, model, paths, instance):\n",
        "        \"\"\"\n",
        "        The perturbed fitting function which fits every dataset used for sensitivity mapping with the perturbed model.\n",
        "\n",
        "        This function receives as input each simulated dataset of the sensitivity map and fits it, in order to\n",
        "        quantify how sensitive the model is to the perturbed feature.\n",
        "\n",
        "        In this example, a full non-linear search is performed to determine how well the model fits the dataset.\n",
        "        The `log_evidence` of the fit is returned which acts as the sensitivity map figure of merit.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        dataset\n",
        "            The dataset which is simulated with the perturbed model and which is fitted.\n",
        "        model\n",
        "            The model instance which is fitted to the dataset, which includes the perturbed feature.\n",
        "        paths\n",
        "            The `Paths` instance which contains the path to the folder where the results of the fit are written to.\n",
        "        instance\n",
        "            The simulation instance, which includes the perturbed feature that is used to simulate the dataset.\n",
        "            This is often not used, but may be useful for certain sensitivity mapping tasks, for example using\n",
        "            true values of the simulated instance to set up aspects of the model-fit (e.g. the priors).\n",
        "        \"\"\"\n",
        "\n",
        "        search = af.DynestyStatic(\n",
        "            paths=paths.for_sub_analysis(analysis_name=\"[perturbed]\"),\n",
        "            nlive=50,\n",
        "            iterations_per_update=50000,\n",
        "        )\n",
        "\n",
        "        analysis = self.analysis_cls(dataset=dataset)\n",
        "\n",
        "        return search.fit(model=model, analysis=analysis)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now combine all of the objects created above and perform sensitivity mapping. The inputs to the `Sensitivity`\n",
        "object below are:\n",
        "\n",
        "- `simulation_instance`: This is an instance of the model used to simulate every dataset that is fitted. In this \n",
        "example it contains an instance of the `gaussian_main` model component.\n",
        "\n",
        "- `base_model`: This is the simpler model that is fitted to every simulated dataset, which in this example is composed \n",
        "of a single `Gaussian` called the `gaussian_main`.\n",
        "\n",
        "- `perturb_model`: This is the extra model component that has two roles: (i) based on the sensitivity grid parameters\n",
        "it is added to the `simulation_instance` to simulate each dataset ; (ii) it is added to the`base_model` and fitted to \n",
        "every simulated dataset (in this example every `simulation_instance` and `perturb_model` there has two `Gaussians` \n",
        "called the `gaussian_main` and `gaussian_feature`).\n",
        "\n",
        "- `simulate_cls`: This is the function that uses the `simulation_instance` and many instances of the `perturb_model` \n",
        "to simulate many datasets which are fitted with the `base_model` and `base_model` + `perturb_model`.\n",
        "\n",
        "- `base_fit_cls`: This is the function that fits the `base_model` to every simulated dataset and returns the\n",
        "goodness-of-fit of the model to the data.\n",
        "\n",
        "- `perturb_fit_cls`: This is the function that fits the `base_model` + `perturb_model` to every simulated dataset and\n",
        "returns the goodness-of-fit of the model to the data.\n",
        "\n",
        "- `number_of_steps`: The number of steps over which the parameters in the `perturb_model` are iterated. In this \n",
        "example, normalization has a `LogUniformPrior` with lower limit 1e-4 and upper limit 1e2, therefore the `number_of_steps` \n",
        "of 2 wills imulate and fit just 2 datasets where the intensities between 1e-4 and 1e2.\n",
        "\n",
        "- `number_of_cores`: The number of cores over which the sensitivity mapping is performed, enabling parallel processing\n",
        "if set above 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "paths = af.DirectoryPaths(\n",
        "    path_prefix=path.join(\"features\"),\n",
        "    unique_tag=\"hello\",\n",
        "    name=\"sensitivity_mapping\",\n",
        ")\n",
        "\n",
        "sensitivity = af.Sensitivity(\n",
        "    paths=paths,\n",
        "    simulation_instance=simulation_instance,\n",
        "    base_model=base_model,\n",
        "    perturb_model=perturb_model,\n",
        "    simulate_cls=Simulate(),\n",
        "    base_fit_cls=BaseFit(analysis_cls=Analysis),\n",
        "    perturb_fit_cls=PerturbFit(analysis_cls=Analysis),\n",
        "    number_of_steps=2,\n",
        "    number_of_cores=2,\n",
        ")\n",
        "sensitivity_result = sensitivity.run()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Results__\n",
        "\n",
        "You should now look at the results of the sensitivity mapping in the folder `output/features/sensitivity_mapping`. \n",
        "\n",
        "You will note the following 4 model-fits have been performed:\n",
        "\n",
        " - The `base_model` is fitted to a simulated dataset where the `simulation_instance` and \n",
        " a `perturb` with `normalization=0.01` are used.\n",
        "\n",
        " - The `base_model` + `perturb_model`  is fitted to a simulated dataset where the `simulation_instance` and \n",
        " a `perturb` with `normalization=0.01` are used.\n",
        "\n",
        " - The `base_model` is fitted to a simulated dataset where the `simulation_instance` and \n",
        " a `perturb` with `normalization=100.0` are used.\n",
        "\n",
        " - The `base_model` + `perturb_model`  is fitted to a simulated dataset where the `simulation_instance` and \n",
        " a `perturb` with `normalization=100.0` are used.\n",
        "\n",
        "The fit produced a `sensitivity_result`. \n",
        "\n",
        "We are still developing the `SensitivityResult` class to provide a data structure that better streamlines the analysis\n",
        "of results. If you intend to use sensitivity mapping, the best way to interpret the resutls is currently via\n",
        "**PyAutoFit**'s database and `Aggregator` tools. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(sensitivity_result.samples)\n",
        "print(sensitivity_result.log_evidences_base)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}