{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 4: Data and Models\n",
        "===========================\n",
        "\n",
        "Up to now, we've used used the `Aggregator` to load and inspect the `Result` and `Samples` of 3 model-fits.\n",
        "\n",
        "In this tutorial, we'll look at how write Python generators which use the `Aggregator` to inspect, interpret and plot\n",
        "the results of the model-fit, including fitting and plotting different models to our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autofit as af"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Database File__\n",
        "\n",
        "We begin by loading the database via the `.sqlite` file as we did in the previous tutorial. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "database_file = \"database_howtofit.sqlite\"\n",
        "agg = af.Aggregator.from_database(filename=database_file, completed_only=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Plot Function__\n",
        "\n",
        "We'll reuse the `plot_profile_1d` function of previous tutorials, however it now displays to the notebook as opposed to\n",
        "outputting the results to a .png file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_profile_1d(\n",
        "    xvalues, profile_1d, title=None, ylabel=None, errors=None, color=\"k\"\n",
        "):\n",
        "    plt.errorbar(\n",
        "        x=xvalues,\n",
        "        y=profile_1d,\n",
        "        yerr=errors,\n",
        "        color=color,\n",
        "        ecolor=\"k\",\n",
        "        elinewidth=1,\n",
        "        capsize=2,\n",
        "    )\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"x value of profile\")\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.show()\n",
        "    plt.clf()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset Loading__\n",
        "\n",
        "We can use the `Aggregator` to load a generator of every fit`s data, by changing the `output` attribute to the \n",
        "`data` attribute at the end of the aggregator.\n",
        "\n",
        "Note that in the `Analysis` class of tutorial 1, we specified that the `data` object would be saved to hard-disc using\n",
        "the `save_attributes` method, so that the `Aggregator` can load it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(len(agg))\n",
        "data_gen = agg.values(\"data\")\n",
        "print(\"Datas:\")\n",
        "print(list(data_gen), \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can plot the `data` using the `plot_profile_1d` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for data in agg.values(\"data\"):\n",
        "    plot_profile_1d(\n",
        "        xvalues=np.arange(data.shape[0]),\n",
        "        profile_1d=data,\n",
        "        title=\"Data\",\n",
        "        ylabel=\"Data Values\",\n",
        "        color=\"k\",\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can repeat the same trick to get the `noise_map` of every fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "noise_map_gen = agg.values(\"noise_map\")\n",
        "print(\"Noise-Maps:\")\n",
        "print(list(noise_map_gen), \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` dictionary we input into the `NonLinearSearch` is also available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for info in agg.values(\"info\"):\n",
        "    print(info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fitting via Lists__\n",
        "\n",
        "We're going to refit each dataset with the `max_log_likelihood_instance` of each model-fit and plot the residuals.\n",
        "\n",
        "(If you are unsure what the `zip` is doing below, it essentially combines the `data_gen`, `noise_map_gen` and\n",
        "`samples_gen` into one list such that we can iterate over them simultaneously)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples_gen = agg.values(\"samples\")\n",
        "data_gen = agg.values(\"data\")\n",
        "noise_map_gen = agg.values(\"noise_map\")\n",
        "\n",
        "for data, noise_map, samples in zip(data_gen, noise_map_gen, samples_gen):\n",
        "    instance = samples.max_log_likelihood()\n",
        "\n",
        "    xvalues = np.arange(data.shape[0])\n",
        "\n",
        "    model_data = sum([profile.model_data_from(xvalues=xvalues) for profile in instance])\n",
        "\n",
        "    residual_map = data - model_data\n",
        "\n",
        "    plot_profile_1d(\n",
        "        xvalues=xvalues,\n",
        "        profile_1d=residual_map,\n",
        "        title=\"Residual Map\",\n",
        "        ylabel=\"Residuals\",\n",
        "        color=\"k\",\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fitting via Generators__\n",
        "\n",
        "There is a problem with how we plotted the residuals above, can you guess what it is?\n",
        "\n",
        "We used lists! If we had fit a large sample of data, the above object would store the data of all objects \n",
        "simultaneously in memory on our hard-disk, likely crashing our laptop! To avoid this, we must write functions that \n",
        "manipulate the `Aggregator` generators as generators themselves. Below is an example function that performs the same \n",
        "task as above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "def plot_residuals_from(fit):\n",
        "    data = fit.value(name=\"dataset.data\")\n",
        "    noise_map = fit.value(name=\"dataset.noise_map\")\n",
        "\n",
        "    xvalues = np.arange(data.shape[0])\n",
        "\n",
        "    model_data = sum(\n",
        "        [profile.model_data_from(xvalues=xvalues) for profile in fit.instance]\n",
        "    )\n",
        "\n",
        "    residual_map = data - model_data\n",
        "\n",
        "    plot_profile_1d(\n",
        "        xvalues=xvalues,\n",
        "        profile_1d=residual_map,\n",
        "        title=\"Residual Map\",\n",
        "        ylabel=\"Residuals\",\n",
        "        color=\"k\",\n",
        "    )\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To manipulate this function as a generator using the `Aggregator`, we apply it to the `Aggregator`'s `map` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plot_residuals_gen = agg.map(func=plot_residuals_from)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets get the `max_log_likelihood_instance`s, as we did in tutorial 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "instances = [samps.max_log_likelihood() for samps in agg.values(\"samples\")]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Okay, we want to inspect the fit of each `max_log_likelihood_instance`. To do this, we reperform each fit.\n",
        "\n",
        "First, we need to create the `model_data` of every `max_log_likelihood_instance`. Lets begin by creating a list \n",
        "of profiles of every model-fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}