{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial Optional: Hierarchical Expectation Propagation (EP)\n",
        "============================================================\n",
        "\n",
        "This optional tutorial gives an example of fitting a hierarchical model using EP.\n",
        "\n",
        "The API is a straightforward combination of tutorials 3 and 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import numpy as np\n",
        "from os import path\n",
        "\n",
        "import autofit as af"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Example Source Code (`af.ex`)__\n",
        "\n",
        "The **PyAutoFit** source code has the following example objects (accessed via `af.ex`) used in this tutorial:\n",
        "\n",
        " - `Analysis`: an analysis object which fits noisy 1D datasets, including `log_likelihood_function` and \n",
        " `visualize` functions.\n",
        "\n",
        " - `Gaussian`: a model component representing a 1D Gaussian profile.\n",
        "\n",
        " - `plot_profile_1d`: a function for plotting 1D profile datasets including their noise.\n",
        "\n",
        "These are functionally identical to the `Analysis`, `Gaussian` and `plot_profile_1d` objects and functions you have seen \n",
        "and used elsewhere throughout the workspace.\n",
        "\n",
        "__Dataset__\n",
        "\n",
        "For each dataset we now set up the correct path and load it. \n",
        "\n",
        "In this example, the three Gaussians have different centres, which are drawn from a parent Gaussian distribution\n",
        "whose mean and scatter we aim to estimate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "total_datasets = 5\n",
        "\n",
        "dataset_name_list = []\n",
        "data_list = []\n",
        "noise_map_list = []\n",
        "\n",
        "for dataset_index in range(total_datasets):\n",
        "    dataset_name = f\"dataset_{dataset_index}\"\n",
        "\n",
        "    dataset_path = path.join(\n",
        "        \"dataset\", \"example_1d\", \"gaussian_x1__hierarchical\", dataset_name\n",
        "    )\n",
        "\n",
        "    data = af.util.numpy_array_from_json(file_path=path.join(dataset_path, \"data.json\"))\n",
        "    noise_map = af.util.numpy_array_from_json(\n",
        "        file_path=path.join(dataset_path, \"noise_map.json\")\n",
        "    )\n",
        "\n",
        "    dataset_name_list.append(dataset_name)\n",
        "    data_list.append(data)\n",
        "    noise_map_list.append(noise_map)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By plotting the Gaussians we can just about make out that their centres are not all at pix 50, and are spreasd out\n",
        "around it (albeit its difficult to be sure, due to the low signal-to-noise of the data). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for dataset_name, data in zip(dataset_name_list, data_list):\n",
        "    af.ex.plot_profile_1d(\n",
        "        xvalues=np.arange(data.shape[0]),\n",
        "        profile_1d=data,\n",
        "        title=dataset_name,\n",
        "        ylabel=\"Data Values\",\n",
        "        color=\"k\",\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "For each dataset we now create a corresponding `Analysis` class, like in the previous tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_list = []\n",
        "\n",
        "for data, noise_map in zip(data_list, noise_map_list):\n",
        "    analysis = af.ex.Analysis(data=data, noise_map=noise_map)\n",
        "\n",
        "    analysis_list.append(analysis)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model Individual Factors__\n",
        "\n",
        "We first set up a model for each `Gaussian` which is individually fitted to each 1D dataset, which forms the\n",
        "factors on the factor graph we compose. \n",
        "\n",
        "This uses a nearly identical for loop to the previous tutorial, however a shared `centre` is no longer used and each \n",
        "`Gaussian` is given its own prior for the `centre`. We will see next how this `centre` is used to construct the \n",
        "hierachical model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "model_list = []\n",
        "\n",
        "for model_index in range(len(data_list)):\n",
        "    gaussian = af.Model(af.ex.Gaussian)\n",
        "\n",
        "    # gaussian.centre = af.UniformPrior(lower_limit=0.0, upper_limit=1e2)\n",
        "    #  gaussian.normalization = af.UniformPrior(lower_limit=0.0, upper_limit=1e2)\n",
        "    # gaussian.sigma = af.UniformPrior(lower_limit=0.0, upper_limit=25.0)\n",
        "\n",
        "    gaussian.centre = af.GaussianPrior(\n",
        "        mean=50.0, sigma=20.0, lower_limit=0.0, upper_limit=100.0\n",
        "    )\n",
        "    gaussian.normalization = af.GaussianPrior(mean=3.0, sigma=5.0, lower_limit=0.0)\n",
        "    gaussian.sigma = af.GaussianPrior(mean=10.0, sigma=10.0, lower_limit=0.0)\n",
        "\n",
        "    model_list.append(gaussian)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis Factors__\n",
        "\n",
        "Now we have our `Analysis` classes and model components, we can compose our `AnalysisFactor`'s.\n",
        "\n",
        "The hierarchical model fit uses EP, therefore we again supply each `AnalysisFactor` its own `search` and `name`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dynesty = af.DynestyStatic(nlive=100, sample=\"rwalk\")\n",
        "\n",
        "analysis_factor_list = []\n",
        "\n",
        "dataset_index = 0\n",
        "\n",
        "for model, analysis in zip(model_list, analysis_list):\n",
        "    dataset_name = f\"dataset_{dataset_index}\"\n",
        "    dataset_index += 1\n",
        "\n",
        "    analysis_factor = af.AnalysisFactor(\n",
        "        prior_model=model, analysis=analysis, optimiser=dynesty, name=dataset_name\n",
        "    )\n",
        "\n",
        "    analysis_factor_list.append(analysis_factor)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We now compose the hierarchical model that we fit, using the individual Gaussian model components we created above.\n",
        "\n",
        "We first create a `HierarchicalFactor`, which represents the parent Gaussian distribution from which we will assume \n",
        "that the `centre` of each individual `Gaussian` dataset is drawn. \n",
        "\n",
        "For this parent `Gaussian`, we have to place priors on its `mean` and `sigma`, given that they are parameters in our\n",
        "model we are ultimately fitting for."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "hierarchical_factor = af.HierarchicalFactor(\n",
        "    af.GaussianPrior,\n",
        "    mean=af.GaussianPrior(mean=50.0, sigma=10, lower_limit=0.0, upper_limit=100.0),\n",
        "    sigma=af.GaussianPrior(mean=10.0, sigma=5.0, lower_limit=0.0, upper_limit=100.0),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now add each of the individual model `Gaussian`'s `centre` parameters to the `hierarchical_factor`.\n",
        "\n",
        "This composes the hierarchical model whereby the individual `centre` of every `Gaussian` in our dataset is now assumed \n",
        "to be drawn from a shared parent distribution. It is the `mean` and `sigma` of this distribution we are hoping to \n",
        "estimate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "for model in model_list:\n",
        "    hierarchical_factor.add_drawn_variable(model.centre)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Factor Graph__\n",
        "\n",
        "We now create the factor graph for this model, using the list of `AnalysisFactor`'s and the hierarchical factor.\n",
        "\n",
        "Note that in previous tutorials, when we created the `FactorGraphModel` we only passed the list of `AnalysisFactor`'s,\n",
        "which contained the necessary information on the model create the factor graph that was fitted. The `AnalysisFactor`'s\n",
        "were created before we composed the `HierachicalFactor`, which is why we need to pass it separate when composing the\n",
        "factor graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "factor_graph = af.FactorGraphModel(*analysis_factor_list, hierarchical_factor)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model Fit__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "laplace = af.LaplaceOptimiser()\n",
        "\n",
        "ep_result = factor_graph.optimise(\n",
        "    laplace,\n",
        "    paths=af.DirectoryPaths(\n",
        "        name=path.join(\n",
        "            \"howtofit\", \"chapter_graphical_models\", \"tutorial_4_hierarchical\"\n",
        "        )\n",
        "    ),\n",
        "    ep_history=af.EPHistory(kl_tol=1.0),\n",
        "    max_steps=5,\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}