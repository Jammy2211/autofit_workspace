{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 1: Source Code\n",
        "=======================\n",
        "\n",
        "In chapter 1, all tutorials were self contained. The code used to define the model, analysis, run the NonLinearSearch,\n",
        "load data and plot images were contained in the Jupyter notebooks of the tutorial itself. If you wanted to simply\n",
        "parameterize and fit models quickly, chapter 1 taught us how to do that with **PyAutoFit**.\n",
        "\n",
        "However, for a long-term software development project, the code would not be contained in one script but instead make\n",
        "up the project's source code. In this chapter, we will set up the code for the 1D Gaussian fitting example as if it\n",
        "were an actual software project with a clearly defined source code library. This source code can be found in the folder\n",
        "`/autofit_workspace/howtofit/chapter_phase_api/src`.\n",
        "\n",
        "This project will follow the same object-oriented design our Astronomy software packages that use **PyAutoFit** do:\n",
        "\n",
        "  - PyAutoGalaxy: https://github.com/Jammy2211/PyAutoGalaxy\n",
        "  - PyAutoLens: https://github.com/Jammy2211/PyAutoLens\n",
        "  - PyAutoCTI: https://github.com/Jammy2211/PyAutoCTI\n",
        "\n",
        "We believe our design is a good template for any model-fitting software and recommend that if you are using PyAutoFit\n",
        "for a long-term software development project you aim to closely closely the design. In particular, the design:\n",
        "\n",
        " - Uses the **PyAutoFit** Phase API, which provides **PyAutoFit** with a more direct interface with the model, data\n",
        " and results as well as providing a concise API for users of the software.\n",
        "\n",
        " - Uses our parent project **PyAutoConf** to set up configuration files for managing many aspects of the model-fitting\n",
        "software.\n",
        "\n",
        " - Follows an object oriented design that provides the best interface with **PyAutoFit** features like the `Aggregator`.\n",
        "\n",
        "To begin, check out the `src` folder, noting the directory structure of the source code is separated into 5 packages:\n",
        "`dataset`, `fit`, `model`, `plot` and `phase`. This separates the different parts of the code which perform\n",
        "different tasks. For example, the code which handles model composition is separate from the code which handles model\n",
        "fitting.\n",
        "\n",
        "This ensures good code design by removing dependencies between parts of the code that do not need them! This is a\n",
        "principle aspect of object oriented design and software engineering called `separation of concerns`, which the template\n",
        "project strongly adheres too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autofit as af"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will describe this line of code in the next tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from autoconf import conf\n",
        "\n",
        "conf.instance.push(\n",
        "    new_path=path.join(workspace_path, \"howtofit\", \"chapter_phase_api\", \"src\", \"config\")\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, checkout the file \n",
        "\n",
        " `autofit_workspace/howtofit/chapter_phase_api/src/__init__.py\n",
        "\n",
        "Here, we have added imports to this file allowing us to import the entire project in one go, which we do below,\n",
        "importing it as `htf`. \n",
        "\n",
        "Many software projects tend not to do this, instead relying on the user explicitly importing every module in the \n",
        "project that need, for example:\n",
        "\n",
        "`from src.dataset.dataset import Dataset`\n",
        "\n",
        "`from src.model.gaussian import Gaussian`\n",
        "\n",
        "`from src.plot import dataset_plots`\n",
        "\n",
        "`from src.plot import fit_plots`\n",
        "\n",
        "Clearly, this creates a burden on the user, as they have to understand the project structure! Furthermore, as you'll \n",
        "see below, by controlling the project import in this way you can design an API that makes tasks like plotting results \n",
        "more intuitive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import src as htf"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To begin, in the `src` folder checkout the `dataset` package, which contains one module, `dataset.py`. Whereas the \n",
        "previous tutorial used arrays for the `data` and `noise_map`, from here on we'll combine them  into a `Dataset` class,  \n",
        "which can be easily extended if our model-fitting problem has additional data components.\n",
        "\n",
        "The `dataset.py` module contains a number of methods and classes that will be expanded upon in tutorial 3. These are\n",
        "associated with trimming, Settings, etc.\n",
        "\n",
        "To create the `Dataset`, we load it from the `autofit_workspace/dataset` folder and then create a `Dataset` object. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = path.join(\"dataset\", \"example_1d\", \"gaussian_x1\")\n",
        "data = af.util.numpy_array_from_json(file_path=path.join(dataset_path, \"data.json\"))\n",
        "noise_map = af.util.numpy_array_from_json(\n",
        "    file_path=path.join(dataset_path, \"noise_map.json\")\n",
        ")\n",
        "dataset = htf.Dataset(data=data, noise_map=noise_map)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Previously, we manually specified how to plot the `Dataset` using a `plot_line` method. These plotting functions are \n",
        "now in the source code, in the `plot` package, check them out now! You'll note we have separate modules for plotting \n",
        "lines corresponding to the `Dataset` or to a fit.\n",
        "\n",
        "You should take note of two things:  \n",
        "\n",
        " - The `dataset_plots.py` plot functions take instances of the `Dataset` class, meaning we we don't have to manually \n",
        " specify the part of our data we want to pass to the function, making for a more concise API.\n",
        " \n",
        " - In `plot/__init__.py` we have imported the `dataset_plots.py`, `fit_plots.py` and `line_plots.py` modules as their \n",
        " corresponding class names; `Dataset`, `FitDataset` and `Line`. We'll see later how this provides a clean API, where \n",
        " it is immediately obvious to the user how to plot the objects they have used elsewhere in the project for performing \n",
        " calculations.\n",
        "\n",
        "Lets use a plot function to plot our data.\n",
        "\n",
        "In tutorial 4, we'll use this results to inspect the `Aggregator` more. We have setup the template project so the `info`\n",
        "dictionary can again be used by the project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "info = {\"date_of_observation\": \"01-02-18\", \"exposure_time\": 1000.0}\n",
        "\n",
        "htf.plot.Dataset.data(dataset=dataset)\n",
        "htf.plot.Dataset.noise_map(dataset=dataset)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, look at the `model` package, which contains the module `profiles.py`. This contains the `Gaussian` and \n",
        "`Exponential` classes we have used previously to compose the 1D `Gaussian` model that we fit. They now use a class\n",
        "inheritance structure.\n",
        "\n",
        "By packaging all the model components into a single package, this will make it straight forward to add new model\n",
        "components to the source code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "gaussian = htf.Gaussian(centre=50.0, intensity=2.0, sigma=20.0)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, lets checkout the `fit` package which contains the `fit.py` module. This packages fitting methods which compute\n",
        "the quantities we introduced in chapter 1 (residual-map, chi_squareds, log likelihoods, etc.) into a single \n",
        "`FitDataset` class.\n",
        "\n",
        "Again, take note of how the fit plot functions take an instance of the `FitDataset` class and were imported as \n",
        "`FitDataset`, making for a clean API where it is intuitive how to plot the fit.\n",
        "\n",
        "Below, I used the `Gaussian` model above to illustrate how we can easily plot different aspects of a fit. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_data = gaussian.profile_from_xvalues(xvalues=dataset.xvalues)\n",
        "\n",
        "fit = htf.FitDataset(dataset=dataset, model_data=model_data)\n",
        "\n",
        "htf.plot.FitDataset.residual_map(fit=fit)\n",
        "htf.plot.FitDataset.normalized_residual_map(fit=fit)\n",
        "htf.plot.FitDataset.chi_squared_map(fit=fit)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we discussed in chapter 1, the different steps of performing a fit (e.g. computing the residuals, the chi-squared,\n",
        "log likelihood, and so forth) are pretty much generic tasks performed by any model-fitting problem. \n",
        "\n",
        "Thus, you should literally be able to copy and paste the `FitDataset` class found in this tutorial (and future \n",
        "tutorials) and use them in your modeling software! I have made sure the class works for datasets of higher \n",
        "dimensionality (e.g. 2D images or 3D datacubes).\n",
        "\n",
        "For simplicitly, this example project does not include masking of data before a fit (e.g. to remove certain regions of \n",
        "the data during a fit). In tutorial 4 of this chapter we describe how one would extend this project to include the \n",
        "fitting of a masked data, including a `FitMaskedDataset` class which you should again be able to copy and paste for \n",
        "your software project.\n",
        "\n",
        "We're finally ready to look at how our source code sets up the `NonLinearSearch` and model-fit. Whereas before we \n",
        "manually set up the `PriorModel`, `Analysis` and `NonLinearSearch`, from now on we're going to use **PyAutoFit**'s \n",
        "Phase API which uses the `phase` package, which contains 5 modules: `phase.py`, `analysis.py`, `result.py`, \n",
        "`visualizer.py` and `settings.py`.\n",
        "\n",
        "At this point, you should open and inspect (in detail) the 3 source code files `phase.py`, `analysis.py` and \n",
        "`result.py` (we'll cover the other 2 in tutorials 2 and 3).\n",
        "\n",
        "An over view of each is as follows:\n",
        "\n",
        "`phase.py` -> contains the Phase class:\n",
        "\n",
        " - Receives the model to be fitted (in this case a single `Gaussian`..\n",
        " \n",
        " - Handles the directory structure of the output (in this example results are output to the folder\n",
        " `/output/phase_example/`.\n",
        " \n",
        "  Is passed the data when run, which is set up for the analysis.\n",
        "\n",
        "`analysis.py` -> contains the `Analysis` class (and is a restructred version of the the previous tutorial's \n",
        "  `Analysis` class):\n",
        "\n",
        " - Prepares the `Dataset` for fitting.\n",
        " \n",
        " - Fits this `Dataset` with a model instance to compute a `log_likelihood` for every iteration of the `NonLinearSearch`.\n",
        "\n",
        "`result.py` -> contains the `Result` class:\n",
        "\n",
        " - Stores the `Samples` object containing information on the `NonLinearSearch`'s samples.\n",
        " \n",
        " - Has functions to create the `model-image`, `residual-map`, `chi_squared_map` and so forth of the \n",
        " maximum log likelihood model etc.\n",
        "\n",
        "Performing a `NonLinearSearch` in **PyAutoFit** now only requires that we instantiate and run a `Phase` object. The \n",
        "`Phase` performs the following tasks (which we performed manually in the previous tutorial):\n",
        "\n",
        " - Builds the model to be fitted and interfaces it with the `NonLinearSearch`.\n",
        " \n",
        " - Receives the data to be fitted and prepares it so the model can fit it.\n",
        " \n",
        " - Contains the `Analysis` class that defines the `log_likelihood_function`.\n",
        " \n",
        " - Returns the `Result`'s, including the `NonLinearSearch`'s `Samples`'s and the maximum likelihood fit.\n",
        "\n",
        "Note that, like before, priors are loaded from the config file `autofit_workspace/config/priors/profiles.json`. \n",
        "\n",
        "Lets instantiate and run a phase, which reduces the task of performing a model-fit in **PyAutoFit** to just two lines\n",
        "of code.  The results are output to the path `autofit_workspace/output/howtofit/chapter_phase_api/phase_t1`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "phase = htf.Phase(\n",
        "    search=af.Emcee(\n",
        "        path_prefix=\"howtofit\", name=\"tutorial_1_source_code\"\n",
        "    ),\n",
        "    settings=htf.SettingsPhase(),  # We describe `Settings` objects in tutorial 3.\n",
        "    profiles=af.CollectionPriorModel(gaussian=htf.Gaussian),\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"Emcee has begun running, checkout: \\n\"\n",
        "    \"autofit_workspace/output/howtofit/chapter_phase_api/phase_t1 \\n\"\n",
        "    \"for live output of the results.\\n\"\n",
        "    \"This Jupyter notebook cell with progress once Emcee has completed - this could take a few minutes!\"\n",
        ")\n",
        "\n",
        "result = phase.run(dataset=dataset, info=info)\n",
        "\n",
        "print(\"Emcee has finished run - you may now continue the notebook.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The phase returns a `Result` object, just like the model-fit performed in the previous tutorial did. However, in\n",
        "`result.py` you'll have noted we extended the `Result` object to include a property containing an `instance` of the \n",
        "maximum likelihood fit in the form of a `FitDataset` object. \n",
        "\n",
        "This illustrates a benefit of containing the entire fit into one class, we can more easily return it to the user \n",
        "after a model-fit is performed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.max_log_likelihood_fit)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Another benefit of writing our `plot` functions so that their inputs are instances of the classes they plot is now \n",
        "clear. We can  visualize our `Result`'s by simply passing these methods the `FitDataset` instance which is readily \n",
        "available in the results to our `plot` functions!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "htf.plot.FitDataset.model_data(fit=result.max_log_likelihood_fit)\n",
        "htf.plot.FitDataset.residual_map(fit=result.max_log_likelihood_fit)\n",
        "htf.plot.FitDataset.chi_squared_map(fit=result.max_log_likelihood_fit)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Making plots such as these in chapter 1 was cumbersome, and required us to write lots of specific Python code to do!\n",
        "\n",
        "And with that, we have introduced the **PyAutoFit** phase API alongside an example project, which provides a template \n",
        "on how to structure model-fitting software. \n",
        "\n",
        "The remaining tutorials describe functionality included in this source code. At this point, you  should be thinking \n",
        "about how this structure mighr benefit your model-fitting software!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}