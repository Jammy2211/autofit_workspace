{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial 5: Complex Models\n",
    "==========================\n",
    "\n",
    "Up to now, we've fitted a very simple model, a 1D `Gaussian` with 3 free parameters. In this tutorial, we'll look at\n",
    "how **PyAutoFit** allows us to compose and fit models of arbitrary complexity.\n",
    "\n",
    "To begin, you should check out the module `autofit_workspace/howtofit/chapter_1_introduction/profiles.py`.\n",
    "\n",
    "In previous tutorials we used the module `gaussian.py` which contained only the `Gaussian` class. The `profiles.py`\n",
    "includes a second profile, `Exponential`, which like the `Gaussian` class is a model-component that can be fitted to\n",
    "data.\n",
    "\n",
    "Up to now, our data has always been generated using a single `Gaussian` profile. Thus, we have only needed to fit\n",
    "it with a single `Gaussian`. In this tutorial, our `dataset` is now a superpositions of multiple profiles. The models\n",
    "we compose and fit are therefore composed of multiple profiles, such that when we generate the model-data we\n",
    "generate it as the sum of all individual profiles in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-06T13:08:06.861248Z",
     "iopub.status.busy": "2021-02-06T13:08:06.860784Z",
     "iopub.status.idle": "2021-02-06T13:08:07.698006Z",
     "shell.execute_reply": "2021-02-06T13:08:07.698300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jammy/Code/PyAuto/autofit_workspace\n",
      "Working Directory has been set to `/mnt/c/Users/Jammy/Code/PyAuto/autofit_workspace`\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from pyprojroot import here\n",
    "workspace_path = str(here())\n",
    "%cd $workspace_path\n",
    "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
    "\n",
    "import autofit as af\n",
    "import os\n",
    "from os import path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets quickly recap tutorial 1, where using `PriorModels` we created a `Gaussian` as a model component and used it to \n",
    "map a list of parameters to a model `instance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-06T13:08:07.701707Z",
     "iopub.status.busy": "2021-02-06T13:08:07.701346Z",
     "iopub.status.idle": "2021-02-06T13:08:07.715678Z",
     "shell.execute_reply": "2021-02-06T13:08:07.715931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PriorModel `Gaussian` object: \n",
      "\n",
      "Gaussian (centre, UniformPrior, lower_limit = 0.0, upper_limit = 100.0), (intensity, LogUniformPrior, lower_limit = 1e-06, upper_limit = 1000000.0), (sigma, UniformPrior, lower_limit = 0.0, upper_limit = 25.0)\n",
      "Model Instance: \n",
      "\n",
      "<profiles.Gaussian object at 0x7fcb74028040>\n",
      "Instance Parameters \n",
      "\n",
      "x =  0.1\n",
      "intensity =  0.2\n",
      "sigma =  0.3\n"
     ]
    }
   ],
   "source": [
    "import profiles as p\n",
    "\n",
    "model = af.PriorModel(p.Gaussian)\n",
    "\n",
    "print(\"PriorModel `Gaussian` object: \\n\")\n",
    "print(model)\n",
    "\n",
    "instance = model.instance_from_vector(vector=[0.1, 0.2, 0.3])\n",
    "\n",
    "print(\"Model Instance: \\n\")\n",
    "print(instance)\n",
    "\n",
    "print(\"Instance Parameters \\n\")\n",
    "print(\"x = \", instance.centre)\n",
    "print(\"intensity = \", instance.intensity)\n",
    "print(\"sigma = \", instance.sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a model using multiple model components is straight forward in **PyAutoFit**, using a `CollectionPriorModel`\n",
    "object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-06T13:08:07.718575Z",
     "iopub.status.busy": "2021-02-06T13:08:07.718227Z",
     "iopub.status.idle": "2021-02-06T13:08:07.739220Z",
     "shell.execute_reply": "2021-02-06T13:08:07.738904Z"
    }
   },
   "outputs": [],
   "source": [
    "model = af.CollectionPriorModel(gaussian=p.Gaussian, exponential=p.Exponential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `CollectionPriorModel` behaves like a `PriorModel` but contains a collection of model components. For example, it\n",
    "creates a model instance by mapping a list of parameters, which in this case is 6 (3 for the `Gaussian` (centre,\n",
    "intensity, sigma) and 3 for the `Exponential` (centre, intensity, rate))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-06T13:08:07.742600Z",
     "iopub.status.busy": "2021-02-06T13:08:07.742260Z",
     "iopub.status.idle": "2021-02-06T13:08:07.744218Z",
     "shell.execute_reply": "2021-02-06T13:08:07.744468Z"
    }
   },
   "outputs": [],
   "source": [
    "instance = model.instance_from_vector(vector=[0.1, 0.2, 0.3, 0.4, 0.5, 0.01])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `instance` contains each of the model components we defined above, using the input argument name of the\n",
    "`CollectionPriorModel` to define the attributes in the `instance`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-06T13:08:07.747426Z",
     "iopub.status.busy": "2021-02-06T13:08:07.747073Z",
     "iopub.status.idle": "2021-02-06T13:08:07.749485Z",
     "shell.execute_reply": "2021-02-06T13:08:07.749732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance Parameters \n",
      "\n",
      "x (Gaussian) =  0.1\n",
      "intensity (Gaussian) =  0.2\n",
      "sigma (Gaussian) =  0.3\n",
      "x (Exponential) =  0.4\n",
      "intensity (Exponential) =  0.5\n",
      "sigma (Exponential) =  0.01\n"
     ]
    }
   ],
   "source": [
    "print(\"Instance Parameters \\n\")\n",
    "print(\"x (Gaussian) = \", instance.gaussian.centre)\n",
    "print(\"intensity (Gaussian) = \", instance.gaussian.intensity)\n",
    "print(\"sigma (Gaussian) = \", instance.gaussian.sigma)\n",
    "print(\"x (Exponential) = \", instance.exponential.centre)\n",
    "print(\"intensity (Exponential) = \", instance.exponential.intensity)\n",
    "print(\"sigma (Exponential) = \", instance.exponential.rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call the components of a `CollectionPriorModel` whatever we want, and the mapped `instance` will use those names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-06T13:08:07.753029Z",
     "iopub.status.busy": "2021-02-06T13:08:07.752663Z",
     "iopub.status.idle": "2021-02-06T13:08:07.775479Z",
     "shell.execute_reply": "2021-02-06T13:08:07.775116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance Parameters \n",
      "\n",
      "x (Gaussian) =  0.1\n",
      "intensity (Gaussian) =  0.2\n",
      "sigma (Gaussian) =  0.3\n",
      "x (Exponential) =  0.4\n",
      "intensity (Exponential) =  0.5\n",
      "sigma (Exponential) =  0.01\n"
     ]
    }
   ],
   "source": [
    "model_custom_names = af.CollectionPriorModel(jammy=p.Gaussian, rich=p.Exponential)\n",
    "\n",
    "instance = model_custom_names.instance_from_vector(\n",
    "    vector=[0.1, 0.2, 0.3, 0.4, 0.5, 0.01]\n",
    ")\n",
    "\n",
    "print(\"Instance Parameters \\n\")\n",
    "print(\"x (Gaussian) = \", instance.jammy.centre)\n",
    "print(\"intensity (Gaussian) = \", instance.jammy.intensity)\n",
    "print(\"sigma (Gaussian) = \", instance.jammy.sigma)\n",
    "print(\"x (Exponential) = \", instance.rich.centre)\n",
    "print(\"intensity (Exponential) = \", instance.rich.intensity)\n",
    "print(\"sigma (Exponential) = \", instance.rich.rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform visualization we'll again use the plot_line function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-06T13:08:07.779118Z",
     "iopub.status.busy": "2021-02-06T13:08:07.778770Z",
     "iopub.status.idle": "2021-02-06T13:08:07.780721Z",
     "shell.execute_reply": "2021-02-06T13:08:07.780373Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_line(\n",
    "    xvalues,\n",
    "    line,\n",
    "    title=None,\n",
    "    ylabel=None,\n",
    "    errors=None,\n",
    "    color=\"k\",\n",
    "    output_path=None,\n",
    "    output_filename=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a 1D line of data on a plot of x versus y, where the x-axis is the x coordinate of the line and the y-axis\n",
    "    is the intensity of the line at that coordinate.\n",
    "\n",
    "    The function include options to output the image to the hard-disk as a .png.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xvalues : np.ndarray\n",
    "        The x-coordinates the profile is defined on.\n",
    "    line : np.ndarray\n",
    "        The intensity values of the profile which are plotted.\n",
    "    ylabel : str\n",
    "        The y-label of the plot.\n",
    "    output_path : str\n",
    "        The path the image is to be output to hard-disk as a .png.\n",
    "    output_filename : str\n",
    "        The filename of the file if it is output as a .png.\n",
    "    output_format : str\n",
    "        Determines where the plot is displayed on your screen (\"show\") or output to the hard-disk as a png (\"png\").\n",
    "    \"\"\"\n",
    "    plt.errorbar(\n",
    "        x=xvalues, y=line, yerr=errors, color=color, ecolor=\"k\", elinewidth=1, capsize=2\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"x value of profile\")\n",
    "    plt.ylabel(ylabel)\n",
    "    if not path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    plt.savefig(path.join(output_path, f\"{output_filename}.png\"))\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a model composed of multiple components we need to fit it to our data. To do this, we use updated \n",
    "`Analysis` class that creates the `model_data` as a super position of all of the model's individual `Profile`'s. For \n",
    "example, in the model above, the `model_data` is the sum of the `Gaussian`'s  individual profile and `Exponential`'s \n",
    "individual profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-06T13:08:07.787136Z",
     "iopub.status.busy": "2021-02-06T13:08:07.786762Z",
     "iopub.status.idle": "2021-02-06T13:08:07.788347Z",
     "shell.execute_reply": "2021-02-06T13:08:07.788587Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Analysis(af.Analysis):\n",
    "    def __init__(self, data, noise_map):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.data = data\n",
    "        self.noise_map = noise_map\n",
    "\n",
    "    def log_likelihood_function(self, instance):\n",
    "        \"\"\"\n",
    "        Returns the log likelihood of a list of Profiles (Gaussians, Exponentials, etc.) to the dataset, using a\n",
    "        model instance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        instance\n",
    "            The list of Profile model instance (e.g. the Gaussians, Exponentials, etc.).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            The log likelihood value indicating how well this model fit the `MaskedDataset`.\n",
    "\n",
    "        In tutorials 3 & 4, the instance was an instance of a single `Gaussian` profile. PyAutoFit knew this instance\n",
    "        would contain just one Gaussian, because when the model was created we used a PriorModel object in PyAutoFit\n",
    "        to make the Gaussian. This meant we could create the model data using the line:\n",
    "\n",
    "            model_data = instance.gaussian.profile_from_xvalues(xvalues=self.masked_dataset.xvalues)\n",
    "\n",
    "        In this tutorial our instance is comprised of multiple Profile objects, because we used a CollectionPriorModel:\n",
    "\n",
    "            model = CollectionPriorModel(gaussian=profiles.Gaussian, exponential=profiles.Exponential).\n",
    "\n",
    "        By using a CollectionPriorModel, this means the instance parameter input into the fit function is a\n",
    "        dictionary where individual profiles (and their parameters) can be accessed as followed:\n",
    "\n",
    "            print(instance.gaussian)\n",
    "            print(instance.exponential)\n",
    "            print(instance.exponential.centre)\n",
    "\n",
    "        The names of the attributes of the instance correspond to what we input into the CollectionPriorModel. Lets\n",
    "        look at a second example:\n",
    "\n",
    "            model = CollectionPriorModel(\n",
    "                          gaussian_0=profiles.Gaussian,\n",
    "                          gaussian_1=profiles.Gaussian,\n",
    "                          whatever_i_want=profiles.Exponential\n",
    "                     ).\n",
    "\n",
    "            print(instance.gaussian_0)\n",
    "            print(instance.gaussian_1)\n",
    "            print(instance.whatever_i_want.centre)\n",
    "\n",
    "        A CollectionPriorModel allows us to name our model components whatever we want!\n",
    "\n",
    "        In this tutorial, we want our `fit` function to fit the data with a profile which is the summed profile\n",
    "        of all individual profiles in the model. Look at `model_data_from_instance` to see how we do this.\n",
    "        \"\"\"\n",
    "        model_data = self.model_data_from_instance(instance=instance)\n",
    "\n",
    "        residual_map = self.data - model_data\n",
    "        chi_squared_map = (residual_map / self.noise_map) ** 2.0\n",
    "        chi_squared = sum(chi_squared_map)\n",
    "        noise_normalization = np.sum(np.log(2 * np.pi * noise_map ** 2.0))\n",
    "        log_likelihood = -0.5 * (chi_squared + noise_normalization)\n",
    "\n",
    "        return log_likelihood\n",
    "\n",
    "    def model_data_from_instance(self, instance):\n",
    "\n",
    "        \"\"\"\n",
    "        To create the summed profile of all individual profiles in an instance, we can use a dictionary comprehension\n",
    "        to iterate over all profiles in the instance.\n",
    "        \"\"\"\n",
    "        xvalues = np.arange(self.data.shape[0])\n",
    "\n",
    "        return sum(\n",
    "            [profile.profile_from_xvalues(xvalues=xvalues) for profile in instance]\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        For those not familiar with dictionary comprehensions, below I've included how one would use the instance to \n",
    "        create the summed profile using a more simple for loop.\n",
    "\n",
    "            model_data = np.zeros(shape=self.masked_dataset.xvalues.shape[0])\n",
    "\n",
    "            for profile in instance:\n",
    "                model_data += profile.profile_from_xvalues(xvalues=self.masked_dataset.xvalues)\n",
    "\n",
    "            return model_data\n",
    "        \"\"\"\n",
    "\n",
    "    def visualize(self, paths, instance, during_analysis):\n",
    "\n",
    "        \"\"\"\n",
    "        This method is identical to the previous tutorial, except it now uses the `model_data_from_instance` method\n",
    "        to create the profile.\n",
    "        \"\"\"\n",
    "        xvalues = np.arange(self.data.shape[0])\n",
    "\n",
    "        model_data = self.model_data_from_instance(instance=instance)\n",
    "\n",
    "        residual_map = self.data - model_data\n",
    "        chi_squared_map = (residual_map / self.noise_map) ** 2.0\n",
    "\n",
    "        \"\"\"The visualizer now outputs images of the best-fit results to hard-disk (checkout `visualizer.py`).\"\"\"\n",
    "        plot_line(\n",
    "            xvalues=xvalues,\n",
    "            line=self.data,\n",
    "            title=\"Data\",\n",
    "            ylabel=\"Data Values\",\n",
    "            color=\"k\",\n",
    "            output_path=paths.image_path,\n",
    "            output_filename=\"data\",\n",
    "        )\n",
    "\n",
    "        plot_line(\n",
    "            xvalues=xvalues,\n",
    "            line=model_data,\n",
    "            title=\"Model Data\",\n",
    "            ylabel=\"Model Data Values\",\n",
    "            color=\"k\",\n",
    "            output_path=paths.image_path,\n",
    "            output_filename=\"model_data\",\n",
    "        )\n",
    "\n",
    "        plot_line(\n",
    "            xvalues=xvalues,\n",
    "            line=residual_map,\n",
    "            title=\"Residual Map\",\n",
    "            ylabel=\"Residuals\",\n",
    "            color=\"k\",\n",
    "            output_path=paths.image_path,\n",
    "            output_filename=\"residual_map\",\n",
    "        )\n",
    "\n",
    "        plot_line(\n",
    "            xvalues=xvalues,\n",
    "            line=chi_squared_map,\n",
    "            title=\"Chi-Squared Map\",\n",
    "            ylabel=\"Chi-Squareds\",\n",
    "            color=\"k\",\n",
    "            output_path=paths.image_path,\n",
    "            output_filename=\"chi_squared_map\",\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset from the `autofit_workspace/dataset` folder. This uses a new `dataset` that is a sum of a \n",
    "`Gaussian` and `Exponential` profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-06T13:08:07.791050Z",
     "iopub.status.busy": "2021-02-06T13:08:07.790722Z",
     "iopub.status.idle": "2021-02-06T13:08:07.792724Z",
     "shell.execute_reply": "2021-02-06T13:08:07.792965Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_path = path.join(\"dataset\", \"example_1d\", \"gaussian_x1__exponential_x1\")\n",
    "data = af.util.numpy_array_from_json(file_path=path.join(dataset_path, \"data.json\"))\n",
    "noise_map = af.util.numpy_array_from_json(\n",
    "    file_path=path.join(dataset_path, \"noise_map.json\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now perform the fit using our model which is composed of two `Profile`'s. You'll note that the `Emcee`\n",
    "dimensionality has increased from N=3 to N=6, given that we are now fitting two `Profile`'s each with 3 free parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-06T13:08:07.795724Z",
     "iopub.status.busy": "2021-02-06T13:08:07.795359Z",
     "iopub.status.idle": "2021-02-06T13:08:09.514585Z",
     "shell.execute_reply": "2021-02-06T13:08:09.514894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emcee has begun running. \n",
      "Checkout the autofit_workspace/output/howtofit/chapter_1/tutorial_5__gaussian_x1__exponential_x1 \n",
      "folder for live output of the results.\n",
      "This Jupyter notebook cell with progress once Emcee has completed - this could take a few minutes!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:tutorial_5__gaussian_x1__exponential_x1 already completed, skipping non-linear search.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emcee has finished run - you may now continue the notebook.\n"
     ]
    }
   ],
   "source": [
    "analysis = Analysis(data=data, noise_map=noise_map)\n",
    "\n",
    "emcee = af.Emcee(\n",
    "    name=\"tutorial_5__gaussian_x1__exponential_x1\", path_prefix=\"howtofit/chapter_1\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Emcee has begun running. \\n\"\n",
    "    \"Checkout the autofit_workspace/output/howtofit/chapter_1/tutorial_5__gaussian_x1__exponential_x1 \\n\"\n",
    "    \"folder for live output of the results.\\n\"\n",
    "    \"This Jupyter notebook cell with progress once Emcee has completed - this could take a few minutes!\"\n",
    ")\n",
    "\n",
    "result = emcee.fit(model=model, analysis=analysis)\n",
    "\n",
    "print(\"Emcee has finished run - you may now continue the notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the results of the fit by going to the folder \n",
    "`autofit_workspace/output/howtofit/chapter_1/tutorial_5__gaussian_x1__exponential_x1`. The fit takes longer to run than \n",
    "the fits performed in previous tutorials, because the dimensionality of the model we fit increases from 3 to 6.\n",
    "\n",
    "With the `CollectionPriorModel`, **PyAutoFit** provides all the tools needed to compose and fit any model imaginable!\n",
    "Lets fit a model composed of two `Gaussian`. and and an `Exponential`, which will have a dimensionality of N=9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-06T13:08:09.518868Z",
     "iopub.status.busy": "2021-02-06T13:08:09.518358Z",
     "iopub.status.idle": "2021-02-06T13:08:11.776583Z",
     "shell.execute_reply": "2021-02-06T13:08:11.776829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emcee has begun running.\n",
      "checkout the autofit_workspace/output/howtofit/chapter_1/tutorial_5__gaussian_x2__exponential_x1\n",
      " folder for live output of the results.\n",
      "This Jupyter notebook cell with progress once Emcee has completed - this could take a few minutes!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:tutorial_5__gaussian_x2__exponential_x1 already completed, skipping non-linear search.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emcee has finished run - you may now continue the notebook.\n"
     ]
    }
   ],
   "source": [
    "dataset_path = path.join(\"dataset\", \"example_1d\", \"gaussian_x2__exponential_x1\")\n",
    "data = af.util.numpy_array_from_json(file_path=path.join(dataset_path, \"data.json\"))\n",
    "noise_map = af.util.numpy_array_from_json(\n",
    "    file_path=path.join(dataset_path, \"noise_map.json\")\n",
    ")\n",
    "\n",
    "analysis = Analysis(data=data, noise_map=noise_map)\n",
    "\n",
    "model = af.CollectionPriorModel(\n",
    "    gaussian_0=p.Gaussian, gaussian_1=p.Gaussian, exponential=p.Exponential\n",
    ")\n",
    "\n",
    "emcee = af.Emcee(\n",
    "    name=\"tutorial_5__gaussian_x2__exponential_x1\", path_prefix=\"howtofit/chapter_1\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Emcee has begun running.\\n\"\n",
    "    \"checkout the autofit_workspace/output/howtofit/chapter_1/tutorial_5__gaussian_x2__exponential_x1\\n\"\n",
    "    \" folder for live output of the results.\\n\"\n",
    "    \"This Jupyter notebook cell with progress once Emcee has completed - this could take a few minutes!\"\n",
    ")\n",
    "\n",
    "result = emcee.fit(model=model, analysis=analysis)\n",
    "\n",
    "print(\"Emcee has finished run - you may now continue the notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fully customize the model that we fit. Lets suppose we have a dataset` that consists of three `Gaussian` \n",
    "profiles, but we also know the following information about the dataset:\n",
    "\n",
    "- All 3 `Gaussian`'s are centrally aligned.\n",
    "- The `sigma` of one `Gaussian` is equal to 1.0.\n",
    "- The sigma of another `Gaussian` is above 3.0.\n",
    "\n",
    "We can edit our `CollectionPriorModel` to meet these constraints accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-06T13:08:11.779496Z",
     "iopub.status.busy": "2021-02-06T13:08:11.779154Z",
     "iopub.status.idle": "2021-02-06T13:08:11.809470Z",
     "shell.execute_reply": "2021-02-06T13:08:11.809146Z"
    }
   },
   "outputs": [],
   "source": [
    "model = af.CollectionPriorModel(\n",
    "    gaussian_0=p.Gaussian, gaussian_1=p.Gaussian, gaussian_2=p.Gaussian\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.gaussian_0.centre = model.gaussian_1.centre\n",
    "model.gaussian_1.centre = model.gaussian_2.centre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-06T13:08:11.811836Z",
     "iopub.status.busy": "2021-02-06T13:08:11.811494Z",
     "iopub.status.idle": "2021-02-06T13:08:11.813405Z",
     "shell.execute_reply": "2021-02-06T13:08:11.813062Z"
    }
   },
   "outputs": [],
   "source": [
    "model.gaussian_0.sigma = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.gaussian_2.add_assertion(model.gaussian_2.sigma > 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-06T13:08:11.816332Z",
     "iopub.status.busy": "2021-02-06T13:08:11.815956Z",
     "iopub.status.idle": "2021-02-06T13:08:13.885677Z",
     "shell.execute_reply": "2021-02-06T13:08:13.886009Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:tutorial_5__gaussian_x3 already completed, skipping non-linear search.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emcee has begun running. Checkout the autofit_workspace/output/howtofit/chapter_1/tutorial_5__gaussian_x3 folder for live output of the results.This Jupyter notebook cell with progress once Emcee has completed - this could take a few minutes!\n",
      "Emcee has finished run - you may now continue the notebook.\n"
     ]
    }
   ],
   "source": [
    "dataset_path = path.join(\"dataset\", \"example_1d\", \"gaussian_x3\")\n",
    "data = af.util.numpy_array_from_json(file_path=path.join(dataset_path, \"data.json\"))\n",
    "noise_map = af.util.numpy_array_from_json(\n",
    "    file_path=path.join(dataset_path, \"noise_map.json\")\n",
    ")\n",
    "\n",
    "analysis = Analysis(data=data, noise_map=noise_map)\n",
    "\n",
    "emcee = af.Emcee(\n",
    "    name=\"tutorial_5__gaussian_x3\", path_prefix=path.join(\"howtofit\", \"chapter_1\")\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Emcee has begun running. \"\n",
    "    \"Checkout the autofit_workspace/output/howtofit/chapter_1/tutorial_5__gaussian_x3\"\n",
    "    \" folder for live output of the results.\"\n",
    "    \"This Jupyter notebook cell with progress once Emcee has completed - this could take a few minutes!\"\n",
    ")\n",
    "\n",
    "result = emcee.fit(model=model, analysis=analysis)\n",
    "\n",
    "print(\"Emcee has finished run - you may now continue the notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with that, we are complete. In this tutorial, we learned how to compose and fit complex models in **PyAutoFit**.\n",
    " \n",
    "To end, you should think again in more detail about your model fitting problem:\n",
    "\n",
    " Are there many different model components you may wish to define and fit?\n",
    "\n",
    " Is your data the super position of many different model components, like the profiles in this tutorial?\n",
    "\n",
    " In this tutorial, all components of our model did the same thing, represent a 1D profile. In your model, you may\n",
    "have model components that represent different parts of your model, which need to be combined in more complicated ways\n",
    "in order to create your model-fit. You now have all the tools you need to define, compose and fit very complex models!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
