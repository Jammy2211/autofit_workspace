{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from autoconf.dictable import to_dict\n",
        "\n",
        "import autofit as af\n",
        "\n",
        "import json\n",
        "from os import path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def simulate_dataset_1d_via_gaussian_from(gaussian, dataset_path):\n",
        "    \"\"\"\n",
        "    Specify the number of pixels used to create the xvalues on which the 1D line of the profile is generated using and\n",
        "    thus defining the number of data-points in our data.\n",
        "    \"\"\"\n",
        "    pixels = 100\n",
        "    xvalues = np.arange(pixels)\n",
        "\n",
        "    \"\"\"\n",
        "    Evaluate this `Gaussian` model instance at every xvalues to create its model profile.\n",
        "    \"\"\"\n",
        "    model_data_1d = gaussian.model_data_from(xvalues=xvalues)\n",
        "\n",
        "    \"\"\"\n",
        "    Determine the noise (at a specified signal to noise level) in every pixel of our model profile.\n",
        "    \"\"\"\n",
        "    signal_to_noise_ratio = 25.0\n",
        "    noise = np.random.normal(0.0, 1.0 / signal_to_noise_ratio, pixels)\n",
        "\n",
        "    \"\"\"\n",
        "    Add this noise to the model line to create the line data that is fitted, using the signal-to-noise ratio to compute\n",
        "    noise-map of our data which is required when evaluating the chi-squared value of the likelihood.\n",
        "    \"\"\"\n",
        "    data = model_data_1d + noise\n",
        "    noise_map = (1.0 / signal_to_noise_ratio) * np.ones(pixels)\n",
        "\n",
        "    \"\"\"\n",
        "    Output the data and noise-map to the `autofit_workspace/dataset` folder so they can be loaded and used \n",
        "    in other example scripts.\n",
        "    \"\"\"\n",
        "    af.util.numpy_array_to_json(\n",
        "        array=data, file_path=path.join(dataset_path, \"data.json\"), overwrite=True\n",
        "    )\n",
        "    af.util.numpy_array_to_json(\n",
        "        array=noise_map,\n",
        "        file_path=path.join(dataset_path, \"noise_map.json\"),\n",
        "        overwrite=True,\n",
        "    )\n",
        "    plt.errorbar(\n",
        "        x=xvalues,\n",
        "        y=data,\n",
        "        yerr=noise_map,\n",
        "        linestyle=\"\",\n",
        "        color=\"k\",\n",
        "        ecolor=\"k\",\n",
        "        elinewidth=1,\n",
        "        capsize=2,\n",
        "    )\n",
        "    plt.title(\"1D Gaussian Dataset.\")\n",
        "    plt.xlabel(\"x values of profile\")\n",
        "    plt.ylabel(\"Profile normalization\")\n",
        "    plt.savefig(path.join(dataset_path, \"image.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    \"\"\"\n",
        "    __Model Json__\n",
        "    \n",
        "    Output the model to a .json file so we can refer to its parameters in the future.\n",
        "    \"\"\"\n",
        "    model_file = path.join(dataset_path, \"model.json\")\n",
        "\n",
        "    with open(model_file, \"w+\") as f:\n",
        "        try:\n",
        "            json.dump(to_dict(gaussian), f, indent=4)\n",
        "        except (TypeError, ValueError):\n",
        "            pass\n",
        "\n",
        "\n",
        "def simulate_data_1d_with_kernel_via_gaussian_from(gaussian, dataset_path):\n",
        "    \"\"\"\n",
        "    Specify the number of pixels used to create the xvalues on which the 1D line of the profile is generated using and\n",
        "    thus defining the number of data-points in our data.\n",
        "    \"\"\"\n",
        "    pixels = 100\n",
        "    xvalues = np.arange(pixels)\n",
        "\n",
        "    \"\"\"\n",
        "    Evaluate this `Gaussian` model instance at every xvalues to create its model profile.\n",
        "    \"\"\"\n",
        "    model_data_1d = gaussian.model_data_from(xvalues=xvalues)\n",
        "\n",
        "    \"\"\"\n",
        "    Determine the noise (at a specified signal to noise level) in every pixel of our model profile.\n",
        "    \"\"\"\n",
        "    kernel_pixels = 21\n",
        "    kernel_xvalues = np.arange(kernel_pixels)\n",
        "    kernel_sigma = 5.0\n",
        "    kernel_centre = 10.0\n",
        "    kernel_xvalues = np.subtract(kernel_xvalues, kernel_centre)\n",
        "    kernel = np.multiply(\n",
        "        np.divide(1.0, kernel_sigma * np.sqrt(2.0 * np.pi)),\n",
        "        np.exp(-0.5 * np.square(np.divide(kernel_xvalues, kernel_sigma))),\n",
        "    )\n",
        "    kernel = kernel / np.sum(kernel)\n",
        "\n",
        "    \"\"\"\n",
        "    Convolve the model line with this kernel.\n",
        "    \"\"\"\n",
        "    blurred_model_data_1d = np.convolve(model_data_1d, kernel, mode=\"same\")\n",
        "\n",
        "    \"\"\"\n",
        "    Create a Gaussian kernel which the model line will be convolved with.\n",
        "    \"\"\"\n",
        "    signal_to_noise_ratio = 25.0\n",
        "    noise = np.random.normal(0.0, 1.0 / signal_to_noise_ratio, pixels)\n",
        "\n",
        "    \"\"\"\n",
        "    Add this noise to the model line to create the line data that is fitted, using the signal-to-noise ratio to compute\n",
        "    noise-map of our data which is required when evaluating the chi-squared value of the likelihood.\n",
        "    \"\"\"\n",
        "    data = blurred_model_data_1d + noise\n",
        "    noise_map = (1.0 / signal_to_noise_ratio) * np.ones(pixels)\n",
        "\n",
        "    \"\"\"\n",
        "    Output the data and noise-map to the `autofit_workspace/dataset` folder so they can be loaded and used \n",
        "    in other example scripts.\n",
        "    \"\"\"\n",
        "    af.util.numpy_array_to_json(\n",
        "        array=data, file_path=path.join(dataset_path, \"data.json\"), overwrite=True\n",
        "    )\n",
        "    af.util.numpy_array_to_json(\n",
        "        array=noise_map,\n",
        "        file_path=path.join(dataset_path, \"noise_map.json\"),\n",
        "        overwrite=True,\n",
        "    )\n",
        "    af.util.numpy_array_to_json(\n",
        "        array=kernel, file_path=path.join(dataset_path, \"kernel.json\"), overwrite=True\n",
        "    )\n",
        "    plt.errorbar(\n",
        "        x=xvalues,\n",
        "        y=data,\n",
        "        yerr=noise_map,\n",
        "        linestyle=\"\",\n",
        "        color=\"k\",\n",
        "        ecolor=\"k\",\n",
        "        elinewidth=1,\n",
        "        capsize=2,\n",
        "    )\n",
        "    plt.title(\"1D Gaussian Dataset with Kernel2D Blurring.\")\n",
        "    plt.xlabel(\"x values of profile\")\n",
        "    plt.ylabel(\"Profile normalization\")\n",
        "    plt.savefig(path.join(dataset_path, \"image.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    \"\"\"\n",
        "    __Model Json__\n",
        "\n",
        "    Output the model to a .json file so we can refer to its parameters in the future.\n",
        "    \"\"\"\n",
        "    model_file = path.join(dataset_path, \"model.json\")\n",
        "\n",
        "    with open(model_file, \"w+\") as f:\n",
        "        json.dump(to_dict(gaussian), f, indent=4)\n",
        "\n",
        "\n",
        "def simulate_dataset_1d_via_profile_1d_list_from(profile_1d_list, dataset_path):\n",
        "    \"\"\"\n",
        "    Specify the number of pixels used to create the xvalues on which the 1D line of the profile is generated using and\n",
        "    thus defining the number of data-points in our data.\n",
        "    \"\"\"\n",
        "    pixels = 100\n",
        "    xvalues = np.arange(pixels)\n",
        "\n",
        "    \"\"\"\n",
        "    Evaluate the `Gaussian` and Exponential model instances at every xvalues to create their model profile and sum\n",
        "    them together to create the overall model profile.\n",
        "    \"\"\"\n",
        "    model_data_1d_list = [\n",
        "        profile_1d.model_data_from(xvalues=xvalues) for profile_1d in profile_1d_list\n",
        "    ]\n",
        "\n",
        "    model_data_1d = sum(model_data_1d_list)\n",
        "\n",
        "    \"\"\"\n",
        "    Determine the noise (at a specified signal to noise level) in every pixel of our model profile.\n",
        "    \"\"\"\n",
        "    signal_to_noise_ratio = 25.0\n",
        "    noise = np.random.normal(0.0, 1.0 / signal_to_noise_ratio, pixels)\n",
        "\n",
        "    \"\"\"\n",
        "    Add this noise to the model line to create the line data that is fitted, using the signal-to-noise ratio to compute\n",
        "    noise-map of our data which is required when evaluating the chi-squared value of the likelihood.\n",
        "    \"\"\"\n",
        "    data = model_data_1d + noise\n",
        "    noise_map = (1.0 / signal_to_noise_ratio) * np.ones(pixels)\n",
        "\n",
        "    \"\"\"\n",
        "    Output the data and noise-map to the `autofit_workspace/dataset` folder so they can be loaded and used \n",
        "    in other example scripts.\n",
        "    \"\"\"\n",
        "    af.util.numpy_array_to_json(\n",
        "        array=data, file_path=path.join(dataset_path, \"data.json\"), overwrite=True\n",
        "    )\n",
        "    af.util.numpy_array_to_json(\n",
        "        array=noise_map,\n",
        "        file_path=path.join(dataset_path, \"noise_map.json\"),\n",
        "        overwrite=True,\n",
        "    )\n",
        "    plt.errorbar(\n",
        "        x=xvalues,\n",
        "        y=data,\n",
        "        yerr=noise_map,\n",
        "        linestyle=\"\",\n",
        "        color=\"k\",\n",
        "        ecolor=\"k\",\n",
        "        elinewidth=1,\n",
        "        capsize=2,\n",
        "    )\n",
        "    plt.plot(range(data.shape[0]), model_data_1d, color=\"r\")\n",
        "    for model_data_1d_individual in model_data_1d_list:\n",
        "        plt.plot(range(data.shape[0]), model_data_1d_individual, \"--\")\n",
        "    plt.title(\"1D Profiles Dataset.\")\n",
        "    plt.xlabel(\"x values of profile\")\n",
        "    plt.ylabel(\"Profile normalization\")\n",
        "    plt.savefig(path.join(dataset_path, \"image.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    \"\"\"\n",
        "    __Model Json__\n",
        "\n",
        "    Output the model to a .json file so we can refer to its parameters in the future.\n",
        "    \"\"\"\n",
        "    for i, profile in enumerate(profile_1d_list):\n",
        "        model_file = path.join(dataset_path, f\"model_{i}.json\")\n",
        "\n",
        "        with open(model_file, \"w+\") as f:\n",
        "            try:\n",
        "                json.dump(to_dict(profile), f, indent=4)\n",
        "            except (TypeError, ValueError):\n",
        "                pass\n",
        "\n",
        "    \"\"\"\n",
        "    __Max Log Likelihood__\n",
        "    \"\"\"\n",
        "    chi_squared = np.sum(((data - model_data_1d) / noise_map) ** 2)\n",
        "    noise_normalization = np.sum(np.log(2 * np.pi * noise_map**2.0))\n",
        "    log_likelihood = -0.5 * (chi_squared + noise_normalization)\n",
        "\n",
        "    with open(path.join(dataset_path, \"max_log_likelihood.json\"), \"w+\") as f:\n",
        "        json.dump({\"log_likelihood\": log_likelihood}, f, indent=4)\n",
        "\n",
        "\n",
        "def simulate_data_1d_with_kernel_via_profile_1d_list_from(\n",
        "    profile_1d_list, dataset_path\n",
        "):\n",
        "    \"\"\"\n",
        "    Specify the number of pixels used to create the xvalues on which the 1D line of the profile is generated using and\n",
        "    thus defining the number of data-points in our data.\n",
        "    \"\"\"\n",
        "    pixels = 100\n",
        "    xvalues = np.arange(pixels)\n",
        "\n",
        "    \"\"\"\n",
        "    Evaluate the `Gaussian` and Exponential model instances at every xvalues to create their model profile and sum\n",
        "    them together to create the overall model profile.\n",
        "    \"\"\"\n",
        "    model_data_1d = np.zeros(shape=pixels)\n",
        "\n",
        "    for profile in profile_1d_list:\n",
        "        model_data_1d += profile.model_data_from(xvalues=xvalues)\n",
        "\n",
        "    \"\"\"\n",
        "    Create a Gaussian kernel which the model line will be convolved with.\n",
        "    \"\"\"\n",
        "    kernel_pixels = 21\n",
        "    kernel_xvalues = np.arange(kernel_pixels)\n",
        "    kernel_sigma = 5.0\n",
        "    kernel_centre = 10.0\n",
        "    kernel_xvalues = np.subtract(kernel_xvalues, kernel_centre)\n",
        "    kernel = np.multiply(\n",
        "        np.divide(1.0, kernel_sigma * np.sqrt(2.0 * np.pi)),\n",
        "        np.exp(-0.5 * np.square(np.divide(kernel_xvalues, kernel_sigma))),\n",
        "    )\n",
        "    kernel = kernel / np.sum(kernel)\n",
        "\n",
        "    \"\"\"\n",
        "    Convolve the model line with this kernel.\n",
        "    \"\"\"\n",
        "\n",
        "    blurred_model_data_1d = np.convolve(model_data_1d, kernel, mode=\"same\")\n",
        "\n",
        "    \"\"\"\n",
        "    Determine the noise (at a specified signal to noise level) in every pixel of our model profile.\n",
        "    \"\"\"\n",
        "    signal_to_noise_ratio = 25.0\n",
        "    noise = np.random.normal(0.0, 1.0 / signal_to_noise_ratio, pixels)\n",
        "\n",
        "    \"\"\"\n",
        "    Add this noise to the model line to create the line data that is fitted, using the signal-to-noise ratio to compute\n",
        "    noise-map of our data which is required when evaluating the chi-squared value of the likelihood.\n",
        "    \"\"\"\n",
        "    data = blurred_model_data_1d + noise\n",
        "    noise_map = (1.0 / signal_to_noise_ratio) * np.ones(pixels)\n",
        "\n",
        "    \"\"\"\n",
        "    Output the data and noise-map to the `autofit_workspace/dataset` folder so they can be loaded and used \n",
        "    in other example scripts.\n",
        "    \"\"\"\n",
        "    af.util.numpy_array_to_json(\n",
        "        array=data, file_path=path.join(dataset_path, \"data.json\"), overwrite=True\n",
        "    )\n",
        "    af.util.numpy_array_to_json(\n",
        "        array=noise_map,\n",
        "        file_path=path.join(dataset_path, \"noise_map.json\"),\n",
        "        overwrite=True,\n",
        "    )\n",
        "    af.util.numpy_array_to_json(\n",
        "        array=kernel, file_path=path.join(dataset_path, \"kernel.json\"), overwrite=True\n",
        "    )\n",
        "\n",
        "    plt.errorbar(\n",
        "        x=xvalues,\n",
        "        y=data,\n",
        "        yerr=noise_map,\n",
        "        linestyle=\"\",\n",
        "        color=\"k\",\n",
        "        ecolor=\"k\",\n",
        "        elinewidth=1,\n",
        "        capsize=2,\n",
        "    )\n",
        "    plt.title(\"1D Profiles Dataset with Kernel2D Blurring.\")\n",
        "    plt.xlabel(\"x values of profile\")\n",
        "    plt.ylabel(\"Profile normalization\")\n",
        "    plt.savefig(path.join(dataset_path, \"image.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    \"\"\"\n",
        "    __Model Json__\n",
        "\n",
        "    Output the model to a .json file so we can refer to its parameters in the future.\n",
        "    \"\"\"\n",
        "    for i, profile in enumerate(profile_1d_list):\n",
        "        model_file = path.join(dataset_path, f\"model_{i}.json\")\n",
        "\n",
        "        with open(model_file, \"w+\") as f:\n",
        "            json.dump(to_dict(profile), f, indent=4)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}